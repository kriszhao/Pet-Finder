{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import all libraries needed. We can remove many of them\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1338) # for reproducibility\n",
    "import pandas as pd\n",
    "import _pickle as cPickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "#from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout, LSTM, GRU, Bidirectional, concatenate\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.utils.layer_utils import print_summary\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.activations import softmax\n",
    "import os\n",
    "\n",
    "#from keras import initializations\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from keras import backend as K\n",
    "# K.clear_session()\n",
    "\n",
    "#libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.layers import Dense, Input, Flatten, Reshape\n",
    "#from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout, LSTM, GRU, Bidirectional, concatenate\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, Concatenate, GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
    "from keras.applications.densenet import preprocess_input, DenseNet121\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.utils.layer_utils import print_summary\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import CSVLogger\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "batch_size = 16\n",
    "VALIDATION_SPLIT = 0.5\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "#Sett=1\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "#Measure of success\n",
    "def kappa(y_true, y_pred):\n",
    "    y_true = np.argmax(y_true, axis = 1)\n",
    "    y_pred = np.argmax(y_pred, axis = 1)\n",
    "    \n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds = pd.read_csv('./all/breed_labels.csv')\n",
    "colors = pd.read_csv('./all/color_labels.csv')\n",
    "states = pd.read_csv('./all/state_labels.csv')\n",
    "train = pd.read_csv('./all/train.csv')\n",
    "test = pd.read_csv('./all/test/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_ids = train['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Extract text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(df):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = df['Description']\n",
    "    string = re.sub(r\"\\\\\", \"\", string)    \n",
    "    #string = re.sub(r\"\\'\", \"\", string)    #this will remove ' \n",
    "    string = re.sub(r\"\\\"\", \"\", string)\n",
    "    string = re.sub(\"<a.*?</a>\", \"\", string) #remobe <a> href tag\n",
    "    return string.strip().lower()\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Preparing text and labels\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    \n",
    "    for idx in range(text.shape[0]):\n",
    "        text = df.Text[idx]\n",
    "        texts.append(clean_str(text))\n",
    "    \n",
    "    return texts\n",
    "\n",
    "def tokenization(texts,dataset= \"full_data\", maxlen=MAX_SEQUENCE_LENGTH,num_words=MAX_NB_WORDS):\n",
    "    ### tokenizing and creating word_index dictionary - Map each word to and index in vocabulary dictionary\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts) #only keep top 20000\n",
    "\n",
    "    word_index = tokenizer.word_index # all unique word index!\n",
    "    print('Found {} unique tokens in {}.'.format(len(word_index),dataset))\n",
    "\n",
    "    data2 = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH) #pad all sequences to be size 1000\n",
    "    \n",
    "    return sequences, word_index, data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(\"\")\n",
    "test = test.fillna(\"\")\n",
    "\n",
    "train['Description'] = train.apply(clean_str, axis = 1)\n",
    "test['Description'] = test.apply(clean_str, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21810 unique tokens in full_data.\n",
      "Found 11547 unique tokens in full_data.\n"
     ]
    }
   ],
   "source": [
    "seq , word_index , full_data = tokenization(train.Description)\n",
    "test_seq , test_word_index , test_full_data = tokenization(test.Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(dic, word_embed):\n",
    "    embedin_matrix = np.random.random((len(dic) + 1 , EMBEDDING_DIM))\n",
    "    for word, ind in dic.items():\n",
    "        embedding_vector = word_embed.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedin_matrix[ind] = embedding_vector ### word not found in glove will be initialized randomly\n",
    "    \n",
    "    return embedin_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "GLOVE_DIR = \"all/data/glove\"\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "em_mat = create_embedding(word_index, embeddings_index)\n",
    "#test_em_mat = create_embedding(test_word_index, embeddings_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the keras embedding layer which we will use for all our experiments\n",
    "embedding_layer = Embedding(len(em_mat),\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[em_mat],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 256 image features for each pet\n",
    "\n",
    "Don't need to run the model now. Directly load the csv features. Later, we could use a different pre-trained model or even re-train few layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resize_to_square(im):\n",
    "#     old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "#     ratio = float(img_size)/max(old_size)\n",
    "#     new_size = tuple([int(x*ratio) for x in old_size])\n",
    "#     # new_size should be in (width, height) format\n",
    "#     im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "#     delta_w = img_size - new_size[1]\n",
    "#     delta_h = img_size - new_size[0]\n",
    "#     top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "#     left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "#     color = [0, 0, 0]\n",
    "#     new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "#     return new_im\n",
    "\n",
    "# def load_image(path, pet_id):\n",
    "#     image = cv2.imread(f'{path}{pet_id}-1.jpg')\n",
    "#     new_image = resize_to_square(image)\n",
    "#     new_image = preprocess_input(new_image)\n",
    "#     return new_image\n",
    "\n",
    "# inp = Input((256,256,3))\n",
    "# backbone = DenseNet121(input_tensor = inp, include_top = False)\n",
    "# x = backbone.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
    "# x = AveragePooling1D(4)(x)\n",
    "# out = Lambda(lambda x: x[:,:,0])(x)\n",
    "\n",
    "# m = Model(inp,out)\n",
    "\n",
    "# features = {}\n",
    "# for b in (range(n_batches)):\n",
    "#     start = b*batch_size\n",
    "#     end = (b+1)*batch_size\n",
    "#     batch_pets = pet_ids[start:end]\n",
    "#     batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "#     for i,pet_id in enumerate(batch_pets):\n",
    "#         try:\n",
    "#             batch_images[i] = load_image(\"all/train_images/\", pet_id)\n",
    "#         except:\n",
    "#             pass\n",
    "#     batch_preds = m.predict(batch_images)\n",
    "#     for i,pet_id in enumerate(batch_pets):\n",
    "#         features[pet_id] = batch_preds[i]\n",
    "\n",
    "# train_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "\n",
    "# train_feats.to_csv('test_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "# test_feats.to_csv('all/test/test_img_features.csv').csv')\n",
    "\n",
    "# test_df = pd.read_csv('all/test/test.csv')\n",
    "# pet_ids = test_df['PetID'].values\n",
    "# n_batches = len(pet_ids) // batch_size + 1\n",
    "\n",
    "# features = {}\n",
    "# for b in tqdm_notebook(range(n_batches)):\n",
    "#     start = b*batch_size\n",
    "#     end = (b+1)*batch_size\n",
    "#     batch_pets = pet_ids[start:end]\n",
    "#     batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "#     for i,pet_id in enumerate(batch_pets):\n",
    "#         try:\n",
    "#             batch_images[i] = load_image(\"all/test_images/\", pet_id)\n",
    "#         except:\n",
    "#             pass\n",
    "#     batch_preds = m.predict(batch_images)\n",
    "#     for i,pet_id in enumerate(batch_pets):\n",
    "#         features[pet_id] = batch_preds[i]\n",
    "\n",
    "# test_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "# test_feats.to_csv('all/test/test_img_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = pd.read_csv('all/train_img_features.csv')\n",
    "test_feats = pd.read_csv('all/test/test_img_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 257)\n",
      "(3948, 257)\n"
     ]
    }
   ],
   "source": [
    "print(train_feats.shape)\n",
    "print(test_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = train_feats.iloc[:, 1:]\n",
    "#train_feats = train_feats.drop(train_feats.columns[1:], axis = 1)\n",
    "#train_feats['Img_data'] = df.apply(lambda x: np.array(x), axis=1)\n",
    "#train_feats['Img_data'] = df.apply(lambda x: x.tolist(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the image features with the categorical and numerical embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787699</td>\n",
       "      <td>0.176625</td>\n",
       "      <td>0.575706</td>\n",
       "      <td>1.088627</td>\n",
       "      <td>0.439557</td>\n",
       "      <td>0.520460</td>\n",
       "      <td>1.547071</td>\n",
       "      <td>0.832572</td>\n",
       "      <td>0.599095</td>\n",
       "      <td>0.763349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628260</td>\n",
       "      <td>0.686865</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.968190</td>\n",
       "      <td>1.070276</td>\n",
       "      <td>1.545739</td>\n",
       "      <td>0.894411</td>\n",
       "      <td>0.838595</td>\n",
       "      <td>0.468236</td>\n",
       "      <td>0.916672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579116</td>\n",
       "      <td>0.557624</td>\n",
       "      <td>1.131405</td>\n",
       "      <td>0.720514</td>\n",
       "      <td>1.496672</td>\n",
       "      <td>0.870955</td>\n",
       "      <td>1.289682</td>\n",
       "      <td>1.184461</td>\n",
       "      <td>0.465113</td>\n",
       "      <td>0.892826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295853</td>\n",
       "      <td>0.326143</td>\n",
       "      <td>0.291668</td>\n",
       "      <td>1.608086</td>\n",
       "      <td>1.119176</td>\n",
       "      <td>1.470888</td>\n",
       "      <td>0.591445</td>\n",
       "      <td>0.832753</td>\n",
       "      <td>0.483021</td>\n",
       "      <td>1.134128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.092663</td>\n",
       "      <td>0.669893</td>\n",
       "      <td>0.395784</td>\n",
       "      <td>0.886075</td>\n",
       "      <td>1.219730</td>\n",
       "      <td>1.033964</td>\n",
       "      <td>1.065685</td>\n",
       "      <td>0.304053</td>\n",
       "      <td>0.438069</td>\n",
       "      <td>0.676818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2       Nibble    3     299       0       1       1       7       0   \n",
       "1     2  No Name Yet    1     265       0       1       1       2       0   \n",
       "2     1       Brisco    1     307       0       1       2       7       0   \n",
       "3     1         Miko    4     307       0       2       1       2       0   \n",
       "4     1       Hunter    1     307       0       1       1       0       0   \n",
       "\n",
       "   MaturitySize    ...          246       247       248       249       250  \\\n",
       "0             1    ...     0.787699  0.176625  0.575706  1.088627  0.439557   \n",
       "1             2    ...     0.628260  0.686865  0.563999  0.968190  1.070276   \n",
       "2             2    ...     0.579116  0.557624  1.131405  0.720514  1.496672   \n",
       "3             2    ...     1.295853  0.326143  0.291668  1.608086  1.119176   \n",
       "4             2    ...     1.092663  0.669893  0.395784  0.886075  1.219730   \n",
       "\n",
       "        251       252       253       254       255  \n",
       "0  0.520460  1.547071  0.832572  0.599095  0.763349  \n",
       "1  1.545739  0.894411  0.838595  0.468236  0.916672  \n",
       "2  0.870955  1.289682  1.184461  0.465113  0.892826  \n",
       "3  1.470888  0.591445  0.832753  0.483021  1.134128  \n",
       "4  1.033964  1.065685  0.304053  0.438069  0.676818  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(train_feats, left_on='PetID', right_on='Unnamed: 0', how='outer')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, pd.DataFrame(full_data)], axis=1, sort=False)\n",
    "test = pd.concat([test, pd.DataFrame(test_full_data)], axis=1, sort=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode tabular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train.AdoptionSpeed\n",
    "#We drop name because it creates a huge embedding vector and we know that name is not very useful anyway\n",
    "train = train.drop(['AdoptionSpeed', 'Name', 'Description', 'PetID', 'Unnamed: 0', 'RescuerID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 1275)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, train_label, test_size=TEST_SPLIT, random_state=9)\n",
    "\n",
    "#Turn labels into n dimensional vectors for loss calculation\n",
    "y_train = to_categorical(y_train, num_classes=None)\n",
    "y_test = to_categorical(y_test, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
    "        'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
    "        'Sterilized', 'Health', 'State']\n",
    "numerical_vars = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(X_train, X_test, embed_cols, num_cols):\n",
    "\n",
    "    input_list_train = []\n",
    "    input_list_test = []\n",
    "    m= MinMaxScaler()\n",
    "        \n",
    "    #the cols to be embedded: rescaling to range [0, # values)\n",
    "    for c in embed_cols:\n",
    "        raw_vals = np.unique(X_train[c])\n",
    "        val_map = {}\n",
    "        for i in range(len(raw_vals)):\n",
    "            val_map[raw_vals[i]] = i       \n",
    "        m.fit(X_train[c].map(val_map).values.reshape(-1, 1))\n",
    "        input_list_train.append(m.transform(X_train[c].map(val_map).values.reshape(-1, 1)))\n",
    "        \n",
    "        m.fit(X_test[c].map(val_map).fillna(0).values.reshape(-1, 1))\n",
    "        input_list_test.append(m.transform(X_test[c].map(val_map).fillna(0).values.reshape(-1, 1)))\n",
    "        \n",
    "    #the numerical columns\n",
    "    m.fit(X_train[num_cols].values)\n",
    "    input_list_train.append(m.transform(X_train[num_cols].values))\n",
    "    \n",
    "    m.fit(X_test[num_cols].values)\n",
    "    input_list_test.append(m.transform(X_test[num_cols].values))\n",
    "    \n",
    "    #img data\n",
    "    input_list_train.append(X_train.iloc[:, 19:275].as_matrix())\n",
    "    input_list_test.append(X_test.iloc[:, 19:275].as_matrix())\n",
    "    \n",
    "    #text data\n",
    "    input_list_train.append(X_train.iloc[:, 275:].as_matrix())\n",
    "    input_list_test.append(X_test.iloc[:, 275:].as_matrix())\n",
    "    \n",
    "    return input_list_train, input_list_test\n",
    "\n",
    "\n",
    "#Creating a Embedding model for categorical variables using the fast.ai approach\n",
    "def createModel(data, categorical_vars, numerical_vars):\n",
    "    embeddings = []\n",
    "    inputs = []\n",
    "    for categorical_var in categorical_vars :\n",
    "        i = Input(shape=(1,))\n",
    "        model = Sequential()\n",
    "        no_of_unique_cat  = data[categorical_var].nunique()\n",
    "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "        embedding_size = int(embedding_size)\n",
    "        vocab  = no_of_unique_cat+1\n",
    "        embedding = Embedding(vocab ,embedding_size, input_length = 1 )(i)\n",
    "        embedding = Reshape(target_shape=(embedding_size,))(embedding)\n",
    "        embeddings.append( embedding )\n",
    "        inputs.append(i)\n",
    "        \n",
    "    input_numeric = Input(shape=(len(numerical_vars),))\n",
    "    embedding_numeric = Dense(16)(input_numeric) \n",
    "    \n",
    "    \n",
    "    inputs.append(input_numeric)\n",
    "    embeddings.append(embedding_numeric)\n",
    "    \n",
    "    x = Concatenate()(embeddings)\n",
    "    x = Dense(40, activation='relu')(x)\n",
    "    x = Dropout(.25)(x)\n",
    "    \n",
    "    #hardcoded for now\n",
    "    image_input = Input(shape=(256,))\n",
    "    inputs.append(image_input)\n",
    "    \n",
    "    y = Dense(80, activation='relu')(image_input)    \n",
    "    y = Dense(40, activation='relu')(y)\n",
    "    y = Dropout(.25)(y)\n",
    "    \n",
    "    #Words\n",
    "    w = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    inputs.append(w)\n",
    "    w = embedding_layer(w)\n",
    "    w = Bidirectional(LSTM(40, recurrent_dropout=0.3))(w)\n",
    "    \n",
    "    z = Concatenate()([x, y, w])\n",
    "    \n",
    "    z = Dense(20, activation='relu')(z)\n",
    "    z = Dense(30, activation='relu')(z)\n",
    "    \n",
    "    output = Dense(5, activation='softmax')(z)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    model.compile(metrics=['categorical_accuracy'], loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "X_train, X_test = preproc(X_train, X_test, categorical_vars, numerical_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 1)         3           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 50)        8850        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 50)        6800        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 2)         8           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 4)         32          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 4)         32          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 3)         21          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 2)         10          input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 2)         8           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 2)         8           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1, 2)         8           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1, 2)         8           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 2)         8           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 7)         105         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 50)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 50)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 2)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 4)            0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 4)            0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 3)            0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 2)            0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 2)            0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 2)            0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 2)            0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 2)            0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 2)            0           embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 7)            0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           96          input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 149)          0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "                                                                 reshape_12[0][0]                 \n",
      "                                                                 reshape_13[0][0]                 \n",
      "                                                                 reshape_14[0][0]                 \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           20560       input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 40)           6000        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 40)           3240        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    2181100     input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 40)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 40)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 80)           45120       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 160)          0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 20)           3220        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           630         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 5)            155         dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,276,022\n",
      "Trainable params: 94,922\n",
      "Non-trainable params: 2,181,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = createModel(train, categorical_vars, numerical_vars)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"checkpoints/weights_image_text_categorical.hdf6\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "earlystopped = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.0001, patience=10, verbose=0, mode='max')\n",
    "#callbacks_list = [checkpoint, earlystopped]\n",
    "callbacks_list = [checkpoint, earlystopped]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 5997 samples\n",
      "Epoch 1/40\n",
      "5997/5997 [==============================] - 333s 55ms/step - loss: 1.4808 - categorical_accuracy: 0.2718 - val_loss: 1.4673 - val_categorical_accuracy: 0.2848\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.28481, saving model to weights_image_text_categorical.hdf6\n",
      "Epoch 2/40\n",
      "5997/5997 [==============================] - 331s 55ms/step - loss: 1.4429 - categorical_accuracy: 0.3177 - val_loss: 1.4420 - val_categorical_accuracy: 0.3085\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.28481 to 0.30849, saving model to weights_image_text_categorical.hdf6\n",
      "Epoch 3/40\n",
      "5997/5997 [==============================] - 332s 55ms/step - loss: 1.4150 - categorical_accuracy: 0.3488 - val_loss: 1.4202 - val_categorical_accuracy: 0.3285\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.30849 to 0.32850, saving model to weights_image_text_categorical.hdf6\n",
      "Epoch 4/40\n",
      "5997/5997 [==============================] - 332s 55ms/step - loss: 1.3843 - categorical_accuracy: 0.3722 - val_loss: 1.4228 - val_categorical_accuracy: 0.3273\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.32850\n",
      "Epoch 5/40\n",
      "5997/5997 [==============================] - 331s 55ms/step - loss: 1.3730 - categorical_accuracy: 0.3809 - val_loss: 1.3921 - val_categorical_accuracy: 0.3588\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.32850 to 0.35885, saving model to weights_image_text_categorical.hdf6\n",
      "Epoch 6/40\n",
      "5997/5997 [==============================] - 314s 52ms/step - loss: 1.3528 - categorical_accuracy: 0.3957 - val_loss: 1.3850 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.35885 to 0.37502, saving model to weights_image_text_categorical.hdf6\n",
      "Epoch 7/40\n",
      "5997/5997 [==============================] - 311s 52ms/step - loss: 1.3402 - categorical_accuracy: 0.4062 - val_loss: 1.3831 - val_categorical_accuracy: 0.3770\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.37502 to 0.37702, saving model to weights_image_text_categorical.hdf6\n",
      "Epoch 8/40\n",
      "5997/5997 [==============================] - 316s 53ms/step - loss: 1.3168 - categorical_accuracy: 0.4270 - val_loss: 1.3793 - val_categorical_accuracy: 0.3759\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.37702\n",
      "Epoch 9/40\n",
      "5997/5997 [==============================] - 315s 53ms/step - loss: 1.2954 - categorical_accuracy: 0.4456 - val_loss: 1.4508 - val_categorical_accuracy: 0.3603\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.37702\n",
      "Epoch 10/40\n",
      "5997/5997 [==============================] - 312s 52ms/step - loss: 1.2894 - categorical_accuracy: 0.4461 - val_loss: 1.3748 - val_categorical_accuracy: 0.3825\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.37702 to 0.38252, saving model to weights_image_text_categorical.hdf6\n",
      "Epoch 11/40\n",
      "5997/5997 [==============================] - 320s 53ms/step - loss: 1.2619 - categorical_accuracy: 0.4692 - val_loss: 1.3958 - val_categorical_accuracy: 0.3754\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.38252\n",
      "Epoch 12/40\n",
      "3712/5997 [=================>............] - ETA: 1:33 - loss: 1.2570 - categorical_accuracy: 0.4655"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-6183d7dcf62d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m hist = model.fit(X_train, y_train, batch_size=64 ,epochs=40, validation_split=VALIDATION_SPLIT, \n\u001b[1;32m----> 2\u001b[1;33m                  shuffle=True, callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\nikhil\\anaconda3\\envs\\mlmonkey\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\nikhil\\anaconda3\\envs\\mlmonkey\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikhil\\anaconda3\\envs\\mlmonkey\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikhil\\anaconda3\\envs\\mlmonkey\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikhil\\anaconda3\\envs\\mlmonkey\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=64 ,epochs=40, validation_split=VALIDATION_SPLIT, \n",
    "                 shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-526b7b67dcf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.legend(['acc', 'val_acc'])\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate our test set and find out Cohen's  quadratic weighte kappa for both Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2999/2999 [==============================] - 84s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3801803194152868, 0.38146048680906813]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26952449758979513"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict(X_test)\n",
    "kappa(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35451363747536924"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = model.predict(X_train)\n",
    "kappa(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load out best model and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'checkpoints/weights_image_text_categorical.hdf6', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-05a1bf9bdeeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'checkpoints/weights_image_text_categorical.hdf6'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkappa\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikhil\\anaconda3\\envs\\mlmonkey\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikhil\\anaconda3\\envs\\mlmonkey\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikhil\\anaconda3\\envs\\mlmonkey\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'checkpoints/weights_image_text_categorical.hdf6', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model.load_weights('checkpoints/weights_image_text_categorical.hdf6')\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "kappa(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44229078933665955"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = model.predict(X_train)\n",
    "kappa(y_train, train_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
