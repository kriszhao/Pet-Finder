{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 168,
>>>>>>> zekun
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import cohen_kappa_score as kappa_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "kappa_scorer = make_scorer(kappa_score)\n",
    "from keras.constraints import maxnorm\n",
    "import os\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import concatenate\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout, Dense, np\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 169,
>>>>>>> zekun
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/all/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/all/test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 170,
>>>>>>> zekun
   "metadata": {
    "_uuid": "ef5d56c772b4442e32b2637e94141cb09ac70751"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>RescuerID</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PetID</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>41326</td>\n",
       "      <td>8480853f516546f6cf33aa88cd76c379</td>\n",
       "      <td>0</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>86e1089a3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>6296e909a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>3422e4906</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>41401</td>\n",
       "      <td>9238e4f44c71a75282e62f7136c6b240</td>\n",
       "      <td>0</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>5842f1ff5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>850a43f90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2       Nibble    3     299       0       1       1       7       0   \n",
       "1     2  No Name Yet    1     265       0       1       1       2       0   \n",
       "2     1       Brisco    1     307       0       1       2       7       0   \n",
       "3     1         Miko    4     307       0       2       1       2       0   \n",
       "4     1       Hunter    1     307       0       1       1       0       0   \n",
       "\n",
       "   MaturitySize  ...  Health  Quantity  Fee  State  \\\n",
       "0             1  ...       1         1  100  41326   \n",
       "1             2  ...       1         1    0  41401   \n",
       "2             2  ...       1         1    0  41326   \n",
       "3             2  ...       1         1  150  41401   \n",
       "4             2  ...       1         1    0  41326   \n",
       "\n",
       "                          RescuerID  VideoAmt  \\\n",
       "0  8480853f516546f6cf33aa88cd76c379         0   \n",
       "1  3082c7125d8fb66f7dd4bff4192c8b14         0   \n",
       "2  fa90fa5b1ee11c86938398b60abc32cb         0   \n",
       "3  9238e4f44c71a75282e62f7136c6b240         0   \n",
       "4  95481e953f8aed9ec3d16fc4509537e8         0   \n",
       "\n",
       "                                         Description      PetID PhotoAmt  \\\n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3      1.0   \n",
       "1  I just found it alone yesterday near my apartm...  6296e909a      2.0   \n",
       "2  Their pregnant mother was dumped by her irresp...  3422e4906      7.0   \n",
       "3  Good guard dog, very alert, active, obedience ...  5842f1ff5      8.0   \n",
       "4  This handsome yet cute boy is up for adoption....  850a43f90      3.0   \n",
       "\n",
       "   AdoptionSpeed  \n",
       "0              2  \n",
       "1              0  \n",
       "2              3  \n",
       "3              2  \n",
       "4              2  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 5,
=======
     "execution_count": 170,
>>>>>>> zekun
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 171,
>>>>>>> zekun
   "metadata": {
    "_uuid": "1f3134cdea8d875a07091109a7dd346cb6a4fa75"
   },
   "outputs": [],
<<<<<<< HEAD
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
   "source": [
    "cat_cols = ['Type','Age','Breed1','Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', \n",
    "          'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized','Health', 'Quantity','State','PhotoAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
>>>>>>> zekun
   "metadata": {
    "_uuid": "17ae5c7fc86c5fe1cae9fae501bfb55197ec73ca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 353,
=======
   "execution_count": 173,
>>>>>>> zekun
   "metadata": {
    "_uuid": "9a97f8dc0cf912e766d0d5e9d81c2676fc2549dd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a2628badb9b1f04cffca6d30b81f45c59227f94"
   },
   "source": [
    "## Handling categorical columns"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 354,
=======
   "execution_count": 174,
>>>>>>> zekun
   "metadata": {
    "_uuid": "0afaf139a012943cb6d03deb4cfa2fcc9b9a16ed"
   },
   "outputs": [],
   "source": [
    "embed_sizes = [len(train_df[col].unique()) + 1 for col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 135,
=======
   "execution_count": 175,
>>>>>>> zekun
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 107, 177, 136, 4, 8, 8, 7, 5, 4, 4, 4, 4, 4, 20, 15, 32]\n"
     ]
    }
   ],
   "source": [
    "print(embed_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7cca9a5c04d10a9c37ba1e9ae8b9a638484c2e55"
   },
   "source": [
    "## Handling numerical columns"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 259,
=======
   "execution_count": 176,
>>>>>>> zekun
   "metadata": {
    "_uuid": "b05f8395653cc9e4592327fb66ed58f7035349c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling num_cols\n",
      "scaling Fee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "print('scaling num_cols')\n",
    "for col in num_cols:\n",
    "    print('scaling {}'.format(col))\n",
    "    col_mean = train_df[col].mean()\n",
    "    train_df[col].fillna(col_mean, inplace=True)\n",
    "    test_df[col].fillna(col_mean, inplace=True)\n",
    "    scaler = StandardScaler()\n",
    "    train_df[col] = scaler.fit_transform(train_df[col].values.reshape(-1, 1))\n",
    "    test_df[col] = scaler.transform(test_df[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {},
=======
   "execution_count": 101,
   "metadata": {
    "_uuid": "a561a4e861fcafd2760ecd2c23c4489ac5fecf85"
   },
>>>>>>> zekun
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 281,
   "metadata": {},
=======
   "execution_count": 41,
   "metadata": {
    "_uuid": "f613316747775cf123e090079e8fb87472e94285"
   },
>>>>>>> zekun
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "1289it [00:00, 12849.76it/s]"
=======
      "1106it [00:00, 11053.92it/s]"
>>>>>>> zekun
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "1000000it [01:19, 12508.26it/s]\n"
=======
      "1000000it [01:22, 12085.05it/s]\n"
>>>>>>> zekun
     ]
    }
   ],
   "source": [
    "print('getting embeddings')\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in tqdm(open('//Users/zekunzhao/Downloads/wiki-news-300d-1M-subword.vec')))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 313,
   "metadata": {},
=======
   "execution_count": 127,
   "metadata": {
    "_uuid": "a9265461a9d4fb775ccee06dd08b0f4f10b7057e"
   },
>>>>>>> zekun
   "outputs": [],
   "source": [
    "num_words = 20000\n",
    "maxlen = 80\n",
<<<<<<< HEAD
    "embed_size = 300\n",
=======
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "_uuid": "abf3715d1ac826cd72c9656580b40617c8ba5fc6"
   },
   "outputs": [],
   "source": [
>>>>>>> zekun
    "train_df['Description'] = train_df['Description'].astype(str).fillna('no text')\n",
    "test_df['Description'] = test_df['Description'].astype(str).fillna('no text')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 314,
   "metadata": {},
=======
   "execution_count": 129,
   "metadata": {
    "_uuid": "8de1d2c7b25c3f94b8816b2d839b9ca5a7723e88"
   },
>>>>>>> zekun
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fitting tokenizer...\n"
     ]
    }
   ],
   "source": [
    "print(\"   Fitting tokenizer...\")\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
<<<<<<< HEAD
    "tokenizer.fit_on_texts(train_df['Description'].values.tolist())\n",
=======
    "tokenizer.fit_on_texts(train_df['Description'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "_uuid": "09501dbc242aa63863ae78989f5fbf613a60c148"
   },
   "outputs": [],
   "source": [
>>>>>>> zekun
    "train_df['Description'] = tokenizer.texts_to_sequences(train_df['Description'])\n",
    "test_df['Description'] = tokenizer.texts_to_sequences(test_df['Description'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 315,
   "metadata": {},
=======
   "execution_count": 131,
   "metadata": {
    "_uuid": "6d5bfc3b6dfa04e5723ed9c1ee5a027849aab513"
   },
>>>>>>> zekun
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(num_words, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= num_words: continue\n",
    "    try:\n",
    "        embedding_vector = embeddings_index[word]\n",
    "    except KeyError:\n",
    "        embedding_vector = None\n",
<<<<<<< HEAD
    "    if embedding_vector is not None: embedding_matrix[i-1] = embedding_vector"
=======
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "_uuid": "d9c4764bb94b0d5a65b28b02040c47e562471d8f"
   },
   "outputs": [],
   "source": [
    "def get_input_features(df):\n",
    "    X = {'description':pad_sequences(df['Description'], maxlen=maxlen)}\n",
    "    X['numerical'] = np.array(df[num_cols])\n",
    "    for cat in cat_cols:\n",
    "        X[cat] = np.array(df[cat])\n",
    "    return X"
>>>>>>> zekun
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68c7d6bd517854b1adf9fdb5ee15bc493e95d295"
   },
   "source": [
    "## Define NN Model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 177,
>>>>>>> zekun
   "metadata": {
    "_uuid": "5b6b71a4869aef86857014827789eed549c0c022"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Concatenate, Flatten, Dense, Dropout, BatchNormalization,LSTM, CuDNNLSTM, SpatialDropout1D\n",
    "from keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
<<<<<<< HEAD
    "from keras.optimizers import  Adam"
=======
    "from keras.optimizers import  Adam\n",
    "\n",
    "def prepare_data(data):\n",
    "    pet_id = data.PetID\n",
    "\n",
    "    # Remove unused features\n",
    "    data.drop(['RescuerID', 'Description', 'PetID', 'State'], axis=1, inplace=True)\n",
    "\n",
    "    # Apply binning to ages\n",
    "    data['Age'] = pd.cut(data['Age'], [-1, 2, 3, 6, 255], labels=[0, 1, 2, 3])\n",
    "\n",
    "    # Apply binning to fee\n",
    "    data['Fee'] = pd.cut(data['Fee'], [-1, 50, 100, 200, 3000], labels=[0, 1, 2, 3])\n",
    "\n",
    "    # Apply binning to photo amount\n",
    "    data['PhotoAmt'] = pd.cut(data['PhotoAmt'], [-1, 1, 5, 10, 100], labels=[0, 1, 2, 3])\n",
    "\n",
    "    # Apply binning to video amount\n",
    "    data['VideoAmt'] = pd.cut(data['VideoAmt'], [-1, 1, 100], labels=[0, 1])\n",
    "\n",
    "    # Replace names with 1 is present, 0 if not present\n",
    "    data.loc[data['Name'].notnull(), 'Name'] = 1\n",
    "    data.loc[data['Name'].isnull(), 'Name'] = 0\n",
    "\n",
    "    # Fill missing continuous data\n",
    "    data_continuous = data.select_dtypes(exclude=['object'])\n",
    "    data_continuous.fillna(0, inplace=True)\n",
    "\n",
    "    # Fill missing string data\n",
    "    data_categorical = data.select_dtypes(include=['object'])\n",
    "    data_categorical.fillna('NONE', inplace=True)\n",
    "\n",
    "    final_data = data_continuous.merge(data_categorical, left_index=True, right_index=True)\n",
    "\n",
    "    return final_data, data_categorical, data_continuous, pet_id, data.shape[1]\n",
    "\n",
    "\n",
    "categorical_inputs = []\n",
    "for cat in cat_cols:\n",
    "    categorical_inputs.append(Input(shape=[1], name=cat))\n",
    "\n",
    "categorical_embeddings = []\n",
    "for i, cat in enumerate(cat_cols):\n",
    "    categorical_embeddings.append(\n",
    "        Embedding(embed_sizes[i], 10)(categorical_inputs[i]))\n",
    "\n",
    "categorical_logits = Concatenate()([Flatten()(cat_emb) for cat_emb in categorical_embeddings])\n",
    "categorical_logits = Dense(256, activation = 'relu')(categorical_logits)\n",
    "\n",
    "\n",
    "numerical_inputs = Input(shape=[len(num_cols)], name='numerical')\n",
    "numerical_logits = numerical_inputs\n",
    "numerical_logits = BatchNormalization()(numerical_logits)\n",
    "numerical_logits = Dense(128, activation = 'relu')(numerical_logits)\n",
    "\n",
    "text_inp = Input(shape=[maxlen], name='description')\n",
    "text_embed = Embedding(nb_words, embed_size, weights=[embedding_matrix], trainable=False)(text_inp)\n",
    "text_logits = SpatialDropout1D(0.2)(text_embed)\n",
    "text_logits = Bidirectional(LSTM(64, return_sequences=True))(text_logits)\n",
    "avg_pool = GlobalAveragePooling1D()(text_logits)\n",
    "max_pool = GlobalMaxPool1D()(text_logits)\n",
    "text_logits = Concatenate()([avg_pool, max_pool])\n",
    "\n",
    "x = Concatenate()([categorical_logits, text_logits, numerical_logits])\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "out = Dense(5, activation = 'sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[text_inp] + categorical_inputs + [numerical_inputs],outputs=out)\n",
    "model.compile(optimizer=Adam(lr = 0.0001), loss = 'mse')\n"
>>>>>>> zekun
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
>>>>>>> zekun
   "metadata": {
    "_uuid": "7bf00ec907fa08fe47ef7a36d297736a8eb98aa3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
<<<<<<< HEAD
    "# train_df['AdoptionSpeed'].values[train_df['AdoptionSpeed'].values < 3] = 0;\n",
    "# train_df['AdoptionSpeed'].values[train_df['AdoptionSpeed'].values == 4] = 2;\n",
    "# train_df['AdoptionSpeed'].values[train_df['AdoptionSpeed'].values == 3] = 1;\n",
    "tr_df, val_df = train_test_split(train_df, test_size = 0.5, random_state = 4)"
=======
    "\n",
    "#for i, l in enumerate(tr_df['AdoptionSpeed'].values):\n",
    "#    y_train[i,l] = 1\n",
    "#for i, l in enumerate(val_df['AdoptionSpeed'].values):\n",
    "#    y_valid[i,l] = 1\n",
    "# train_df, noused_df = train_test_split(train_df, test_size = 0.6, random_state = 23)\n",
    "tr_df, val_df = train_test_split(train_df, test_size = 0.33, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "_uuid": "beb7737cd9a56e2616e0fcf7c415d52433f1f0da"
   },
   "outputs": [],
   "source": [
    "# from keras.utils.np_utils import to_categorical"
>>>>>>> zekun
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5996 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "5996/5996 [==============================] - 0s 40us/step - loss: 0.2318 - acc: 0.1788 - val_loss: 0.2097 - val_acc: 0.1907\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.19067, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 2/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1997 - acc: 0.2050 - val_loss: 0.1876 - val_acc: 0.1987\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.19067 to 0.19867, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 3/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1813 - acc: 0.2100 - val_loss: 0.1749 - val_acc: 0.2087\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.19867 to 0.20867, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 4/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1708 - acc: 0.2262 - val_loss: 0.1671 - val_acc: 0.2193\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.20867 to 0.21933, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 5/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1635 - acc: 0.2548 - val_loss: 0.1605 - val_acc: 0.2560\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.21933 to 0.25600, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 6/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1576 - acc: 0.2872 - val_loss: 0.1554 - val_acc: 0.2860\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.25600 to 0.28600, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 7/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1531 - acc: 0.3139 - val_loss: 0.1520 - val_acc: 0.2967\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.28600 to 0.29667, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 8/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1502 - acc: 0.3344 - val_loss: 0.1500 - val_acc: 0.3287\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.29667 to 0.32867, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 9/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1483 - acc: 0.3439 - val_loss: 0.1488 - val_acc: 0.3207\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.32867\n",
      "Epoch 10/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1472 - acc: 0.3526 - val_loss: 0.1483 - val_acc: 0.3287\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.32867\n",
      "Epoch 11/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1464 - acc: 0.3604 - val_loss: 0.1479 - val_acc: 0.3440\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.32867 to 0.34400, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 12/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1461 - acc: 0.3626 - val_loss: 0.1473 - val_acc: 0.3420\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.34400\n",
      "Epoch 13/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1452 - acc: 0.3686 - val_loss: 0.1471 - val_acc: 0.3520\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.34400 to 0.35200, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 14/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1449 - acc: 0.3691 - val_loss: 0.1472 - val_acc: 0.3500\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.35200\n",
      "Epoch 15/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1442 - acc: 0.3754 - val_loss: 0.1465 - val_acc: 0.3600\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.35200 to 0.36000, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 16/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1439 - acc: 0.3771 - val_loss: 0.1466 - val_acc: 0.3547\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.36000\n",
      "Epoch 17/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1434 - acc: 0.3814 - val_loss: 0.1463 - val_acc: 0.3613\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.36000 to 0.36133, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 18/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1430 - acc: 0.3811 - val_loss: 0.1468 - val_acc: 0.3573\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.36133\n",
      "Epoch 19/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1429 - acc: 0.3829 - val_loss: 0.1459 - val_acc: 0.3640\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.36133 to 0.36400, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 20/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1426 - acc: 0.3863 - val_loss: 0.1463 - val_acc: 0.3700\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.36400 to 0.37000, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 21/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1421 - acc: 0.3964 - val_loss: 0.1457 - val_acc: 0.3627\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.37000\n",
      "Epoch 22/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1418 - acc: 0.3951 - val_loss: 0.1458 - val_acc: 0.3673\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.37000\n",
      "Epoch 23/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1422 - acc: 0.3936 - val_loss: 0.1456 - val_acc: 0.3660\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.37000\n",
      "Epoch 24/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1415 - acc: 0.3986 - val_loss: 0.1459 - val_acc: 0.3640\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.37000\n",
      "Epoch 25/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1414 - acc: 0.3974 - val_loss: 0.1455 - val_acc: 0.3727\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.37000 to 0.37267, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 26/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1410 - acc: 0.3986 - val_loss: 0.1454 - val_acc: 0.3640\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.37267\n",
      "Epoch 27/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1409 - acc: 0.3984 - val_loss: 0.1452 - val_acc: 0.3673\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.37267\n",
      "Epoch 28/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1406 - acc: 0.4044 - val_loss: 0.1452 - val_acc: 0.3767\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.37267 to 0.37667, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 29/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1403 - acc: 0.4024 - val_loss: 0.1452 - val_acc: 0.3700\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.37667\n",
      "Epoch 30/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1405 - acc: 0.4021 - val_loss: 0.1451 - val_acc: 0.3773\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.37667 to 0.37733, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 31/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1400 - acc: 0.4054 - val_loss: 0.1452 - val_acc: 0.3767\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.37733\n",
      "Epoch 32/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1398 - acc: 0.4069 - val_loss: 0.1450 - val_acc: 0.3727\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.37733\n",
      "Epoch 33/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1399 - acc: 0.4103 - val_loss: 0.1462 - val_acc: 0.3753\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.37733\n",
      "Epoch 34/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1395 - acc: 0.4126 - val_loss: 0.1454 - val_acc: 0.3693\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.37733\n",
      "Epoch 35/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1393 - acc: 0.4153 - val_loss: 0.1450 - val_acc: 0.3793\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.37733 to 0.37933, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 36/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1391 - acc: 0.4124 - val_loss: 0.1458 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.37933\n",
      "Epoch 37/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1395 - acc: 0.4188 - val_loss: 0.1458 - val_acc: 0.3733\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.37933\n",
      "Epoch 38/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1389 - acc: 0.4183 - val_loss: 0.1450 - val_acc: 0.3713\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.37933\n",
      "Epoch 39/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1385 - acc: 0.4199 - val_loss: 0.1450 - val_acc: 0.3733\n"
     ]
    },
=======
   "execution_count": 180,
   "metadata": {
    "_uuid": "ccc902b5c62afceca9159762813d525cc5d2482e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10045,)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df['AdoptionSpeed'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>RescuerID</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PetID</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13507</th>\n",
       "      <td>2</td>\n",
       "      <td>Missy, Bobtailed Kitten</td>\n",
       "      <td>4</td>\n",
       "      <td>266</td>\n",
       "      <td>249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>5aca30a29e8290093fee2a334d65d835</td>\n",
       "      <td>0</td>\n",
       "      <td>If you love bob-tailed kitties, then how about...</td>\n",
       "      <td>4693e646e</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10594</th>\n",
       "      <td>2</td>\n",
       "      <td>Sneaky, Playful, Calmie, Adventura</td>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>bd646cb96f00a7c5bff955a4084872fc</td>\n",
       "      <td>0</td>\n",
       "      <td>Their mother came to us few months ago, she wa...</td>\n",
       "      <td>45afc38e4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>7b107e61f7d24a581e46e0abc4d2a7a7</td>\n",
       "      <td>0</td>\n",
       "      <td>Found this cutie at the Putrajaya Sentral car ...</td>\n",
       "      <td>69262e404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6321</th>\n",
       "      <td>1</td>\n",
       "      <td>Kruppy</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>d4a8b5e64cd89e2f055b505383a8ee7a</td>\n",
       "      <td>0</td>\n",
       "      <td>[On trial adoption] Pics 1-5 with credits to O...</td>\n",
       "      <td>df17a57ae</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12323</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>abe54643224ddbb5c199cd46fbca0392</td>\n",
       "      <td>0</td>\n",
       "      <td>3 cute and playful kitties 2 months old for fr...</td>\n",
       "      <td>08ee62d43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8052</th>\n",
       "      <td>1</td>\n",
       "      <td>Xiao Ke</td>\n",
       "      <td>6</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41327</td>\n",
       "      <td>4e9f9a3804795b86c27dd86f7fe05029</td>\n",
       "      <td>0</td>\n",
       "      <td>A dog that dumped by owner at market. Pls gv h...</td>\n",
       "      <td>87a679d31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>2</td>\n",
       "      <td>Little Red Bean</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>93dfc7e5d65f9772958c411eb3a8b53f</td>\n",
       "      <td>0</td>\n",
       "      <td>Little Red Bean is still waiting for her forev...</td>\n",
       "      <td>f205b0649</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13732</th>\n",
       "      <td>1</td>\n",
       "      <td>DELIGHTFUL PUPPIES!</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>9dc662ce3243365c173dc9029aad6989</td>\n",
       "      <td>0</td>\n",
       "      <td>Here are 4 beautiful puppies for adoption! The...</td>\n",
       "      <td>a07a65495</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1</td>\n",
       "      <td>--Shiro--</td>\n",
       "      <td>9</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41327</td>\n",
       "      <td>c2e496d5b05dc9771f234e168465b389</td>\n",
       "      <td>0</td>\n",
       "      <td>A white mixed breed dog looking for adoption. ...</td>\n",
       "      <td>9c580ca06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9366</th>\n",
       "      <td>2</td>\n",
       "      <td>Max And Bobby</td>\n",
       "      <td>3</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>1004c35eccb48a99a16726b45f0d7baa</td>\n",
       "      <td>0</td>\n",
       "      <td>dua2 ni adik beradik..comel,sihat and cergas.....</td>\n",
       "      <td>fecec878e</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11752</th>\n",
       "      <td>2</td>\n",
       "      <td>AJ</td>\n",
       "      <td>18</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>f529803bddfac1cacf9be19b32c9a523</td>\n",
       "      <td>0</td>\n",
       "      <td>This is AJ. He is a very handsome, warm and lo...</td>\n",
       "      <td>9edf8fff1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>2</td>\n",
       "      <td>Hiro</td>\n",
       "      <td>6</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41327</td>\n",
       "      <td>58129f5a444ddda87cd0afe50e6b4773</td>\n",
       "      <td>0</td>\n",
       "      <td>Male kitten needing a forever home. He's very ...</td>\n",
       "      <td>a2a04b6e4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7894</th>\n",
       "      <td>2</td>\n",
       "      <td>Ramone</td>\n",
       "      <td>12</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>c00756f2bdd8fa88fc9f07a8309f7d5d</td>\n",
       "      <td>0</td>\n",
       "      <td>Ramone is very soft and sweet and beautiful. H...</td>\n",
       "      <td>beb658bc0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6886</th>\n",
       "      <td>1</td>\n",
       "      <td>Save Me Or I'll Die #26</td>\n",
       "      <td>12</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>ee2747ce26468ec44c7194e7d1d9dad9</td>\n",
       "      <td>0</td>\n",
       "      <td>PLEASE RESCUE/ADOPT ME FROM KLANG POUND OR I W...</td>\n",
       "      <td>5e696928a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6824</th>\n",
       "      <td>1</td>\n",
       "      <td>Ã¢ÂœÂª OLIVIA Ã¢ÂœÂª</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.192474</td>\n",
       "      <td>41336</td>\n",
       "      <td>d73b10f170720b7edc3c12fc93b1fc63</td>\n",
       "      <td>0</td>\n",
       "      <td>Adoption fee includes the basic medical expens...</td>\n",
       "      <td>742cced96</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8331</th>\n",
       "      <td>2</td>\n",
       "      <td>Blu</td>\n",
       "      <td>48</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>82a32b0880e7b35ae5133945a67e90a7</td>\n",
       "      <td>0</td>\n",
       "      <td>I will be moving to Australia soon and I am lo...</td>\n",
       "      <td>24fad6b0b</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6387</th>\n",
       "      <td>2</td>\n",
       "      <td>Playful Kitty (spayed 1 Year Old)</td>\n",
       "      <td>12</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>efa9a4be1e2e903503540f01db1766f3</td>\n",
       "      <td>0</td>\n",
       "      <td>Macy is a spayed 1 year old rescued female. Sm...</td>\n",
       "      <td>45ba264f2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10579</th>\n",
       "      <td>1</td>\n",
       "      <td>Blackies</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>c13802ffd2e87ef97bba5f7b3d8ea3d7</td>\n",
       "      <td>1</td>\n",
       "      <td>A friendly mother dog, found her abandoned/los...</td>\n",
       "      <td>3b0238af8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10213</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>c0637f196649469caecd5210a9b12874</td>\n",
       "      <td>0</td>\n",
       "      <td>He got a pair of beautiful eyes, sharp figures...</td>\n",
       "      <td>84b297843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14981</th>\n",
       "      <td>1</td>\n",
       "      <td>Patch</td>\n",
       "      <td>8</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>001e42763024f9d4abe31e79472b1827</td>\n",
       "      <td>0</td>\n",
       "      <td>Patch is for free adoption. If you want to ado...</td>\n",
       "      <td>23874f644</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>2</td>\n",
       "      <td>Twinky And Oringa-</td>\n",
       "      <td>3</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>844018bf488f35cfa490c6307f710309</td>\n",
       "      <td>0</td>\n",
       "      <td>Two Kittens: Twinky(girl ) and Oringa(Boy) is ...</td>\n",
       "      <td>915f0b42a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9202</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>f4d07514e4efa1233908cab099829910</td>\n",
       "      <td>0</td>\n",
       "      <td>Was found wandering around the neighborhood wi...</td>\n",
       "      <td>bb928145e</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10596</th>\n",
       "      <td>1</td>\n",
       "      <td>Dopey</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>1a2113010d6048d5410b265347b35c91</td>\n",
       "      <td>0</td>\n",
       "      <td>*Adoption fee is a donation of your choice* Do...</td>\n",
       "      <td>a54202bba</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13267</th>\n",
       "      <td>2</td>\n",
       "      <td>Domestic Tabby Kitten</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>540a712eacd464a4e752151db85588e7</td>\n",
       "      <td>0</td>\n",
       "      <td>It happened that I found this cat hidden on ca...</td>\n",
       "      <td>1498a5e81</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>1</td>\n",
       "      <td>BUBU</td>\n",
       "      <td>72</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>8edfd19b404ab7c171ae024cf7cb51bf</td>\n",
       "      <td>0</td>\n",
       "      <td>we found the dog when jogging around broga are...</td>\n",
       "      <td>4a311c6dc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>1</td>\n",
       "      <td>Sugee</td>\n",
       "      <td>1</td>\n",
       "      <td>218</td>\n",
       "      <td>307</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n",
       "      <td>0</td>\n",
       "      <td>Lovely puppy looking for a home sweet home. Co...</td>\n",
       "      <td>86d203b94</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10626</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>78</td>\n",
       "      <td>307</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>c852f96558b98f87a444c8eda0da1604</td>\n",
       "      <td>0</td>\n",
       "      <td>It's a pet currently stay in my home looking f...</td>\n",
       "      <td>8cae4a15b</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>1</td>\n",
       "      <td>Lily</td>\n",
       "      <td>48</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>5fc4f48cf3213a83d0d571f584487f08</td>\n",
       "      <td>0</td>\n",
       "      <td>Golden retriver cross. Shy with strangers, but...</td>\n",
       "      <td>ddf06fabf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>1</td>\n",
       "      <td>Yenny</td>\n",
       "      <td>6</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n",
       "      <td>0</td>\n",
       "      <td>Yenny is a very humble and obedient girl. She ...</td>\n",
       "      <td>37d88b689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13141</th>\n",
       "      <td>1</td>\n",
       "      <td>Poppy</td>\n",
       "      <td>84</td>\n",
       "      <td>103</td>\n",
       "      <td>307</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>1112a5e33e8557701cc8a1395d0921d3</td>\n",
       "      <td>0</td>\n",
       "      <td>She was abandoned by owner. Personality and qu...</td>\n",
       "      <td>d8179f4d9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12222</th>\n",
       "      <td>1</td>\n",
       "      <td>Poor Baby</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>500c48db7b281eabec3c293160f4a71c</td>\n",
       "      <td>0</td>\n",
       "      <td>On behalf of Exotica Pets Healthy puppy availa...</td>\n",
       "      <td>46e25aa2b</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>2</td>\n",
       "      <td>Ashe</td>\n",
       "      <td>5</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>54505759613a27d188eb21d90838b9a5</td>\n",
       "      <td>0</td>\n",
       "      <td>Ashe is adopted a few months ago. however, i s...</td>\n",
       "      <td>e5d3151bc</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5711</th>\n",
       "      <td>2</td>\n",
       "      <td>Chellom</td>\n",
       "      <td>9</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>f3af605bd0505d318bd1172709b3dff7</td>\n",
       "      <td>0</td>\n",
       "      <td>jantina : female DOB : / - manja, sedikit pema...</td>\n",
       "      <td>ebd16285e</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>1</td>\n",
       "      <td>NT-Female Puppy-04</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41327</td>\n",
       "      <td>3223e1c4cb2bef48823ee5c604b9aa04</td>\n",
       "      <td>0</td>\n",
       "      <td>Name of Pet: NT-Female Puppy-04 Age: 1 month B...</td>\n",
       "      <td>93ae9be69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>1</td>\n",
       "      <td>Rockia's</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41330</td>\n",
       "      <td>82cd0a317e8abc32c37de1f5f980acbb</td>\n",
       "      <td>0</td>\n",
       "      <td>Rescued these puppies from a near by abandoned...</td>\n",
       "      <td>832110a99</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12821</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>297ceb457f85f68f73c356340ec86d10</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello! I am a cutey brown dog! A few days ago,...</td>\n",
       "      <td>107c30c6d</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276</th>\n",
       "      <td>2</td>\n",
       "      <td>Bubui</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>98b3e1d6395d5f8c3cf10b848e4ae0c4</td>\n",
       "      <td>0</td>\n",
       "      <td>hi. few days ago ada org buang anak kucing dep...</td>\n",
       "      <td>d8b0d6ad9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>1</td>\n",
       "      <td>Rusk</td>\n",
       "      <td>48</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.554816</td>\n",
       "      <td>41401</td>\n",
       "      <td>c00756f2bdd8fa88fc9f07a8309f7d5d</td>\n",
       "      <td>0</td>\n",
       "      <td>Rescued miniature poodle for adoption. barks a...</td>\n",
       "      <td>8ef4b6cf3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11973</th>\n",
       "      <td>1</td>\n",
       "      <td>Harry</td>\n",
       "      <td>84</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41327</td>\n",
       "      <td>fd970cc91d06d82eebf046340137b272</td>\n",
       "      <td>0</td>\n",
       "      <td>Harry is up for adoption... Min poodle. Male. ...</td>\n",
       "      <td>155d18f5f</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12245</th>\n",
       "      <td>1</td>\n",
       "      <td>3 Month Old Puppy</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>d1d34c64b5ab9b9f7c086187f96db972</td>\n",
       "      <td>0</td>\n",
       "      <td>Mistake on my phone number sorry!! Young Puppy...</td>\n",
       "      <td>0434520ef</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>1</td>\n",
       "      <td>Max</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>c6790f3f049fd3d57569910536b32093</td>\n",
       "      <td>0</td>\n",
       "      <td>Max is a mix and once quoted by a vet as a Bel...</td>\n",
       "      <td>94d930dae</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>Alang</td>\n",
       "      <td>60</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>d835d7d98b94ec261d6d889a39eaed73</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi... I have one long haired adult male cat fo...</td>\n",
       "      <td>0d25f084f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>1</td>\n",
       "      <td>Orange</td>\n",
       "      <td>12</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41327</td>\n",
       "      <td>3fd88396eec81e232ca821fc302f33eb</td>\n",
       "      <td>0</td>\n",
       "      <td>She stay in a food court, but i had seen few h...</td>\n",
       "      <td>5b4dd9fb3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11693</th>\n",
       "      <td>2</td>\n",
       "      <td>George</td>\n",
       "      <td>18</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>9ae807946a63565d6c225c66b5dc4979</td>\n",
       "      <td>0</td>\n",
       "      <td>George is a free spirited unicorn with a socia...</td>\n",
       "      <td>2b4017cf2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>1</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>6</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>87d3fdeb2302303f9284597da8488b3a</td>\n",
       "      <td>0</td>\n",
       "      <td>He is Bruce. Very lovely and friendly. He is W...</td>\n",
       "      <td>76a045292</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>2</td>\n",
       "      <td>Blackberry And Daisy</td>\n",
       "      <td>7</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>a87a2542ac13e92151b29fd9bc47966d</td>\n",
       "      <td>0</td>\n",
       "      <td>1) Black \"homely\" boy. Likes to run a bit, but...</td>\n",
       "      <td>01e517961</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>241</td>\n",
       "      <td>276</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>5cbf7860da1936f71acb44d6c1b8b292</td>\n",
       "      <td>0</td>\n",
       "      <td>We save her from stray.. But my house gt a dog...</td>\n",
       "      <td>57aecbbcf</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8857</th>\n",
       "      <td>1</td>\n",
       "      <td>Puppy (6)</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41336</td>\n",
       "      <td>451db4e2524093cb4e47744bfa82bccc</td>\n",
       "      <td>0</td>\n",
       "      <td>Just born on 10 May , location at Taman Bukit ...</td>\n",
       "      <td>1cac8717d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3674</th>\n",
       "      <td>2</td>\n",
       "      <td>Lorax</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>3f25286cff6f07688fe567d8a42f6a4a</td>\n",
       "      <td>0</td>\n",
       "      <td>I am Lorax. I am the last of my four brothers....</td>\n",
       "      <td>80621df6b</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>Boy</td>\n",
       "      <td>12</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>6757d0b9d5b72d8b78c20e355c7fe62c</td>\n",
       "      <td>0</td>\n",
       "      <td>-playful -energetic dog -friendly and easily a...</td>\n",
       "      <td>4e3640544</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>7d5ffd5e8da0c4e9d8a65dfedb82defd</td>\n",
       "      <td>0</td>\n",
       "      <td>the cat came to my house last week out of nowh...</td>\n",
       "      <td>66dda45c4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11724</th>\n",
       "      <td>2</td>\n",
       "      <td>Comel Kecik</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.016069</td>\n",
       "      <td>41326</td>\n",
       "      <td>b990f8dcaa97abbc385bb78ff772ea84</td>\n",
       "      <td>0</td>\n",
       "      <td>Kitten comel. -comel kecik mencari tuan baru -...</td>\n",
       "      <td>d11ac47cb</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10477</th>\n",
       "      <td>1</td>\n",
       "      <td>Bull Dog</td>\n",
       "      <td>24</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.235190</td>\n",
       "      <td>41401</td>\n",
       "      <td>a1c7a4f20bb936fcb8d97039741c40be</td>\n",
       "      <td>0</td>\n",
       "      <td>Found this bull dog near my neighbourhood for ...</td>\n",
       "      <td>31a77d7ba</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>2</td>\n",
       "      <td>Mochi &amp; Koki</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>264</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>efc53964e5825ede3b3df18383f65eec</td>\n",
       "      <td>0</td>\n",
       "      <td>I have 2 small kitten up for adoption...URGENT...</td>\n",
       "      <td>2f18b4092</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>1</td>\n",
       "      <td>Trisha</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.016069</td>\n",
       "      <td>41327</td>\n",
       "      <td>7ed6d84e2e6879245e55447aee39c328</td>\n",
       "      <td>0</td>\n",
       "      <td>The lil' puppy is currently taking shelter at ...</td>\n",
       "      <td>1aaa74b35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11190</th>\n",
       "      <td>1</td>\n",
       "      <td>Max</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41327</td>\n",
       "      <td>44fce325ccb9ef4e894c4578d2fd9371</td>\n",
       "      <td>0</td>\n",
       "      <td>We are putting up our well trained, very frien...</td>\n",
       "      <td>7117c4553</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10185</th>\n",
       "      <td>2</td>\n",
       "      <td>2.5 Weeks Old Kittens For Adoption</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>5aca30a29e8290093fee2a334d65d835</td>\n",
       "      <td>0</td>\n",
       "      <td>These 4 kittens are currently located in a con...</td>\n",
       "      <td>6a5ba2ea7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9256</th>\n",
       "      <td>2</td>\n",
       "      <td>Millie</td>\n",
       "      <td>6</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>c00756f2bdd8fa88fc9f07a8309f7d5d</td>\n",
       "      <td>0</td>\n",
       "      <td>very pretty colour</td>\n",
       "      <td>d353746a5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13030</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>4d0f4b83bd88ffe0dff2db53746f909b</td>\n",
       "      <td>0</td>\n",
       "      <td>7 kittens for Adoption. Litter trained. Mix co...</td>\n",
       "      <td>d0f8b280d</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8787</th>\n",
       "      <td>2</td>\n",
       "      <td>Espresso (Black) &amp; Latte (Tiger)</td>\n",
       "      <td>2</td>\n",
       "      <td>264</td>\n",
       "      <td>265</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41401</td>\n",
       "      <td>fef79d84a134ca6234e6734eda00b884</td>\n",
       "      <td>1</td>\n",
       "      <td>They are cute and active siblings found at my ...</td>\n",
       "      <td>8ebe54ca6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10045 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type                                Name  Age  Breed1  Breed2  Gender  \\\n",
       "13507     2             Missy, Bobtailed Kitten    4     266     249       2   \n",
       "10594     2  Sneaky, Playful, Calmie, Adventura    2     266       0       3   \n",
       "1017      2                                Wiki    3     266       0       1   \n",
       "6321      1                              Kruppy    1     307       0       1   \n",
       "12323     2                                 NaN    2     266       0       3   \n",
       "8052      1                             Xiao Ke    6     307       0       1   \n",
       "5947      2                     Little Red Bean    2     265     265       2   \n",
       "13732     1                 DELIGHTFUL PUPPIES!    3     307       0       3   \n",
       "987       1                           --Shiro--    9     307       0       1   \n",
       "9366      2                       Max And Bobby    3     265       0       3   \n",
       "11752     2                                  AJ   18     266       0       1   \n",
       "5369      2                                Hiro    6     266       0       1   \n",
       "7894      2                              Ramone   12     266       0       1   \n",
       "6886      1             Save Me Or I'll Die #26   12     307       0       3   \n",
       "6824      1                      Ã¢ÂœÂª OLIVIA Ã¢ÂœÂª    1     307     200       2   \n",
       "8331      2                                 Blu   48     266       0       2   \n",
       "6387      2   Playful Kitty (spayed 1 Year Old)   12     266     266       2   \n",
       "10579     1                            Blackies    3     307       0       3   \n",
       "10213     1                                 NaN    5     307       0       1   \n",
       "14981     1                               Patch    8     307       0       2   \n",
       "3275      2                  Twinky And Oringa-    3     265     265       3   \n",
       "9202      1                                 NaN   96     207       0       1   \n",
       "10596     1                               Dopey    2     307     307       1   \n",
       "13267     2               Domestic Tabby Kitten    1     266       0       1   \n",
       "5130      1                                BUBU   72     307       0       1   \n",
       "1103      1                               Sugee    1     218     307       2   \n",
       "10626     1                                 NaN   14      78     307       2   \n",
       "3005      1                                Lily   48     109       0       2   \n",
       "8001      1                               Yenny    6     307       0       2   \n",
       "13141     1                               Poppy   84     103     307       2   \n",
       "...     ...                                 ...  ...     ...     ...     ...   \n",
       "12222     1                           Poor Baby    3     307       0       1   \n",
       "1882      2                                Ashe    5     266       0       2   \n",
       "5711      2                             Chellom    9     266       0       2   \n",
       "11561     1                  NT-Female Puppy-04    1     307       0       2   \n",
       "9776      1                            Rockia's    2     307     307       3   \n",
       "12821     1                                 NaN   36     307       0       2   \n",
       "11276     2                               Bubui    1     266       0       1   \n",
       "5312      1                                Rusk   48     179       0       1   \n",
       "11973     1                               Harry   84     179       0       1   \n",
       "12245     1                   3 Month Old Puppy    3     307       0       2   \n",
       "2507      1                                 Max   60      24       0       1   \n",
       "49        2                               Alang   60     264       0       1   \n",
       "13836     1                              Orange   12     307       0       2   \n",
       "11693     2                              George   18     299       0       1   \n",
       "10107     1                               Bruce    6     307       0       1   \n",
       "7174      2                Blackberry And Daisy    7     299     299       3   \n",
       "4019      2                                 NaN    6     241     276       2   \n",
       "8857      1                           Puppy (6)    0     307       0       3   \n",
       "3674      2                               Lorax    3     266       0       1   \n",
       "39        1                                 Boy   12     307       0       1   \n",
       "347       2                                 NaN    4     266       0       2   \n",
       "11724     2                         Comel Kecik    1     266     266       2   \n",
       "10477     1                            Bull Dog   24      82       0       1   \n",
       "6175      2                        Mochi & Koki    1     265     264       3   \n",
       "9704      1                              Trisha    1     307       0       2   \n",
       "11190     1                                 Max   32     128       0       2   \n",
       "10185     2  2.5 Weeks Old Kittens For Adoption    0     266       0       3   \n",
       "9256      2                              Millie    6     266       0       2   \n",
       "13030     2                                 NaN    2     297       0       3   \n",
       "8787      2    Espresso (Black) & Latte (Tiger)    2     264     265       3   \n",
       "\n",
       "       Color1  Color2  Color3  MaturitySize  ...  Health  Quantity        Fee  \\\n",
       "13507       1       3       7             2  ...       1         1  -0.271132   \n",
       "10594       4       5       6             2  ...       1         4  -0.271132   \n",
       "1017        4       7       0             2  ...       1         1  -0.271132   \n",
       "6321        1       3       7             2  ...       1         1  -0.271132   \n",
       "12323       3       6       7             2  ...       1         3  -0.271132   \n",
       "8052        2       0       0             2  ...       2         1  -0.271132   \n",
       "5947        6       7       0             1  ...       1         1  -0.271132   \n",
       "13732       1       2       5             2  ...       1         4  -0.271132   \n",
       "987         7       0       0             2  ...       1         1  -0.271132   \n",
       "9366        1       2       7             1  ...       1         2  -0.271132   \n",
       "11752       6       7       0             2  ...       1         1  -0.271132   \n",
       "5369        7       0       0             1  ...       1         1  -0.271132   \n",
       "7894        5       7       0             1  ...       1         1  -0.271132   \n",
       "6886        1       2       5             2  ...       1         4  -0.271132   \n",
       "6824        2       0       0             2  ...       1         1   4.192474   \n",
       "8331        5       7       0             2  ...       1         1  -0.271132   \n",
       "6387        2       7       0             1  ...       1         1  -0.271132   \n",
       "10579       1       0       0             2  ...       1         3  -0.271132   \n",
       "10213       2       7       0             2  ...       1         1  -0.271132   \n",
       "14981       2       7       0             2  ...       1         1  -0.271132   \n",
       "3275        4       6       0             2  ...       1         2  -0.271132   \n",
       "9202        1       5       6             1  ...       1         1  -0.271132   \n",
       "10596       2       0       0             2  ...       1         1  -0.271132   \n",
       "13267       2       6       0             1  ...       1         1  -0.271132   \n",
       "5130        1       0       0             2  ...       1         1  -0.271132   \n",
       "1103        1       2       0             2  ...       1         1  -0.271132   \n",
       "10626       2       0       0             2  ...       1         1  -0.271132   \n",
       "3005        3       5       0             2  ...       1         1  -0.271132   \n",
       "8001        2       7       0             2  ...       1         1  -0.271132   \n",
       "13141       1       4       0             2  ...       1         1  -0.271132   \n",
       "...       ...     ...     ...           ...  ...     ...       ...        ...   \n",
       "12222       5       0       0             2  ...       1         1  -0.271132   \n",
       "1882        6       0       0             2  ...       1         1  -0.271132   \n",
       "5711        1       0       0             2  ...       1         1  -0.271132   \n",
       "11561       1       0       0             2  ...       1         1  -0.271132   \n",
       "9776        1       2       7             2  ...       1         9  -0.271132   \n",
       "12821       2       3       4             2  ...       2         1  -0.271132   \n",
       "11276       6       7       0             1  ...       1         1  -0.271132   \n",
       "5312        4       0       0             1  ...       1         1   3.554816   \n",
       "11973       2       0       0             1  ...       2         1  -0.271132   \n",
       "12245       7       0       0             2  ...       1         1  -0.271132   \n",
       "2507        2       0       0             2  ...       1         1  -0.271132   \n",
       "49          1       2       7             3  ...       1         1  -0.271132   \n",
       "13836       2       3       4             2  ...       1         1  -0.271132   \n",
       "11693       1       2       6             3  ...       1         1  -0.271132   \n",
       "10107       7       0       0             2  ...       1         1  -0.271132   \n",
       "7174        1       4       7             2  ...       1         2  -0.271132   \n",
       "4019        1       6       0             1  ...       2         1  -0.271132   \n",
       "8857        1       2       3             2  ...       1         6  -0.271132   \n",
       "3674        4       7       0             1  ...       1         1  -0.271132   \n",
       "39          5       0       0             2  ...       1         1  -0.271132   \n",
       "347         1       6       7             1  ...       1         1  -0.271132   \n",
       "11724       1       2       7             1  ...       1         1  -0.016069   \n",
       "10477       2       5       7             2  ...       1         1  25.235190   \n",
       "6175        2       3       0             2  ...       1         2  -0.271132   \n",
       "9704        2       0       0             2  ...       1         1  -0.016069   \n",
       "11190       2       7       0             1  ...       1         1  -0.271132   \n",
       "10185       1       3       4             2  ...       1         4  -0.271132   \n",
       "9256        6       7       0             1  ...       1         1  -0.271132   \n",
       "13030       3       6       7             1  ...       1         7  -0.271132   \n",
       "8787        1       2       6             1  ...       1         2  -0.271132   \n",
       "\n",
       "       State                         RescuerID  VideoAmt  \\\n",
       "13507  41326  5aca30a29e8290093fee2a334d65d835         0   \n",
       "10594  41326  bd646cb96f00a7c5bff955a4084872fc         0   \n",
       "1017   41326  7b107e61f7d24a581e46e0abc4d2a7a7         0   \n",
       "6321   41326  d4a8b5e64cd89e2f055b505383a8ee7a         0   \n",
       "12323  41401  abe54643224ddbb5c199cd46fbca0392         0   \n",
       "8052   41327  4e9f9a3804795b86c27dd86f7fe05029         0   \n",
       "5947   41401  93dfc7e5d65f9772958c411eb3a8b53f         0   \n",
       "13732  41401  9dc662ce3243365c173dc9029aad6989         0   \n",
       "987    41327  c2e496d5b05dc9771f234e168465b389         0   \n",
       "9366   41401  1004c35eccb48a99a16726b45f0d7baa         0   \n",
       "11752  41401  f529803bddfac1cacf9be19b32c9a523         0   \n",
       "5369   41327  58129f5a444ddda87cd0afe50e6b4773         0   \n",
       "7894   41401  c00756f2bdd8fa88fc9f07a8309f7d5d         0   \n",
       "6886   41401  ee2747ce26468ec44c7194e7d1d9dad9         0   \n",
       "6824   41336  d73b10f170720b7edc3c12fc93b1fc63         0   \n",
       "8331   41326  82a32b0880e7b35ae5133945a67e90a7         0   \n",
       "6387   41326  efa9a4be1e2e903503540f01db1766f3         0   \n",
       "10579  41401  c13802ffd2e87ef97bba5f7b3d8ea3d7         1   \n",
       "10213  41326  c0637f196649469caecd5210a9b12874         0   \n",
       "14981  41326  001e42763024f9d4abe31e79472b1827         0   \n",
       "3275   41326  844018bf488f35cfa490c6307f710309         0   \n",
       "9202   41401  f4d07514e4efa1233908cab099829910         0   \n",
       "10596  41326  1a2113010d6048d5410b265347b35c91         0   \n",
       "13267  41401  540a712eacd464a4e752151db85588e7         0   \n",
       "5130   41326  8edfd19b404ab7c171ae024cf7cb51bf         0   \n",
       "1103   41326  fa90fa5b1ee11c86938398b60abc32cb         0   \n",
       "10626  41401  c852f96558b98f87a444c8eda0da1604         0   \n",
       "3005   41326  5fc4f48cf3213a83d0d571f584487f08         0   \n",
       "8001   41326  95481e953f8aed9ec3d16fc4509537e8         0   \n",
       "13141  41401  1112a5e33e8557701cc8a1395d0921d3         0   \n",
       "...      ...                               ...       ...   \n",
       "12222  41401  500c48db7b281eabec3c293160f4a71c         0   \n",
       "1882   41401  54505759613a27d188eb21d90838b9a5         0   \n",
       "5711   41326  f3af605bd0505d318bd1172709b3dff7         0   \n",
       "11561  41327  3223e1c4cb2bef48823ee5c604b9aa04         0   \n",
       "9776   41330  82cd0a317e8abc32c37de1f5f980acbb         0   \n",
       "12821  41401  297ceb457f85f68f73c356340ec86d10         0   \n",
       "11276  41326  98b3e1d6395d5f8c3cf10b848e4ae0c4         0   \n",
       "5312   41401  c00756f2bdd8fa88fc9f07a8309f7d5d         0   \n",
       "11973  41327  fd970cc91d06d82eebf046340137b272         0   \n",
       "12245  41326  d1d34c64b5ab9b9f7c086187f96db972         0   \n",
       "2507   41326  c6790f3f049fd3d57569910536b32093         0   \n",
       "49     41326  d835d7d98b94ec261d6d889a39eaed73         0   \n",
       "13836  41327  3fd88396eec81e232ca821fc302f33eb         0   \n",
       "11693  41326  9ae807946a63565d6c225c66b5dc4979         0   \n",
       "10107  41326  87d3fdeb2302303f9284597da8488b3a         0   \n",
       "7174   41326  a87a2542ac13e92151b29fd9bc47966d         0   \n",
       "4019   41326  5cbf7860da1936f71acb44d6c1b8b292         0   \n",
       "8857   41336  451db4e2524093cb4e47744bfa82bccc         0   \n",
       "3674   41401  3f25286cff6f07688fe567d8a42f6a4a         0   \n",
       "39     41326  6757d0b9d5b72d8b78c20e355c7fe62c         0   \n",
       "347    41326  7d5ffd5e8da0c4e9d8a65dfedb82defd         0   \n",
       "11724  41326  b990f8dcaa97abbc385bb78ff772ea84         0   \n",
       "10477  41401  a1c7a4f20bb936fcb8d97039741c40be         0   \n",
       "6175   41326  efc53964e5825ede3b3df18383f65eec         0   \n",
       "9704   41327  7ed6d84e2e6879245e55447aee39c328         0   \n",
       "11190  41327  44fce325ccb9ef4e894c4578d2fd9371         0   \n",
       "10185  41326  5aca30a29e8290093fee2a334d65d835         0   \n",
       "9256   41401  c00756f2bdd8fa88fc9f07a8309f7d5d         0   \n",
       "13030  41326  4d0f4b83bd88ffe0dff2db53746f909b         0   \n",
       "8787   41401  fef79d84a134ca6234e6734eda00b884         1   \n",
       "\n",
       "                                             Description      PetID PhotoAmt  \\\n",
       "13507  If you love bob-tailed kitties, then how about...  4693e646e     14.0   \n",
       "10594  Their mother came to us few months ago, she wa...  45afc38e4      8.0   \n",
       "1017   Found this cutie at the Putrajaya Sentral car ...  69262e404      1.0   \n",
       "6321   [On trial adoption] Pics 1-5 with credits to O...  df17a57ae      6.0   \n",
       "12323  3 cute and playful kitties 2 months old for fr...  08ee62d43      2.0   \n",
       "8052   A dog that dumped by owner at market. Pls gv h...  87a679d31      1.0   \n",
       "5947   Little Red Bean is still waiting for her forev...  f205b0649     13.0   \n",
       "13732  Here are 4 beautiful puppies for adoption! The...  a07a65495      1.0   \n",
       "987    A white mixed breed dog looking for adoption. ...  9c580ca06      1.0   \n",
       "9366   dua2 ni adik beradik..comel,sihat and cergas.....  fecec878e      2.0   \n",
       "11752  This is AJ. He is a very handsome, warm and lo...  9edf8fff1      1.0   \n",
       "5369   Male kitten needing a forever home. He's very ...  a2a04b6e4      2.0   \n",
       "7894   Ramone is very soft and sweet and beautiful. H...  beb658bc0      5.0   \n",
       "6886   PLEASE RESCUE/ADOPT ME FROM KLANG POUND OR I W...  5e696928a      1.0   \n",
       "6824   Adoption fee includes the basic medical expens...  742cced96      5.0   \n",
       "8331   I will be moving to Australia soon and I am lo...  24fad6b0b      5.0   \n",
       "6387   Macy is a spayed 1 year old rescued female. Sm...  45ba264f2      7.0   \n",
       "10579  A friendly mother dog, found her abandoned/los...  3b0238af8      7.0   \n",
       "10213  He got a pair of beautiful eyes, sharp figures...  84b297843      1.0   \n",
       "14981  Patch is for free adoption. If you want to ado...  23874f644      2.0   \n",
       "3275   Two Kittens: Twinky(girl ) and Oringa(Boy) is ...  915f0b42a      1.0   \n",
       "9202   Was found wandering around the neighborhood wi...  bb928145e      3.0   \n",
       "10596  *Adoption fee is a donation of your choice* Do...  a54202bba      3.0   \n",
       "13267  It happened that I found this cat hidden on ca...  1498a5e81      3.0   \n",
       "5130   we found the dog when jogging around broga are...  4a311c6dc      0.0   \n",
       "1103   Lovely puppy looking for a home sweet home. Co...  86d203b94      3.0   \n",
       "10626  It's a pet currently stay in my home looking f...  8cae4a15b      2.0   \n",
       "3005   Golden retriver cross. Shy with strangers, but...  ddf06fabf      2.0   \n",
       "8001   Yenny is a very humble and obedient girl. She ...  37d88b689      4.0   \n",
       "13141  She was abandoned by owner. Personality and qu...  d8179f4d9      2.0   \n",
       "...                                                  ...        ...      ...   \n",
       "12222  On behalf of Exotica Pets Healthy puppy availa...  46e25aa2b      2.0   \n",
       "1882   Ashe is adopted a few months ago. however, i s...  e5d3151bc      5.0   \n",
       "5711   jantina : female DOB : / - manja, sedikit pema...  ebd16285e      5.0   \n",
       "11561  Name of Pet: NT-Female Puppy-04 Age: 1 month B...  93ae9be69      1.0   \n",
       "9776   Rescued these puppies from a near by abandoned...  832110a99      9.0   \n",
       "12821  Hello! I am a cutey brown dog! A few days ago,...  107c30c6d      2.0   \n",
       "11276  hi. few days ago ada org buang anak kucing dep...  d8b0d6ad9      3.0   \n",
       "5312   Rescued miniature poodle for adoption. barks a...  8ef4b6cf3      3.0   \n",
       "11973  Harry is up for adoption... Min poodle. Male. ...  155d18f5f      2.0   \n",
       "12245  Mistake on my phone number sorry!! Young Puppy...  0434520ef      5.0   \n",
       "2507   Max is a mix and once quoted by a vet as a Bel...  94d930dae      1.0   \n",
       "49     Hi... I have one long haired adult male cat fo...  0d25f084f      3.0   \n",
       "13836  She stay in a food court, but i had seen few h...  5b4dd9fb3      1.0   \n",
       "11693  George is a free spirited unicorn with a socia...  2b4017cf2      5.0   \n",
       "10107  He is Bruce. Very lovely and friendly. He is W...  76a045292      6.0   \n",
       "7174   1) Black \"homely\" boy. Likes to run a bit, but...  01e517961      2.0   \n",
       "4019   We save her from stray.. But my house gt a dog...  57aecbbcf      3.0   \n",
       "8857   Just born on 10 May , location at Taman Bukit ...  1cac8717d      1.0   \n",
       "3674   I am Lorax. I am the last of my four brothers....  80621df6b      5.0   \n",
       "39     -playful -energetic dog -friendly and easily a...  4e3640544      1.0   \n",
       "347    the cat came to my house last week out of nowh...  66dda45c4      3.0   \n",
       "11724  Kitten comel. -comel kecik mencari tuan baru -...  d11ac47cb      5.0   \n",
       "10477  Found this bull dog near my neighbourhood for ...  31a77d7ba      3.0   \n",
       "6175   I have 2 small kitten up for adoption...URGENT...  2f18b4092      3.0   \n",
       "9704   The lil' puppy is currently taking shelter at ...  1aaa74b35      1.0   \n",
       "11190  We are putting up our well trained, very frien...  7117c4553      2.0   \n",
       "10185  These 4 kittens are currently located in a con...  6a5ba2ea7      6.0   \n",
       "9256                                  very pretty colour  d353746a5      4.0   \n",
       "13030  7 kittens for Adoption. Litter trained. Mix co...  d0f8b280d      5.0   \n",
       "8787   They are cute and active siblings found at my ...  8ebe54ca6      5.0   \n",
       "\n",
       "       AdoptionSpeed  \n",
       "13507              1  \n",
       "10594              3  \n",
       "1017               2  \n",
       "6321               1  \n",
       "12323              3  \n",
       "8052               4  \n",
       "5947               3  \n",
       "13732              4  \n",
       "987                4  \n",
       "9366               4  \n",
       "11752              1  \n",
       "5369               2  \n",
       "7894               2  \n",
       "6886               4  \n",
       "6824               3  \n",
       "8331               4  \n",
       "6387               4  \n",
       "10579              3  \n",
       "10213              4  \n",
       "14981              3  \n",
       "3275               3  \n",
       "9202               3  \n",
       "10596              2  \n",
       "13267              2  \n",
       "5130               4  \n",
       "1103               3  \n",
       "10626              4  \n",
       "3005               2  \n",
       "8001               3  \n",
       "13141              4  \n",
       "...              ...  \n",
       "12222              1  \n",
       "1882               2  \n",
       "5711               3  \n",
       "11561              3  \n",
       "9776               4  \n",
       "12821              4  \n",
       "11276              3  \n",
       "5312               3  \n",
       "11973              3  \n",
       "12245              1  \n",
       "2507               2  \n",
       "49                 2  \n",
       "13836              3  \n",
       "11693              4  \n",
       "10107              4  \n",
       "7174               4  \n",
       "4019               3  \n",
       "8857               3  \n",
       "3674               3  \n",
       "39                 3  \n",
       "347                1  \n",
       "11724              3  \n",
       "10477              1  \n",
       "6175               3  \n",
       "9704               2  \n",
       "11190              3  \n",
       "10185              0  \n",
       "9256               3  \n",
       "13030              1  \n",
       "8787               1  \n",
       "\n",
       "[10045 rows x 24 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "_uuid": "c8ba9c6ea62da5a0d94acbb22d88c5c89e2f3c1a"
   },
   "outputs": [],
   "source": [
    "y_train = tr_df['AdoptionSpeed'].values / 4\n",
    "y_valid = val_df['AdoptionSpeed'].values / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "_uuid": "28870d4162b0556201bc5016c7b817532c615324"
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(tr_df['AdoptionSpeed'], num_classes=5)\n",
    "y_valid = np_utils.to_categorical(val_df['AdoptionSpeed'], num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "_uuid": "d11852ccd09ff14509a1e8aadc09ec8e0c510c90"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`sequences` must be a list of iterables. Found non-iterable: nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-a5622fe3dfa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-143-1030ea61c48c>\u001b[0m in \u001b[0;36mget_input_features\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_input_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'numerical'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             raise ValueError('`sequences` must be a list of iterables. '\n\u001b[0;32m---> 60\u001b[0;31m                              'Found non-iterable: ' + str(x))\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `sequences` must be a list of iterables. Found non-iterable: nan"
     ]
    }
   ],
   "source": [
    "X_train = get_input_features(tr_df)\n",
    "X_valid = get_input_features(val_df)\n",
    "X_test = get_input_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10045 samples, validate on 4948 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[0,0] = 7 is not in [0, 7)\n\t [[{{node embedding_138/embedding_lookup}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_5/Adam/Assign_23\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_138/embeddings/read, embedding_138/Cast, training_5/Adam/gradients/embedding_138/embedding_lookup_grad/concat/axis)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-d56a060618e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[0,0] = 7 is not in [0, 7)\n\t [[{{node embedding_138/embedding_lookup}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@training_5/Adam/Assign_23\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_138/embeddings/read, embedding_138/Cast, training_5/Adam/gradients/embedding_138/embedding_lookup_grad/concat/axis)]]"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, validation_data = (X_valid,y_valid), batch_size = 256, epochs = 10, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
>>>>>>> zekun
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\n",
      "Epoch 00039: val_acc did not improve from 0.37933\n",
      "Epoch 40/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1386 - acc: 0.4219 - val_loss: 0.1459 - val_acc: 0.3700\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.37933\n",
      "Epoch 41/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1384 - acc: 0.4211 - val_loss: 0.1457 - val_acc: 0.3687\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.37933\n",
      "Epoch 42/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1381 - acc: 0.4246 - val_loss: 0.1452 - val_acc: 0.3687\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.37933\n",
      "Epoch 43/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1382 - acc: 0.4228 - val_loss: 0.1451 - val_acc: 0.3800\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.37933 to 0.38000, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 44/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1380 - acc: 0.4251 - val_loss: 0.1452 - val_acc: 0.3713\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.38000\n",
      "Epoch 45/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1378 - acc: 0.4275 - val_loss: 0.1451 - val_acc: 0.3733\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.38000\n",
      "Epoch 46/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1376 - acc: 0.4301 - val_loss: 0.1452 - val_acc: 0.3740\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.38000\n",
      "Epoch 47/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1374 - acc: 0.4265 - val_loss: 0.1457 - val_acc: 0.3753\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.38000\n",
      "Epoch 48/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1377 - acc: 0.4226 - val_loss: 0.1454 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.38000\n",
      "Epoch 49/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1372 - acc: 0.4325 - val_loss: 0.1452 - val_acc: 0.3740\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.38000\n",
      "Epoch 50/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1374 - acc: 0.4290 - val_loss: 0.1457 - val_acc: 0.3753\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.38000\n",
      "Epoch 51/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1372 - acc: 0.4351 - val_loss: 0.1454 - val_acc: 0.3760\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.38000\n",
      "Epoch 52/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1369 - acc: 0.4331 - val_loss: 0.1456 - val_acc: 0.3767\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.38000\n",
      "Epoch 53/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1366 - acc: 0.4343 - val_loss: 0.1453 - val_acc: 0.3813\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.38000 to 0.38133, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 54/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1366 - acc: 0.4333 - val_loss: 0.1460 - val_acc: 0.3720\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.38133\n",
      "Epoch 55/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1366 - acc: 0.4306 - val_loss: 0.1461 - val_acc: 0.3793\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.38133\n",
      "Epoch 56/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1365 - acc: 0.4381 - val_loss: 0.1454 - val_acc: 0.3720\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.38133\n",
      "Epoch 57/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1361 - acc: 0.4436 - val_loss: 0.1455 - val_acc: 0.3747\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.38133\n",
      "Epoch 58/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1367 - acc: 0.4398 - val_loss: 0.1452 - val_acc: 0.3773\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.38133\n",
      "Epoch 59/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1357 - acc: 0.4363 - val_loss: 0.1457 - val_acc: 0.3733\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.38133\n",
      "Epoch 60/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1361 - acc: 0.4383 - val_loss: 0.1453 - val_acc: 0.3760\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.38133\n",
      "Epoch 61/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1355 - acc: 0.4423 - val_loss: 0.1456 - val_acc: 0.3793\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.38133\n",
      "Epoch 62/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1354 - acc: 0.4430 - val_loss: 0.1459 - val_acc: 0.3733\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.38133\n",
      "Epoch 63/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1358 - acc: 0.4455 - val_loss: 0.1474 - val_acc: 0.3680\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.38133\n",
      "Epoch 64/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1355 - acc: 0.4431 - val_loss: 0.1456 - val_acc: 0.3680\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.38133\n",
      "Epoch 65/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1353 - acc: 0.4490 - val_loss: 0.1460 - val_acc: 0.3773\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.38133\n",
      "Epoch 66/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1351 - acc: 0.4460 - val_loss: 0.1469 - val_acc: 0.3747\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.38133\n",
      "Epoch 67/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1354 - acc: 0.4438 - val_loss: 0.1454 - val_acc: 0.3773\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.38133\n",
      "Epoch 68/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1347 - acc: 0.4495 - val_loss: 0.1455 - val_acc: 0.3707\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.38133\n",
      "Epoch 69/100\n",
      "5996/5996 [==============================] - 0s 6us/step - loss: 0.1351 - acc: 0.4453 - val_loss: 0.1459 - val_acc: 0.3720\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.38133\n",
      "Epoch 70/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1351 - acc: 0.4443 - val_loss: 0.1456 - val_acc: 0.3733\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.38133\n",
      "Epoch 71/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1346 - acc: 0.4475 - val_loss: 0.1458 - val_acc: 0.3733\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.38133\n",
      "Epoch 72/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1347 - acc: 0.4443 - val_loss: 0.1468 - val_acc: 0.3747\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.38133\n",
      "Epoch 73/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1344 - acc: 0.4480 - val_loss: 0.1456 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.38133\n",
      "Epoch 74/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1340 - acc: 0.4535 - val_loss: 0.1460 - val_acc: 0.3720\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.38133\n",
      "Epoch 75/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1351 - acc: 0.4455 - val_loss: 0.1457 - val_acc: 0.3760\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.38133\n",
      "Epoch 76/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1337 - acc: 0.4563 - val_loss: 0.1459 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.38133\n",
      "Epoch 77/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1340 - acc: 0.4556 - val_loss: 0.1465 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.38133\n",
      "Epoch 78/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1340 - acc: 0.4580 - val_loss: 0.1465 - val_acc: 0.3693\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.38133\n",
      "Epoch 79/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1339 - acc: 0.4523 - val_loss: 0.1468 - val_acc: 0.3727\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.38133\n",
      "Epoch 80/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1339 - acc: 0.4531 - val_loss: 0.1458 - val_acc: 0.3700\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.38133\n",
      "Epoch 81/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1337 - acc: 0.4591 - val_loss: 0.1465 - val_acc: 0.3753\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.38133\n",
      "Epoch 82/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1334 - acc: 0.4563 - val_loss: 0.1462 - val_acc: 0.3673\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.38133\n",
      "Epoch 83/100\n"
     ]
    },
=======
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# zipcodes = tr_df[uncontinuous].value_counts().keys().tolist()\n",
    "# counts = tr_df[uncontinuous].value_counts().tolist()\n",
    "\n",
    "# \t# loop over each of the unique zip codes and their corresponding\n",
    "# \t# count\n",
    "# for (zipcode, count) in zip(zipcodes, counts):\n",
    "# \t\t# the zip code counts for our housing dataset is *extremely*\n",
    "# \t\t# unbalanced (some only having 1 or 2 houses per zip code)\n",
    "# \t\t# so let's sanitize our data by removing any houses with less\n",
    "# \t\t# than 25 houses per zip code\n",
    "# \tif count < 25:\n",
    "# \t\tidxs = tr_df[tr_df[uncontinuous] == zipcode].index\n",
    "# \t\ttr_df.drop(idxs, inplace=True)\n",
    "        \n",
    "# zipBinarizer = LabelBinarizer().fit(tr_df[uncontinuous])\n",
    "# trainCategorical = zipBinarizer.transform(tr_df[uncontinuous])\n",
    "\n",
    "# print(\"----------------------------\")\n",
    "# print(tr_df)\n",
    "continuous = ['Type','Age','Breed1','Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', \n",
    "          'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized','Health', 'Fee','Quantity','VideoAmt','PhotoAmt']\n",
    "cs = StandardScaler();\n",
    "# LABEL = 'AdoptionSpeed'\n",
    "# tr_df = tr_df.drop([LABEL], axis=1);\n",
    "# val_df = val_df.drop([LABEL], axis=1);\n",
    "# test_df = test_df.drop([LABEL], axis=1);\n",
    "LABEL = 'RescuerID'\n",
    "tr_df = tr_df.drop([LABEL], axis=1);\n",
    "val_df = val_df.drop([LABEL], axis=1);\n",
    "test_df = test_df.drop([LABEL], axis=1);\n",
    "LABEL = 'Description'\n",
    "tr_df = tr_df.drop([LABEL], axis=1);\n",
    "val_df = val_df.drop([LABEL], axis=1);\n",
    "test_df = test_df.drop([LABEL], axis=1);\n",
    "LABEL = 'PetID'\n",
    "tr_df = tr_df.drop([LABEL], axis=1);\n",
    "val_df = val_df.drop([LABEL], axis=1);\n",
    "test_df = test_df.drop([LABEL], axis=1);\n",
    "LABEL = 'Name'\n",
    "tr_df = tr_df.drop([LABEL], axis=1);\n",
    "val_df = val_df.drop([LABEL], axis=1);\n",
    "test_df = test_df.drop([LABEL], axis=1);\n",
    "trainContinuous = cs.fit_transform(tr_df[continuous])\n",
    "trainContinuous2 = cs.fit_transform(val_df[continuous])\n",
    "trainContinuous3 = cs.fit_transform(test_df[continuous])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainContinuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
>>>>>>> zekun
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1332 - acc: 0.4568 - val_loss: 0.1465 - val_acc: 0.3687\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.38133\n",
      "Epoch 84/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1335 - acc: 0.4598 - val_loss: 0.1461 - val_acc: 0.3693\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.38133\n",
      "Epoch 85/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1329 - acc: 0.4605 - val_loss: 0.1462 - val_acc: 0.3767\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.38133\n",
      "Epoch 86/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1331 - acc: 0.4595 - val_loss: 0.1477 - val_acc: 0.3720\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.38133\n",
      "Epoch 87/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1338 - acc: 0.4511 - val_loss: 0.1461 - val_acc: 0.3687\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.38133\n",
      "Epoch 88/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1329 - acc: 0.4643 - val_loss: 0.1462 - val_acc: 0.3700\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.38133\n",
      "Epoch 89/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1332 - acc: 0.4610 - val_loss: 0.1461 - val_acc: 0.3680\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.38133\n",
      "Epoch 90/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1327 - acc: 0.4638 - val_loss: 0.1461 - val_acc: 0.3713\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.38133\n",
      "Epoch 91/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1323 - acc: 0.4658 - val_loss: 0.1466 - val_acc: 0.3700\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.38133\n",
      "Epoch 92/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1326 - acc: 0.4631 - val_loss: 0.1470 - val_acc: 0.3660\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.38133\n",
      "Epoch 93/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1330 - acc: 0.4538 - val_loss: 0.1464 - val_acc: 0.3713\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.38133\n",
      "Epoch 94/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1319 - acc: 0.4700 - val_loss: 0.1464 - val_acc: 0.3767\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.38133\n",
      "Epoch 95/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1320 - acc: 0.4683 - val_loss: 0.1473 - val_acc: 0.3707\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.38133\n",
      "Epoch 96/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1322 - acc: 0.4660 - val_loss: 0.1467 - val_acc: 0.3733\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.38133\n",
      "Epoch 97/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1317 - acc: 0.4708 - val_loss: 0.1465 - val_acc: 0.3687\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.38133\n",
      "Epoch 98/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1330 - acc: 0.4566 - val_loss: 0.1465 - val_acc: 0.3733\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.38133\n",
      "Epoch 99/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1320 - acc: 0.4696 - val_loss: 0.1465 - val_acc: 0.3773\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.38133\n",
      "Epoch 100/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1320 - acc: 0.4720 - val_loss: 0.1468 - val_acc: 0.3727\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.38133\n",
      "Train on 5996 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1344 - acc: 0.4551 - val_loss: 0.1349 - val_acc: 0.4673\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.38133 to 0.46733, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 2/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1339 - acc: 0.4556 - val_loss: 0.1348 - val_acc: 0.4520\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.46733\n",
      "Epoch 3/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1347 - acc: 0.4473 - val_loss: 0.1353 - val_acc: 0.4547\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.46733\n",
      "Epoch 4/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1336 - acc: 0.4530 - val_loss: 0.1360 - val_acc: 0.4567\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.46733\n",
      "Epoch 5/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1339 - acc: 0.4551 - val_loss: 0.1363 - val_acc: 0.4533\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.46733\n",
      "Epoch 6/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1341 - acc: 0.4523 - val_loss: 0.1361 - val_acc: 0.4520\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.46733\n",
      "Epoch 7/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1333 - acc: 0.4625 - val_loss: 0.1358 - val_acc: 0.4387\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.46733\n",
      "Epoch 8/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1333 - acc: 0.4558 - val_loss: 0.1360 - val_acc: 0.4540\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.46733\n",
      "Epoch 9/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1331 - acc: 0.4553 - val_loss: 0.1364 - val_acc: 0.4293\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.46733\n",
      "Epoch 10/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1334 - acc: 0.4531 - val_loss: 0.1376 - val_acc: 0.4247\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.46733\n",
      "Epoch 11/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1333 - acc: 0.4565 - val_loss: 0.1368 - val_acc: 0.4480\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.46733\n",
      "Epoch 12/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1327 - acc: 0.4591 - val_loss: 0.1369 - val_acc: 0.4320\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.46733\n",
      "Epoch 13/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1323 - acc: 0.4680 - val_loss: 0.1368 - val_acc: 0.4447\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.46733\n",
      "Epoch 14/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1335 - acc: 0.4553 - val_loss: 0.1372 - val_acc: 0.4447\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.46733\n",
      "Epoch 15/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1322 - acc: 0.4643 - val_loss: 0.1379 - val_acc: 0.4367\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.46733\n",
      "Epoch 16/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1325 - acc: 0.4636 - val_loss: 0.1367 - val_acc: 0.4420\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.46733\n",
      "Epoch 17/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1320 - acc: 0.4693 - val_loss: 0.1369 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.46733\n",
      "Epoch 18/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1318 - acc: 0.4645 - val_loss: 0.1396 - val_acc: 0.4300\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.46733\n",
      "Epoch 19/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1323 - acc: 0.4651 - val_loss: 0.1372 - val_acc: 0.4360\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.46733\n",
      "Epoch 20/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1318 - acc: 0.4691 - val_loss: 0.1396 - val_acc: 0.4313\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.46733\n",
      "Epoch 21/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1329 - acc: 0.4576 - val_loss: 0.1372 - val_acc: 0.4387\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.46733\n",
      "Epoch 22/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1312 - acc: 0.4706 - val_loss: 0.1375 - val_acc: 0.4340\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.46733\n",
      "Epoch 23/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1314 - acc: 0.4691 - val_loss: 0.1381 - val_acc: 0.4253\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.46733\n",
      "Epoch 24/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1321 - acc: 0.4680 - val_loss: 0.1374 - val_acc: 0.4287\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.46733\n",
      "Epoch 25/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1313 - acc: 0.4650 - val_loss: 0.1379 - val_acc: 0.4333\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.46733\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1310 - acc: 0.4705 - val_loss: 0.1397 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.46733\n",
      "Epoch 27/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1310 - acc: 0.4728 - val_loss: 0.1377 - val_acc: 0.4320\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.46733\n",
      "Epoch 28/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1307 - acc: 0.4772 - val_loss: 0.1384 - val_acc: 0.4287\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.46733\n",
      "Epoch 29/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1310 - acc: 0.4673 - val_loss: 0.1397 - val_acc: 0.4320\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.46733\n",
      "Epoch 30/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1316 - acc: 0.4685 - val_loss: 0.1381 - val_acc: 0.4340\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.46733\n",
      "Epoch 31/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1304 - acc: 0.4785 - val_loss: 0.1380 - val_acc: 0.4327\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.46733\n",
      "Epoch 32/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1303 - acc: 0.4778 - val_loss: 0.1403 - val_acc: 0.4220\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.46733\n",
      "Epoch 33/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1307 - acc: 0.4686 - val_loss: 0.1388 - val_acc: 0.4300\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.46733\n",
      "Epoch 34/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1303 - acc: 0.4768 - val_loss: 0.1390 - val_acc: 0.4220\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.46733\n",
      "Epoch 35/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1306 - acc: 0.4792 - val_loss: 0.1379 - val_acc: 0.4293\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.46733\n",
      "Epoch 36/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1304 - acc: 0.4741 - val_loss: 0.1380 - val_acc: 0.4340\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.46733\n",
      "Epoch 37/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1296 - acc: 0.4823 - val_loss: 0.1383 - val_acc: 0.4260\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.46733\n",
      "Epoch 38/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1296 - acc: 0.4812 - val_loss: 0.1416 - val_acc: 0.4187\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.46733\n",
      "Epoch 39/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1309 - acc: 0.4696 - val_loss: 0.1386 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.46733\n",
      "Epoch 40/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1301 - acc: 0.4748 - val_loss: 0.1397 - val_acc: 0.4253\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.46733\n",
      "Epoch 41/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1295 - acc: 0.4838 - val_loss: 0.1386 - val_acc: 0.4260\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.46733\n",
      "Epoch 42/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1292 - acc: 0.4880 - val_loss: 0.1391 - val_acc: 0.4287\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.46733\n",
      "Epoch 43/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1293 - acc: 0.4795 - val_loss: 0.1392 - val_acc: 0.4287\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.46733\n",
      "Epoch 44/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1292 - acc: 0.4803 - val_loss: 0.1392 - val_acc: 0.4273\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.46733\n",
      "Epoch 45/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1297 - acc: 0.4790 - val_loss: 0.1398 - val_acc: 0.4247\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.46733\n",
      "Epoch 46/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1293 - acc: 0.4793 - val_loss: 0.1389 - val_acc: 0.4253\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.46733\n",
      "Epoch 47/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1285 - acc: 0.4872 - val_loss: 0.1390 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.46733\n",
      "Epoch 48/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1296 - acc: 0.4803 - val_loss: 0.1399 - val_acc: 0.4180\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.46733\n",
      "Epoch 49/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1294 - acc: 0.4797 - val_loss: 0.1392 - val_acc: 0.4240\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.46733\n",
      "Epoch 50/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1285 - acc: 0.4890 - val_loss: 0.1399 - val_acc: 0.4207\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.46733\n",
      "Epoch 51/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1288 - acc: 0.4817 - val_loss: 0.1411 - val_acc: 0.4167\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.46733\n",
      "Epoch 52/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1289 - acc: 0.4817 - val_loss: 0.1399 - val_acc: 0.4213\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.46733\n",
      "Epoch 53/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1280 - acc: 0.4893 - val_loss: 0.1398 - val_acc: 0.4240\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.46733\n",
      "Epoch 54/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1289 - acc: 0.4862 - val_loss: 0.1404 - val_acc: 0.4220\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.46733\n",
      "Epoch 55/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1283 - acc: 0.4908 - val_loss: 0.1400 - val_acc: 0.4180\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.46733\n",
      "Epoch 56/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1283 - acc: 0.4840 - val_loss: 0.1396 - val_acc: 0.4193\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.46733\n",
      "Epoch 57/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1284 - acc: 0.4872 - val_loss: 0.1398 - val_acc: 0.4260\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.46733\n",
      "Epoch 58/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1274 - acc: 0.4910 - val_loss: 0.1396 - val_acc: 0.4147\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.46733\n",
      "Epoch 59/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1286 - acc: 0.4870 - val_loss: 0.1407 - val_acc: 0.4220\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.46733\n",
      "Epoch 60/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1288 - acc: 0.4815 - val_loss: 0.1399 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.46733\n",
      "Epoch 61/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1273 - acc: 0.4918 - val_loss: 0.1401 - val_acc: 0.4180\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.46733\n",
      "Epoch 62/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1283 - acc: 0.4863 - val_loss: 0.1410 - val_acc: 0.4133\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.46733\n",
      "Epoch 63/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1275 - acc: 0.4908 - val_loss: 0.1400 - val_acc: 0.4213\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.46733\n",
      "Epoch 64/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1270 - acc: 0.4945 - val_loss: 0.1406 - val_acc: 0.4147\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.46733\n",
      "Epoch 65/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1279 - acc: 0.4863 - val_loss: 0.1403 - val_acc: 0.4180\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.46733\n",
      "Epoch 66/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1272 - acc: 0.4902 - val_loss: 0.1423 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.46733\n",
      "Epoch 67/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1271 - acc: 0.4925 - val_loss: 0.1409 - val_acc: 0.4173\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.46733\n",
      "Epoch 68/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1269 - acc: 0.4970 - val_loss: 0.1406 - val_acc: 0.4180\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.46733\n",
      "Epoch 69/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1264 - acc: 0.4987 - val_loss: 0.1407 - val_acc: 0.4133\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.46733\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1265 - acc: 0.4962 - val_loss: 0.1434 - val_acc: 0.4040\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.46733\n",
      "Epoch 71/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1276 - acc: 0.4895 - val_loss: 0.1408 - val_acc: 0.4087\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.46733\n",
      "Epoch 72/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1279 - acc: 0.4923 - val_loss: 0.1415 - val_acc: 0.4113\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.46733\n",
      "Epoch 73/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1260 - acc: 0.4980 - val_loss: 0.1408 - val_acc: 0.4173\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.46733\n",
      "Epoch 74/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1264 - acc: 0.4987 - val_loss: 0.1410 - val_acc: 0.4193\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.46733\n",
      "Epoch 75/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1257 - acc: 0.5005 - val_loss: 0.1412 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.46733\n",
      "Epoch 76/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1276 - acc: 0.4895 - val_loss: 0.1411 - val_acc: 0.4133\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.46733\n",
      "Epoch 77/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1258 - acc: 0.4988 - val_loss: 0.1415 - val_acc: 0.4067\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.46733\n",
      "Epoch 78/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1263 - acc: 0.4967 - val_loss: 0.1433 - val_acc: 0.4033\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.46733\n",
      "Epoch 79/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1257 - acc: 0.5048 - val_loss: 0.1423 - val_acc: 0.4067\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.46733\n",
      "Epoch 80/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1267 - acc: 0.4975 - val_loss: 0.1415 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.46733\n",
      "Epoch 81/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1257 - acc: 0.5027 - val_loss: 0.1425 - val_acc: 0.4047\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.46733\n",
      "Epoch 82/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1260 - acc: 0.5000 - val_loss: 0.1421 - val_acc: 0.4047\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.46733\n",
      "Epoch 83/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1252 - acc: 0.5023 - val_loss: 0.1420 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.46733\n",
      "Epoch 84/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1262 - acc: 0.4977 - val_loss: 0.1416 - val_acc: 0.4180\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.46733\n",
      "Epoch 85/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1255 - acc: 0.4988 - val_loss: 0.1416 - val_acc: 0.4080\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.46733\n",
      "Epoch 86/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1248 - acc: 0.5100 - val_loss: 0.1434 - val_acc: 0.4040\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.46733\n",
      "Epoch 87/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1259 - acc: 0.5005 - val_loss: 0.1446 - val_acc: 0.4007\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.46733\n",
      "Epoch 88/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1258 - acc: 0.5013 - val_loss: 0.1433 - val_acc: 0.3993\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.46733\n",
      "Epoch 89/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1247 - acc: 0.5092 - val_loss: 0.1428 - val_acc: 0.4060\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.46733\n",
      "Epoch 90/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1252 - acc: 0.5078 - val_loss: 0.1427 - val_acc: 0.4040\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.46733\n",
      "Epoch 91/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1252 - acc: 0.5033 - val_loss: 0.1427 - val_acc: 0.4047\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.46733\n",
      "Epoch 92/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1253 - acc: 0.5035 - val_loss: 0.1447 - val_acc: 0.3953\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.46733\n",
      "Epoch 93/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1249 - acc: 0.5090 - val_loss: 0.1432 - val_acc: 0.4013\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.46733\n",
      "Epoch 94/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1254 - acc: 0.4997 - val_loss: 0.1423 - val_acc: 0.4207\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.46733\n",
      "Epoch 95/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1247 - acc: 0.5108 - val_loss: 0.1420 - val_acc: 0.4160\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.46733\n",
      "Epoch 96/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1240 - acc: 0.5120 - val_loss: 0.1425 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.46733\n",
      "Epoch 97/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1256 - acc: 0.5020 - val_loss: 0.1425 - val_acc: 0.4147\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.46733\n",
      "Epoch 98/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1239 - acc: 0.5112 - val_loss: 0.1430 - val_acc: 0.4040\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.46733\n",
      "Epoch 99/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1237 - acc: 0.5138 - val_loss: 0.1429 - val_acc: 0.4007\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.46733\n",
      "Epoch 100/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1245 - acc: 0.5092 - val_loss: 0.1429 - val_acc: 0.4013\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.46733\n",
      "Train on 5996 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1277 - acc: 0.4920 - val_loss: 0.1293 - val_acc: 0.4680\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.46733 to 0.46800, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 2/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1271 - acc: 0.4995 - val_loss: 0.1311 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.46800\n",
      "Epoch 3/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1271 - acc: 0.4968 - val_loss: 0.1301 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.46800\n",
      "Epoch 4/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1261 - acc: 0.5050 - val_loss: 0.1308 - val_acc: 0.4687\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.46800 to 0.46867, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 5/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1277 - acc: 0.4927 - val_loss: 0.1316 - val_acc: 0.4593\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.46867\n",
      "Epoch 6/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1261 - acc: 0.5062 - val_loss: 0.1314 - val_acc: 0.4540\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.46867\n",
      "Epoch 7/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1260 - acc: 0.5037 - val_loss: 0.1314 - val_acc: 0.4600\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.46867\n",
      "Epoch 8/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1266 - acc: 0.5022 - val_loss: 0.1341 - val_acc: 0.4453\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.46867\n",
      "Epoch 9/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1264 - acc: 0.4998 - val_loss: 0.1326 - val_acc: 0.4500\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.46867\n",
      "Epoch 10/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1252 - acc: 0.5097 - val_loss: 0.1330 - val_acc: 0.4480\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.46867\n",
      "Epoch 11/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1259 - acc: 0.5093 - val_loss: 0.1328 - val_acc: 0.4533\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.46867\n",
      "Epoch 12/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1253 - acc: 0.5085 - val_loss: 0.1333 - val_acc: 0.4493\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.46867\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1260 - acc: 0.5038 - val_loss: 0.1342 - val_acc: 0.4420\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.46867\n",
      "Epoch 14/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1264 - acc: 0.4953 - val_loss: 0.1326 - val_acc: 0.4520\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.46867\n",
      "Epoch 15/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1248 - acc: 0.5153 - val_loss: 0.1332 - val_acc: 0.4447\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.46867\n",
      "Epoch 16/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1254 - acc: 0.5042 - val_loss: 0.1341 - val_acc: 0.4373\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.46867\n",
      "Epoch 17/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1250 - acc: 0.5133 - val_loss: 0.1341 - val_acc: 0.4407\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.46867\n",
      "Epoch 18/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1259 - acc: 0.5078 - val_loss: 0.1345 - val_acc: 0.4413\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.46867\n",
      "Epoch 19/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1242 - acc: 0.5155 - val_loss: 0.1355 - val_acc: 0.4313\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.46867\n",
      "Epoch 20/100\n",
      "5996/5996 [==============================] - 0s 6us/step - loss: 0.1243 - acc: 0.5140 - val_loss: 0.1350 - val_acc: 0.4367\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.46867\n",
      "Epoch 21/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1254 - acc: 0.5080 - val_loss: 0.1381 - val_acc: 0.4253\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.46867\n",
      "Epoch 22/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1244 - acc: 0.5118 - val_loss: 0.1342 - val_acc: 0.4420\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.46867\n",
      "Epoch 23/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1239 - acc: 0.5167 - val_loss: 0.1349 - val_acc: 0.4440\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.46867\n",
      "Epoch 24/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1255 - acc: 0.5045 - val_loss: 0.1341 - val_acc: 0.4467\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.46867\n",
      "Epoch 25/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1235 - acc: 0.5190 - val_loss: 0.1357 - val_acc: 0.4373\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.46867\n",
      "Epoch 26/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1237 - acc: 0.5182 - val_loss: 0.1343 - val_acc: 0.4460\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.46867\n",
      "Epoch 27/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1245 - acc: 0.5122 - val_loss: 0.1364 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.46867\n",
      "Epoch 28/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1241 - acc: 0.5152 - val_loss: 0.1352 - val_acc: 0.4387\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.46867\n",
      "Epoch 29/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1237 - acc: 0.5173 - val_loss: 0.1359 - val_acc: 0.4380\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.46867\n",
      "Epoch 30/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1249 - acc: 0.5088 - val_loss: 0.1373 - val_acc: 0.4307\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.46867\n",
      "Epoch 31/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1236 - acc: 0.5183 - val_loss: 0.1358 - val_acc: 0.4427\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.46867\n",
      "Epoch 32/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1230 - acc: 0.5185 - val_loss: 0.1353 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.46867\n",
      "Epoch 33/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1234 - acc: 0.5162 - val_loss: 0.1417 - val_acc: 0.4073\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.46867\n",
      "Epoch 34/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1242 - acc: 0.5113 - val_loss: 0.1358 - val_acc: 0.4393\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.46867\n",
      "Epoch 35/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1230 - acc: 0.5248 - val_loss: 0.1354 - val_acc: 0.4380\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.46867\n",
      "Epoch 36/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1225 - acc: 0.5240 - val_loss: 0.1360 - val_acc: 0.4347\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.46867\n",
      "Epoch 37/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1239 - acc: 0.5148 - val_loss: 0.1382 - val_acc: 0.4260\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.46867\n",
      "Epoch 38/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1223 - acc: 0.5237 - val_loss: 0.1358 - val_acc: 0.4393\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.46867\n",
      "Epoch 39/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1245 - acc: 0.5107 - val_loss: 0.1360 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.46867\n",
      "Epoch 40/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1219 - acc: 0.5287 - val_loss: 0.1367 - val_acc: 0.4307\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.46867\n",
      "Epoch 41/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1224 - acc: 0.5238 - val_loss: 0.1372 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.46867\n",
      "Epoch 42/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1242 - acc: 0.5147 - val_loss: 0.1369 - val_acc: 0.4327\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.46867\n",
      "Epoch 43/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1226 - acc: 0.5260 - val_loss: 0.1370 - val_acc: 0.4353\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.46867\n",
      "Epoch 44/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1226 - acc: 0.5267 - val_loss: 0.1366 - val_acc: 0.4393\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.46867\n",
      "Epoch 45/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1229 - acc: 0.5187 - val_loss: 0.1374 - val_acc: 0.4300\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.46867\n",
      "Epoch 46/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1221 - acc: 0.5289 - val_loss: 0.1360 - val_acc: 0.4340\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.46867\n",
      "Epoch 47/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1214 - acc: 0.5304 - val_loss: 0.1370 - val_acc: 0.4313\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.46867\n",
      "Epoch 48/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1222 - acc: 0.5267 - val_loss: 0.1395 - val_acc: 0.4273\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.46867\n",
      "Epoch 49/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1235 - acc: 0.5127 - val_loss: 0.1383 - val_acc: 0.4320\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.46867\n",
      "Epoch 50/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1216 - acc: 0.5285 - val_loss: 0.1382 - val_acc: 0.4327\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.46867\n",
      "Epoch 51/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1229 - acc: 0.5158 - val_loss: 0.1371 - val_acc: 0.4320\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.46867\n",
      "Epoch 52/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1212 - acc: 0.5290 - val_loss: 0.1365 - val_acc: 0.4327\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.46867\n",
      "Epoch 53/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1218 - acc: 0.5292 - val_loss: 0.1404 - val_acc: 0.4100\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.46867\n",
      "Epoch 54/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1215 - acc: 0.5289 - val_loss: 0.1372 - val_acc: 0.4327\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.46867\n",
      "Epoch 55/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1217 - acc: 0.5275 - val_loss: 0.1397 - val_acc: 0.4167\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.46867\n",
      "Epoch 56/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1230 - acc: 0.5217 - val_loss: 0.1370 - val_acc: 0.4273\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.46867\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1206 - acc: 0.5317 - val_loss: 0.1374 - val_acc: 0.4293\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.46867\n",
      "Epoch 58/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1206 - acc: 0.5334 - val_loss: 0.1372 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.46867\n",
      "Epoch 59/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1213 - acc: 0.5312 - val_loss: 0.1403 - val_acc: 0.4087\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.46867\n",
      "Epoch 60/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1236 - acc: 0.5213 - val_loss: 0.1376 - val_acc: 0.4260\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.46867\n",
      "Epoch 61/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1208 - acc: 0.5360 - val_loss: 0.1393 - val_acc: 0.4173\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.46867\n",
      "Epoch 62/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1211 - acc: 0.5317 - val_loss: 0.1383 - val_acc: 0.4173\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.46867\n",
      "Epoch 63/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1214 - acc: 0.5339 - val_loss: 0.1387 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.46867\n",
      "Epoch 64/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1214 - acc: 0.5282 - val_loss: 0.1386 - val_acc: 0.4200\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.46867\n",
      "Epoch 65/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1203 - acc: 0.5370 - val_loss: 0.1380 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.46867\n",
      "Epoch 66/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1199 - acc: 0.5412 - val_loss: 0.1399 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.46867\n",
      "Epoch 67/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1234 - acc: 0.5128 - val_loss: 0.1391 - val_acc: 0.4227\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.46867\n",
      "Epoch 68/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1201 - acc: 0.5324 - val_loss: 0.1383 - val_acc: 0.4300\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.46867\n",
      "Epoch 69/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1198 - acc: 0.5399 - val_loss: 0.1396 - val_acc: 0.4133\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.46867\n",
      "Epoch 70/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1223 - acc: 0.5255 - val_loss: 0.1383 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.46867\n",
      "Epoch 71/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1196 - acc: 0.5444 - val_loss: 0.1386 - val_acc: 0.4240\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.46867\n",
      "Epoch 72/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1198 - acc: 0.5395 - val_loss: 0.1396 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.46867\n",
      "Epoch 73/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1215 - acc: 0.5282 - val_loss: 0.1394 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.46867\n",
      "Epoch 74/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1195 - acc: 0.5394 - val_loss: 0.1393 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.46867\n",
      "Epoch 75/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1212 - acc: 0.5297 - val_loss: 0.1400 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.46867\n",
      "Epoch 76/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1191 - acc: 0.5437 - val_loss: 0.1400 - val_acc: 0.4273\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.46867\n",
      "Epoch 77/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1193 - acc: 0.5444 - val_loss: 0.1386 - val_acc: 0.4220\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.46867\n",
      "Epoch 78/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1223 - acc: 0.5277 - val_loss: 0.1391 - val_acc: 0.4193\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.46867\n",
      "Epoch 79/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1191 - acc: 0.5449 - val_loss: 0.1389 - val_acc: 0.4220\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.46867\n",
      "Epoch 80/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1213 - acc: 0.5320 - val_loss: 0.1399 - val_acc: 0.4160\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.46867\n",
      "Epoch 81/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1194 - acc: 0.5424 - val_loss: 0.1391 - val_acc: 0.4273\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.46867\n",
      "Epoch 82/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1189 - acc: 0.5482 - val_loss: 0.1414 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.46867\n",
      "Epoch 83/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1194 - acc: 0.5417 - val_loss: 0.1403 - val_acc: 0.4160\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.46867\n",
      "Epoch 84/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1212 - acc: 0.5322 - val_loss: 0.1419 - val_acc: 0.4287\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.46867\n",
      "Epoch 85/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1198 - acc: 0.5414 - val_loss: 0.1392 - val_acc: 0.4240\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.46867\n",
      "Epoch 86/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1194 - acc: 0.5447 - val_loss: 0.1406 - val_acc: 0.4180\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.46867\n",
      "Epoch 87/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1192 - acc: 0.5477 - val_loss: 0.1399 - val_acc: 0.4153\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.46867\n",
      "Epoch 88/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1185 - acc: 0.5462 - val_loss: 0.1400 - val_acc: 0.4147\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.46867\n",
      "Epoch 89/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1201 - acc: 0.5362 - val_loss: 0.1406 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.46867\n",
      "Epoch 90/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1192 - acc: 0.5449 - val_loss: 0.1400 - val_acc: 0.4240\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.46867\n",
      "Epoch 91/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1187 - acc: 0.5450 - val_loss: 0.1397 - val_acc: 0.4167\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.46867\n",
      "Epoch 92/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1197 - acc: 0.5422 - val_loss: 0.1400 - val_acc: 0.4180\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.46867\n",
      "Epoch 93/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1186 - acc: 0.5449 - val_loss: 0.1398 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.46867\n",
      "Epoch 94/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1178 - acc: 0.5527 - val_loss: 0.1400 - val_acc: 0.4160\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.46867\n",
      "Epoch 95/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1204 - acc: 0.5375 - val_loss: 0.1401 - val_acc: 0.4073\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.46867\n",
      "Epoch 96/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1188 - acc: 0.5464 - val_loss: 0.1400 - val_acc: 0.4167\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.46867\n",
      "Epoch 97/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1188 - acc: 0.5412 - val_loss: 0.1433 - val_acc: 0.4167\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.46867\n",
      "Epoch 98/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1188 - acc: 0.5452 - val_loss: 0.1416 - val_acc: 0.4153\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.46867\n",
      "Epoch 99/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1180 - acc: 0.5509 - val_loss: 0.1412 - val_acc: 0.4227\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.46867\n",
      "Epoch 100/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1179 - acc: 0.5529 - val_loss: 0.1416 - val_acc: 0.4213\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.46867\n",
      "Train on 5996 samples, validate on 1500 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1225 - acc: 0.5254 - val_loss: 0.1217 - val_acc: 0.5313\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.46867 to 0.53133, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 2/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1236 - acc: 0.5185 - val_loss: 0.1230 - val_acc: 0.5247\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.53133\n",
      "Epoch 3/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1211 - acc: 0.5299 - val_loss: 0.1226 - val_acc: 0.5260\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.53133\n",
      "Epoch 4/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1232 - acc: 0.5197 - val_loss: 0.1253 - val_acc: 0.5080\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.53133\n",
      "Epoch 5/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1210 - acc: 0.5344 - val_loss: 0.1244 - val_acc: 0.5180\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.53133\n",
      "Epoch 6/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1228 - acc: 0.5213 - val_loss: 0.1251 - val_acc: 0.5180\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.53133\n",
      "Epoch 7/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1219 - acc: 0.5254 - val_loss: 0.1247 - val_acc: 0.5147\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.53133\n",
      "Epoch 8/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1214 - acc: 0.5319 - val_loss: 0.1262 - val_acc: 0.5013\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.53133\n",
      "Epoch 9/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1206 - acc: 0.5369 - val_loss: 0.1272 - val_acc: 0.4967\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.53133\n",
      "Epoch 10/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1211 - acc: 0.5277 - val_loss: 0.1255 - val_acc: 0.5033\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.53133\n",
      "Epoch 11/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1210 - acc: 0.5304 - val_loss: 0.1288 - val_acc: 0.4860\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.53133\n",
      "Epoch 12/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1216 - acc: 0.5309 - val_loss: 0.1260 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.53133\n",
      "Epoch 13/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1198 - acc: 0.5417 - val_loss: 0.1281 - val_acc: 0.5013\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.53133\n",
      "Epoch 14/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1225 - acc: 0.5238 - val_loss: 0.1267 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.53133\n",
      "Epoch 15/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1195 - acc: 0.5450 - val_loss: 0.1270 - val_acc: 0.5047\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.53133\n",
      "Epoch 16/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1195 - acc: 0.5437 - val_loss: 0.1298 - val_acc: 0.4907\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.53133\n",
      "Epoch 17/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1224 - acc: 0.5243 - val_loss: 0.1275 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.53133\n",
      "Epoch 18/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1202 - acc: 0.5377 - val_loss: 0.1279 - val_acc: 0.5060\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.53133\n",
      "Epoch 19/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1190 - acc: 0.5485 - val_loss: 0.1274 - val_acc: 0.4913\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.53133\n",
      "Epoch 20/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1190 - acc: 0.5520 - val_loss: 0.1278 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.53133\n",
      "Epoch 21/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1216 - acc: 0.5299 - val_loss: 0.1279 - val_acc: 0.4953\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.53133\n",
      "Epoch 22/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1206 - acc: 0.5364 - val_loss: 0.1295 - val_acc: 0.4973\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.53133\n",
      "Epoch 23/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1188 - acc: 0.5447 - val_loss: 0.1282 - val_acc: 0.4980\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.53133\n",
      "Epoch 24/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1184 - acc: 0.5472 - val_loss: 0.1287 - val_acc: 0.4993\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.53133\n",
      "Epoch 25/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1215 - acc: 0.5327 - val_loss: 0.1289 - val_acc: 0.5020\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.53133\n",
      "Epoch 26/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1187 - acc: 0.5499 - val_loss: 0.1301 - val_acc: 0.4820\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.53133\n",
      "Epoch 27/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1203 - acc: 0.5364 - val_loss: 0.1307 - val_acc: 0.4733\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.53133\n",
      "Epoch 28/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1185 - acc: 0.5497 - val_loss: 0.1290 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.53133\n",
      "Epoch 29/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1179 - acc: 0.5517 - val_loss: 0.1299 - val_acc: 0.4753\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.53133\n",
      "Epoch 30/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1214 - acc: 0.5305 - val_loss: 0.1306 - val_acc: 0.4713\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.53133\n",
      "Epoch 31/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1187 - acc: 0.5472 - val_loss: 0.1303 - val_acc: 0.4867\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.53133\n",
      "Epoch 32/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1186 - acc: 0.5455 - val_loss: 0.1311 - val_acc: 0.4727\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.53133\n",
      "Epoch 33/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1197 - acc: 0.5415 - val_loss: 0.1301 - val_acc: 0.4860\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.53133\n",
      "Epoch 34/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1180 - acc: 0.5507 - val_loss: 0.1300 - val_acc: 0.4827\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.53133\n",
      "Epoch 35/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1195 - acc: 0.5400 - val_loss: 0.1306 - val_acc: 0.4913\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.53133\n",
      "Epoch 36/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1188 - acc: 0.5479 - val_loss: 0.1309 - val_acc: 0.4827\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.53133\n",
      "Epoch 37/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1172 - acc: 0.5557 - val_loss: 0.1300 - val_acc: 0.4913\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.53133\n",
      "Epoch 38/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1199 - acc: 0.5347 - val_loss: 0.1305 - val_acc: 0.4833\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.53133\n",
      "Epoch 39/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1174 - acc: 0.5510 - val_loss: 0.1314 - val_acc: 0.4787\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.53133\n",
      "Epoch 40/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1175 - acc: 0.5549 - val_loss: 0.1314 - val_acc: 0.4773\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.53133\n",
      "Epoch 41/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1190 - acc: 0.5432 - val_loss: 0.1322 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.53133\n",
      "Epoch 42/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1193 - acc: 0.5439 - val_loss: 0.1321 - val_acc: 0.4727\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.53133\n",
      "Epoch 43/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1175 - acc: 0.5540 - val_loss: 0.1319 - val_acc: 0.4733\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.53133\n",
      "Epoch 44/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1179 - acc: 0.5515 - val_loss: 0.1325 - val_acc: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: val_acc did not improve from 0.53133\n",
      "Epoch 45/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1185 - acc: 0.5455 - val_loss: 0.1312 - val_acc: 0.4853\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.53133\n",
      "Epoch 46/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1180 - acc: 0.5510 - val_loss: 0.1325 - val_acc: 0.4747\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.53133\n",
      "Epoch 47/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1168 - acc: 0.5555 - val_loss: 0.1321 - val_acc: 0.4847\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.53133\n",
      "Epoch 48/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1175 - acc: 0.5529 - val_loss: 0.1312 - val_acc: 0.4780\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.53133\n",
      "Epoch 49/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1184 - acc: 0.5497 - val_loss: 0.1323 - val_acc: 0.4813\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.53133\n",
      "Epoch 50/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1181 - acc: 0.5480 - val_loss: 0.1322 - val_acc: 0.4740\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.53133\n",
      "Epoch 51/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1169 - acc: 0.5544 - val_loss: 0.1345 - val_acc: 0.4580\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.53133\n",
      "Epoch 52/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1169 - acc: 0.5592 - val_loss: 0.1322 - val_acc: 0.4713\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.53133\n",
      "Epoch 53/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1170 - acc: 0.5557 - val_loss: 0.1361 - val_acc: 0.4453\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.53133\n",
      "Epoch 54/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1183 - acc: 0.5492 - val_loss: 0.1333 - val_acc: 0.4633\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.53133\n",
      "Epoch 55/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1167 - acc: 0.5535 - val_loss: 0.1332 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.53133\n",
      "Epoch 56/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1179 - acc: 0.5515 - val_loss: 0.1329 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.53133\n",
      "Epoch 57/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1160 - acc: 0.5609 - val_loss: 0.1330 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.53133\n",
      "Epoch 58/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1166 - acc: 0.5580 - val_loss: 0.1371 - val_acc: 0.4273\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.53133\n",
      "Epoch 59/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1177 - acc: 0.5529 - val_loss: 0.1339 - val_acc: 0.4600\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.53133\n",
      "Epoch 60/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1164 - acc: 0.5579 - val_loss: 0.1324 - val_acc: 0.4753\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.53133\n",
      "Epoch 61/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1154 - acc: 0.5642 - val_loss: 0.1328 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.53133\n",
      "Epoch 62/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1180 - acc: 0.5457 - val_loss: 0.1386 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.53133\n",
      "Epoch 63/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1173 - acc: 0.5547 - val_loss: 0.1327 - val_acc: 0.4727\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.53133\n",
      "Epoch 64/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1150 - acc: 0.5647 - val_loss: 0.1331 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.53133\n",
      "Epoch 65/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1177 - acc: 0.5542 - val_loss: 0.1343 - val_acc: 0.4713\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.53133\n",
      "Epoch 66/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1161 - acc: 0.5555 - val_loss: 0.1342 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.53133\n",
      "Epoch 67/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1164 - acc: 0.5580 - val_loss: 0.1336 - val_acc: 0.4733\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.53133\n",
      "Epoch 68/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1154 - acc: 0.5615 - val_loss: 0.1368 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.53133\n",
      "Epoch 69/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1180 - acc: 0.5487 - val_loss: 0.1348 - val_acc: 0.4547\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.53133\n",
      "Epoch 70/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1157 - acc: 0.5640 - val_loss: 0.1339 - val_acc: 0.4713\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.53133\n",
      "Epoch 71/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1169 - acc: 0.5525 - val_loss: 0.1352 - val_acc: 0.4620\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.53133\n",
      "Epoch 72/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1146 - acc: 0.5705 - val_loss: 0.1340 - val_acc: 0.4733\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.53133\n",
      "Epoch 73/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1161 - acc: 0.5650 - val_loss: 0.1345 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.53133\n",
      "Epoch 74/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1169 - acc: 0.5562 - val_loss: 0.1349 - val_acc: 0.4640\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.53133\n",
      "Epoch 75/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1145 - acc: 0.5707 - val_loss: 0.1348 - val_acc: 0.4633\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.53133\n",
      "Epoch 76/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1174 - acc: 0.5519 - val_loss: 0.1361 - val_acc: 0.4427\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.53133\n",
      "Epoch 77/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1148 - acc: 0.5685 - val_loss: 0.1342 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.53133\n",
      "Epoch 78/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1145 - acc: 0.5662 - val_loss: 0.1374 - val_acc: 0.4447\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.53133\n",
      "Epoch 79/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1174 - acc: 0.5495 - val_loss: 0.1349 - val_acc: 0.4600\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.53133\n",
      "Epoch 80/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1145 - acc: 0.5665 - val_loss: 0.1351 - val_acc: 0.4587\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.53133\n",
      "Epoch 81/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1166 - acc: 0.5552 - val_loss: 0.1351 - val_acc: 0.4600\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.53133\n",
      "Epoch 82/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1138 - acc: 0.5707 - val_loss: 0.1353 - val_acc: 0.4627\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.53133\n",
      "Epoch 83/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1168 - acc: 0.5565 - val_loss: 0.1361 - val_acc: 0.4447\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.53133\n",
      "Epoch 84/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1152 - acc: 0.5632 - val_loss: 0.1351 - val_acc: 0.4633\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.53133\n",
      "Epoch 85/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1150 - acc: 0.5677 - val_loss: 0.1355 - val_acc: 0.4600\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.53133\n",
      "Epoch 86/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1140 - acc: 0.5677 - val_loss: 0.1363 - val_acc: 0.4540\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.53133\n",
      "Epoch 87/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1166 - acc: 0.5567 - val_loss: 0.1366 - val_acc: 0.4653\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.53133\n",
      "Epoch 88/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1147 - acc: 0.5640 - val_loss: 0.1371 - val_acc: 0.4540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00088: val_acc did not improve from 0.53133\n",
      "Epoch 89/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1141 - acc: 0.5655 - val_loss: 0.1363 - val_acc: 0.4640\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.53133\n",
      "Epoch 90/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1161 - acc: 0.5570 - val_loss: 0.1360 - val_acc: 0.4680\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.53133\n",
      "Epoch 91/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1140 - acc: 0.5674 - val_loss: 0.1378 - val_acc: 0.4540\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.53133\n",
      "Epoch 92/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1150 - acc: 0.5674 - val_loss: 0.1352 - val_acc: 0.4673\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.53133\n",
      "Epoch 93/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1150 - acc: 0.5670 - val_loss: 0.1376 - val_acc: 0.4513\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.53133\n",
      "Epoch 94/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1150 - acc: 0.5665 - val_loss: 0.1368 - val_acc: 0.4513\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.53133\n",
      "Epoch 95/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1147 - acc: 0.5642 - val_loss: 0.1379 - val_acc: 0.4487\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.53133\n",
      "Epoch 96/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1145 - acc: 0.5699 - val_loss: 0.1362 - val_acc: 0.4607\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.53133\n",
      "Epoch 97/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1131 - acc: 0.5751 - val_loss: 0.1358 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.53133\n",
      "Epoch 98/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1156 - acc: 0.5599 - val_loss: 0.1366 - val_acc: 0.4647\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.53133\n",
      "Epoch 99/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1141 - acc: 0.5674 - val_loss: 0.1371 - val_acc: 0.4553\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.53133\n",
      "Epoch 100/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1143 - acc: 0.5709 - val_loss: 0.1373 - val_acc: 0.4573\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.53133\n",
      "Train on 5996 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1179 - acc: 0.5527 - val_loss: 0.1223 - val_acc: 0.5267\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.53133\n",
      "Epoch 2/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1171 - acc: 0.5532 - val_loss: 0.1254 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.53133\n",
      "Epoch 3/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1192 - acc: 0.5397 - val_loss: 0.1212 - val_acc: 0.5273\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.53133\n",
      "Epoch 4/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1161 - acc: 0.5602 - val_loss: 0.1204 - val_acc: 0.5380\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.53133 to 0.53800, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 5/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1168 - acc: 0.5532 - val_loss: 0.1222 - val_acc: 0.5287\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.53800\n",
      "Epoch 6/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1183 - acc: 0.5490 - val_loss: 0.1214 - val_acc: 0.5267\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.53800\n",
      "Epoch 7/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1157 - acc: 0.5637 - val_loss: 0.1238 - val_acc: 0.5213\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.53800\n",
      "Epoch 8/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1170 - acc: 0.5479 - val_loss: 0.1253 - val_acc: 0.5073\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.53800\n",
      "Epoch 9/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1175 - acc: 0.5530 - val_loss: 0.1244 - val_acc: 0.5140\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.53800\n",
      "Epoch 10/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1168 - acc: 0.5527 - val_loss: 0.1228 - val_acc: 0.5193\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.53800\n",
      "Epoch 11/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1155 - acc: 0.5604 - val_loss: 0.1238 - val_acc: 0.5187\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.53800\n",
      "Epoch 12/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1159 - acc: 0.5590 - val_loss: 0.1273 - val_acc: 0.4967\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.53800\n",
      "Epoch 13/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1169 - acc: 0.5515 - val_loss: 0.1238 - val_acc: 0.5153\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.53800\n",
      "Epoch 14/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1152 - acc: 0.5650 - val_loss: 0.1260 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.53800\n",
      "Epoch 15/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1177 - acc: 0.5504 - val_loss: 0.1243 - val_acc: 0.5140\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.53800\n",
      "Epoch 16/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1147 - acc: 0.5669 - val_loss: 0.1283 - val_acc: 0.5027\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.53800\n",
      "Epoch 17/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1165 - acc: 0.5624 - val_loss: 0.1253 - val_acc: 0.5153\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.53800\n",
      "Epoch 18/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1148 - acc: 0.5677 - val_loss: 0.1250 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.53800\n",
      "Epoch 19/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1172 - acc: 0.5552 - val_loss: 0.1253 - val_acc: 0.5093\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.53800\n",
      "Epoch 20/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1158 - acc: 0.5584 - val_loss: 0.1246 - val_acc: 0.5093\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.53800\n",
      "Epoch 21/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1142 - acc: 0.5725 - val_loss: 0.1247 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.53800\n",
      "Epoch 22/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1151 - acc: 0.5629 - val_loss: 0.1255 - val_acc: 0.5060\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.53800\n",
      "Epoch 23/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1152 - acc: 0.5679 - val_loss: 0.1248 - val_acc: 0.5013\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.53800\n",
      "Epoch 24/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1139 - acc: 0.5729 - val_loss: 0.1253 - val_acc: 0.5060\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.53800\n",
      "Epoch 25/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1155 - acc: 0.5684 - val_loss: 0.1298 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.53800\n",
      "Epoch 26/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1157 - acc: 0.5650 - val_loss: 0.1255 - val_acc: 0.4980\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.53800\n",
      "Epoch 27/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1141 - acc: 0.5714 - val_loss: 0.1263 - val_acc: 0.5013\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.53800\n",
      "Epoch 28/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1152 - acc: 0.5632 - val_loss: 0.1257 - val_acc: 0.5033\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.53800\n",
      "Epoch 29/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1146 - acc: 0.5724 - val_loss: 0.1269 - val_acc: 0.4967\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.53800\n",
      "Epoch 30/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1154 - acc: 0.5670 - val_loss: 0.1262 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.53800\n",
      "Epoch 31/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1141 - acc: 0.5699 - val_loss: 0.1268 - val_acc: 0.5020\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.53800\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1141 - acc: 0.5734 - val_loss: 0.1277 - val_acc: 0.4920\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.53800\n",
      "Epoch 33/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1149 - acc: 0.5680 - val_loss: 0.1268 - val_acc: 0.4993\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.53800\n",
      "Epoch 34/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1138 - acc: 0.5737 - val_loss: 0.1269 - val_acc: 0.4947\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.53800\n",
      "Epoch 35/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1148 - acc: 0.5724 - val_loss: 0.1271 - val_acc: 0.4967\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.53800\n",
      "Epoch 36/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1133 - acc: 0.5756 - val_loss: 0.1279 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.53800\n",
      "Epoch 37/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1132 - acc: 0.5777 - val_loss: 0.1275 - val_acc: 0.4920\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.53800\n",
      "Epoch 38/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1160 - acc: 0.5572 - val_loss: 0.1275 - val_acc: 0.4913\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.53800\n",
      "Epoch 39/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1138 - acc: 0.5740 - val_loss: 0.1286 - val_acc: 0.4860\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.53800\n",
      "Epoch 40/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1133 - acc: 0.5774 - val_loss: 0.1278 - val_acc: 0.4913\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.53800\n",
      "Epoch 41/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1132 - acc: 0.5749 - val_loss: 0.1309 - val_acc: 0.4780\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.53800\n",
      "Epoch 42/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1144 - acc: 0.5729 - val_loss: 0.1284 - val_acc: 0.4873\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.53800\n",
      "Epoch 43/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1140 - acc: 0.5734 - val_loss: 0.1308 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.53800\n",
      "Epoch 44/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1141 - acc: 0.5740 - val_loss: 0.1308 - val_acc: 0.4773\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.53800\n",
      "Epoch 45/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1135 - acc: 0.5806 - val_loss: 0.1284 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.53800\n",
      "Epoch 46/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1129 - acc: 0.5695 - val_loss: 0.1323 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.53800\n",
      "Epoch 47/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1133 - acc: 0.5767 - val_loss: 0.1300 - val_acc: 0.4773\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.53800\n",
      "Epoch 48/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1133 - acc: 0.5772 - val_loss: 0.1291 - val_acc: 0.4973\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.53800\n",
      "Epoch 49/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1126 - acc: 0.5809 - val_loss: 0.1322 - val_acc: 0.4653\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.53800\n",
      "Epoch 50/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1149 - acc: 0.5662 - val_loss: 0.1308 - val_acc: 0.4733\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.53800\n",
      "Epoch 51/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1117 - acc: 0.5836 - val_loss: 0.1305 - val_acc: 0.4773\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.53800\n",
      "Epoch 52/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1129 - acc: 0.5776 - val_loss: 0.1303 - val_acc: 0.4847\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.53800\n",
      "Epoch 53/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1126 - acc: 0.5774 - val_loss: 0.1347 - val_acc: 0.4640\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.53800\n",
      "Epoch 54/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1138 - acc: 0.5732 - val_loss: 0.1311 - val_acc: 0.4740\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.53800\n",
      "Epoch 55/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1115 - acc: 0.5849 - val_loss: 0.1308 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.53800\n",
      "Epoch 56/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1149 - acc: 0.5689 - val_loss: 0.1304 - val_acc: 0.4780\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.53800\n",
      "Epoch 57/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1116 - acc: 0.5882 - val_loss: 0.1316 - val_acc: 0.4773\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.53800\n",
      "Epoch 58/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1131 - acc: 0.5757 - val_loss: 0.1333 - val_acc: 0.4647\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.53800\n",
      "Epoch 59/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1125 - acc: 0.5807 - val_loss: 0.1297 - val_acc: 0.4847\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.53800\n",
      "Epoch 60/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1109 - acc: 0.5861 - val_loss: 0.1294 - val_acc: 0.4867\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.53800\n",
      "Epoch 61/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1107 - acc: 0.5899 - val_loss: 0.1292 - val_acc: 0.4867\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.53800\n",
      "Epoch 62/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1163 - acc: 0.5619 - val_loss: 0.1305 - val_acc: 0.4720\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.53800\n",
      "Epoch 63/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1113 - acc: 0.5861 - val_loss: 0.1298 - val_acc: 0.4873\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.53800\n",
      "Epoch 64/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1112 - acc: 0.5882 - val_loss: 0.1312 - val_acc: 0.4680\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.53800\n",
      "Epoch 65/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1139 - acc: 0.5776 - val_loss: 0.1301 - val_acc: 0.4847\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.53800\n",
      "Epoch 66/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1121 - acc: 0.5886 - val_loss: 0.1294 - val_acc: 0.4887\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.53800\n",
      "Epoch 67/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1112 - acc: 0.5882 - val_loss: 0.1298 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.53800\n",
      "Epoch 68/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1117 - acc: 0.5831 - val_loss: 0.1301 - val_acc: 0.4827\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.53800\n",
      "Epoch 69/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1115 - acc: 0.5844 - val_loss: 0.1301 - val_acc: 0.4807\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.53800\n",
      "Epoch 70/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1131 - acc: 0.5801 - val_loss: 0.1308 - val_acc: 0.4760\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.53800\n",
      "Epoch 71/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1103 - acc: 0.5911 - val_loss: 0.1307 - val_acc: 0.4760\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.53800\n",
      "Epoch 72/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1137 - acc: 0.5695 - val_loss: 0.1314 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.53800\n",
      "Epoch 73/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1109 - acc: 0.5899 - val_loss: 0.1330 - val_acc: 0.4653\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.53800\n",
      "Epoch 74/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1123 - acc: 0.5804 - val_loss: 0.1344 - val_acc: 0.4633\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.53800\n",
      "Epoch 75/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1112 - acc: 0.5849 - val_loss: 0.1327 - val_acc: 0.4773\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.53800\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1120 - acc: 0.5814 - val_loss: 0.1327 - val_acc: 0.4680\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.53800\n",
      "Epoch 77/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1102 - acc: 0.5961 - val_loss: 0.1304 - val_acc: 0.4787\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.53800\n",
      "Epoch 78/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1128 - acc: 0.5787 - val_loss: 0.1316 - val_acc: 0.4653\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.53800\n",
      "Epoch 79/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1119 - acc: 0.5816 - val_loss: 0.1319 - val_acc: 0.4740\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.53800\n",
      "Epoch 80/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1098 - acc: 0.5957 - val_loss: 0.1364 - val_acc: 0.4600\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.53800\n",
      "Epoch 81/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1122 - acc: 0.5791 - val_loss: 0.1324 - val_acc: 0.4700\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.53800\n",
      "Epoch 82/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1117 - acc: 0.5832 - val_loss: 0.1349 - val_acc: 0.4633\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.53800\n",
      "Epoch 83/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1113 - acc: 0.5876 - val_loss: 0.1343 - val_acc: 0.4660\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.53800\n",
      "Epoch 84/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1105 - acc: 0.5924 - val_loss: 0.1319 - val_acc: 0.4733\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.53800\n",
      "Epoch 85/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1095 - acc: 0.5942 - val_loss: 0.1377 - val_acc: 0.4493\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.53800\n",
      "Epoch 86/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1115 - acc: 0.5802 - val_loss: 0.1340 - val_acc: 0.4640\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.53800\n",
      "Epoch 87/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1094 - acc: 0.5946 - val_loss: 0.1354 - val_acc: 0.4607\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.53800\n",
      "Epoch 88/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1118 - acc: 0.5801 - val_loss: 0.1344 - val_acc: 0.4647\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.53800\n",
      "Epoch 89/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1120 - acc: 0.5807 - val_loss: 0.1336 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.53800\n",
      "Epoch 90/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1100 - acc: 0.5921 - val_loss: 0.1340 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.53800\n",
      "Epoch 91/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1131 - acc: 0.5772 - val_loss: 0.1342 - val_acc: 0.4573\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.53800\n",
      "Epoch 92/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1094 - acc: 0.5917 - val_loss: 0.1323 - val_acc: 0.4687\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.53800\n",
      "Epoch 93/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1090 - acc: 0.5972 - val_loss: 0.1334 - val_acc: 0.4593\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.53800\n",
      "Epoch 94/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1112 - acc: 0.5859 - val_loss: 0.1362 - val_acc: 0.4607\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.53800\n",
      "Epoch 95/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1114 - acc: 0.5844 - val_loss: 0.1361 - val_acc: 0.4573\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.53800\n",
      "Epoch 96/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1096 - acc: 0.5936 - val_loss: 0.1337 - val_acc: 0.4673\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.53800\n",
      "Epoch 97/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1112 - acc: 0.5861 - val_loss: 0.1366 - val_acc: 0.4427\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.53800\n",
      "Epoch 98/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1103 - acc: 0.5919 - val_loss: 0.1332 - val_acc: 0.4627\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.53800\n",
      "Epoch 99/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1103 - acc: 0.5882 - val_loss: 0.1357 - val_acc: 0.4527\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.53800\n",
      "Epoch 100/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1103 - acc: 0.5864 - val_loss: 0.1358 - val_acc: 0.4580\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.53800\n",
      "Train on 5996 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1147 - acc: 0.5654 - val_loss: 0.1169 - val_acc: 0.5507\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.53800 to 0.55067, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 2/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1136 - acc: 0.5777 - val_loss: 0.1171 - val_acc: 0.5507\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.55067 to 0.55067, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 3/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1130 - acc: 0.5752 - val_loss: 0.1172 - val_acc: 0.5540\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.55067 to 0.55400, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 4/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1147 - acc: 0.5657 - val_loss: 0.1180 - val_acc: 0.5520\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.55400\n",
      "Epoch 5/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1115 - acc: 0.5846 - val_loss: 0.1180 - val_acc: 0.5460\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.55400\n",
      "Epoch 6/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1135 - acc: 0.5747 - val_loss: 0.1195 - val_acc: 0.5373\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.55400\n",
      "Epoch 7/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1134 - acc: 0.5729 - val_loss: 0.1201 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.55400\n",
      "Epoch 8/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1144 - acc: 0.5677 - val_loss: 0.1205 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.55400\n",
      "Epoch 9/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1119 - acc: 0.5817 - val_loss: 0.1199 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.55400\n",
      "Epoch 10/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1112 - acc: 0.5839 - val_loss: 0.1214 - val_acc: 0.5427\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.55400\n",
      "Epoch 11/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1137 - acc: 0.5735 - val_loss: 0.1217 - val_acc: 0.5360\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.55400\n",
      "Epoch 12/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1110 - acc: 0.5886 - val_loss: 0.1214 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.55400\n",
      "Epoch 13/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1144 - acc: 0.5742 - val_loss: 0.1209 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.55400\n",
      "Epoch 14/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1103 - acc: 0.5886 - val_loss: 0.1204 - val_acc: 0.5413\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.55400\n",
      "Epoch 15/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1111 - acc: 0.5846 - val_loss: 0.1275 - val_acc: 0.5020\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.55400\n",
      "Epoch 16/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1146 - acc: 0.5677 - val_loss: 0.1219 - val_acc: 0.5327\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.55400\n",
      "Epoch 17/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1125 - acc: 0.5789 - val_loss: 0.1250 - val_acc: 0.5160\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.55400\n",
      "Epoch 18/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1107 - acc: 0.5889 - val_loss: 0.1236 - val_acc: 0.5307\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.55400\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1111 - acc: 0.5847 - val_loss: 0.1235 - val_acc: 0.5233\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.55400\n",
      "Epoch 20/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1115 - acc: 0.5849 - val_loss: 0.1220 - val_acc: 0.5260\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.55400\n",
      "Epoch 21/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1108 - acc: 0.5899 - val_loss: 0.1268 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.55400\n",
      "Epoch 22/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1123 - acc: 0.5839 - val_loss: 0.1258 - val_acc: 0.5147\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.55400\n",
      "Epoch 23/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1125 - acc: 0.5812 - val_loss: 0.1231 - val_acc: 0.5193\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.55400\n",
      "Epoch 24/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1098 - acc: 0.5947 - val_loss: 0.1257 - val_acc: 0.5140\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.55400\n",
      "Epoch 25/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1130 - acc: 0.5819 - val_loss: 0.1267 - val_acc: 0.5140\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.55400\n",
      "Epoch 26/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1108 - acc: 0.5887 - val_loss: 0.1243 - val_acc: 0.5207\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.55400\n",
      "Epoch 27/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1095 - acc: 0.5962 - val_loss: 0.1251 - val_acc: 0.5160\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.55400\n",
      "Epoch 28/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1124 - acc: 0.5779 - val_loss: 0.1232 - val_acc: 0.5193\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.55400\n",
      "Epoch 29/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1095 - acc: 0.5942 - val_loss: 0.1263 - val_acc: 0.5120\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.55400\n",
      "Epoch 30/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1132 - acc: 0.5767 - val_loss: 0.1237 - val_acc: 0.5173\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.55400\n",
      "Epoch 31/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1099 - acc: 0.5927 - val_loss: 0.1245 - val_acc: 0.5120\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.55400\n",
      "Epoch 32/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1094 - acc: 0.5942 - val_loss: 0.1255 - val_acc: 0.5147\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.55400\n",
      "Epoch 33/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1123 - acc: 0.5771 - val_loss: 0.1251 - val_acc: 0.5120\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.55400\n",
      "Epoch 34/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1108 - acc: 0.5897 - val_loss: 0.1245 - val_acc: 0.5127\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.55400\n",
      "Epoch 35/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1098 - acc: 0.5979 - val_loss: 0.1269 - val_acc: 0.5093\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.55400\n",
      "Epoch 36/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1095 - acc: 0.5971 - val_loss: 0.1247 - val_acc: 0.5153\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.55400\n",
      "Epoch 37/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1106 - acc: 0.5906 - val_loss: 0.1264 - val_acc: 0.5033\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.55400\n",
      "Epoch 38/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1094 - acc: 0.5984 - val_loss: 0.1264 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.55400\n",
      "Epoch 39/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1113 - acc: 0.5854 - val_loss: 0.1258 - val_acc: 0.5073\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.55400\n",
      "Epoch 40/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1102 - acc: 0.5921 - val_loss: 0.1261 - val_acc: 0.5047\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.55400\n",
      "Epoch 41/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1107 - acc: 0.5852 - val_loss: 0.1262 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.55400\n",
      "Epoch 42/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1086 - acc: 0.6026 - val_loss: 0.1275 - val_acc: 0.5033\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.55400\n",
      "Epoch 43/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1108 - acc: 0.5909 - val_loss: 0.1270 - val_acc: 0.5047\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.55400\n",
      "Epoch 44/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1086 - acc: 0.6042 - val_loss: 0.1255 - val_acc: 0.5173\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.55400\n",
      "Epoch 45/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1098 - acc: 0.5927 - val_loss: 0.1316 - val_acc: 0.4813\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.55400\n",
      "Epoch 46/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1114 - acc: 0.5831 - val_loss: 0.1267 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.55400\n",
      "Epoch 47/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1088 - acc: 0.5939 - val_loss: 0.1282 - val_acc: 0.5060\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.55400\n",
      "Epoch 48/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1083 - acc: 0.6017 - val_loss: 0.1260 - val_acc: 0.5087\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.55400\n",
      "Epoch 49/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1107 - acc: 0.5882 - val_loss: 0.1290 - val_acc: 0.4960\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.55400\n",
      "Epoch 50/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1100 - acc: 0.5929 - val_loss: 0.1303 - val_acc: 0.4880\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.55400\n",
      "Epoch 51/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1095 - acc: 0.6007 - val_loss: 0.1315 - val_acc: 0.4820\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.55400\n",
      "Epoch 52/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1096 - acc: 0.5937 - val_loss: 0.1306 - val_acc: 0.4853\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.55400\n",
      "Epoch 53/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1096 - acc: 0.5936 - val_loss: 0.1273 - val_acc: 0.5080\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.55400\n",
      "Epoch 54/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1075 - acc: 0.6059 - val_loss: 0.1284 - val_acc: 0.5053\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.55400\n",
      "Epoch 55/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1112 - acc: 0.5834 - val_loss: 0.1277 - val_acc: 0.4973\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.55400\n",
      "Epoch 56/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1083 - acc: 0.6029 - val_loss: 0.1268 - val_acc: 0.5073\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.55400\n",
      "Epoch 57/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1080 - acc: 0.5989 - val_loss: 0.1325 - val_acc: 0.4780\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.55400\n",
      "Epoch 58/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1102 - acc: 0.5924 - val_loss: 0.1283 - val_acc: 0.4973\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.55400\n",
      "Epoch 59/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1081 - acc: 0.6051 - val_loss: 0.1289 - val_acc: 0.5033\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.55400\n",
      "Epoch 60/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1095 - acc: 0.5931 - val_loss: 0.1287 - val_acc: 0.4980\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.55400\n",
      "Epoch 61/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1092 - acc: 0.5939 - val_loss: 0.1289 - val_acc: 0.4967\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.55400\n",
      "Epoch 62/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1093 - acc: 0.5991 - val_loss: 0.1280 - val_acc: 0.4987\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.55400\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1081 - acc: 0.6016 - val_loss: 0.1289 - val_acc: 0.5020\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.55400\n",
      "Epoch 64/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1095 - acc: 0.5907 - val_loss: 0.1306 - val_acc: 0.4947\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.55400\n",
      "Epoch 65/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1086 - acc: 0.6039 - val_loss: 0.1282 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.55400\n",
      "Epoch 66/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1101 - acc: 0.5916 - val_loss: 0.1287 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.55400\n",
      "Epoch 67/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1094 - acc: 0.5937 - val_loss: 0.1293 - val_acc: 0.4993\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.55400\n",
      "Epoch 68/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1077 - acc: 0.6046 - val_loss: 0.1286 - val_acc: 0.4947\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.55400\n",
      "Epoch 69/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1088 - acc: 0.5987 - val_loss: 0.1290 - val_acc: 0.4953\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.55400\n",
      "Epoch 70/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1076 - acc: 0.6059 - val_loss: 0.1296 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.55400\n",
      "Epoch 71/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1104 - acc: 0.5889 - val_loss: 0.1288 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.55400\n",
      "Epoch 72/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1070 - acc: 0.6107 - val_loss: 0.1288 - val_acc: 0.5020\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.55400\n",
      "Epoch 73/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1093 - acc: 0.5932 - val_loss: 0.1327 - val_acc: 0.4753\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.55400\n",
      "Epoch 74/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1088 - acc: 0.5974 - val_loss: 0.1283 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.55400\n",
      "Epoch 75/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1080 - acc: 0.6031 - val_loss: 0.1301 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.55400\n",
      "Epoch 76/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1090 - acc: 0.5999 - val_loss: 0.1312 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.55400\n",
      "Epoch 77/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1069 - acc: 0.6094 - val_loss: 0.1301 - val_acc: 0.4887\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.55400\n",
      "Epoch 78/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1078 - acc: 0.6084 - val_loss: 0.1294 - val_acc: 0.4967\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.55400\n",
      "Epoch 79/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1089 - acc: 0.6004 - val_loss: 0.1312 - val_acc: 0.4880\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.55400\n",
      "Epoch 80/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1076 - acc: 0.6099 - val_loss: 0.1296 - val_acc: 0.4913\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.55400\n",
      "Epoch 81/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1077 - acc: 0.6027 - val_loss: 0.1356 - val_acc: 0.4593\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.55400\n",
      "Epoch 82/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1090 - acc: 0.5967 - val_loss: 0.1329 - val_acc: 0.4787\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.55400\n",
      "Epoch 83/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1075 - acc: 0.6017 - val_loss: 0.1322 - val_acc: 0.4780\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.55400\n",
      "Epoch 84/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1067 - acc: 0.6069 - val_loss: 0.1291 - val_acc: 0.4987\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.55400\n",
      "Epoch 85/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1089 - acc: 0.5906 - val_loss: 0.1334 - val_acc: 0.4787\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.55400\n",
      "Epoch 86/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1067 - acc: 0.6091 - val_loss: 0.1300 - val_acc: 0.4893\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.55400\n",
      "Epoch 87/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1059 - acc: 0.6124 - val_loss: 0.1308 - val_acc: 0.4940\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.55400\n",
      "Epoch 88/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1092 - acc: 0.5924 - val_loss: 0.1328 - val_acc: 0.4760\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.55400\n",
      "Epoch 89/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1076 - acc: 0.6072 - val_loss: 0.1329 - val_acc: 0.4833\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.55400\n",
      "Epoch 90/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1082 - acc: 0.6011 - val_loss: 0.1300 - val_acc: 0.4940\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.55400\n",
      "Epoch 91/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1070 - acc: 0.6087 - val_loss: 0.1298 - val_acc: 0.5013\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.55400\n",
      "Epoch 92/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1076 - acc: 0.6054 - val_loss: 0.1342 - val_acc: 0.4707\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.55400\n",
      "Epoch 93/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1098 - acc: 0.5921 - val_loss: 0.1302 - val_acc: 0.4913\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.55400\n",
      "Epoch 94/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1055 - acc: 0.6152 - val_loss: 0.1310 - val_acc: 0.4867\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.55400\n",
      "Epoch 95/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1088 - acc: 0.5949 - val_loss: 0.1312 - val_acc: 0.4973\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.55400\n",
      "Epoch 96/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1086 - acc: 0.6037 - val_loss: 0.1299 - val_acc: 0.4967\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.55400\n",
      "Epoch 97/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1051 - acc: 0.6159 - val_loss: 0.1305 - val_acc: 0.4960\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.55400\n",
      "Epoch 98/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1074 - acc: 0.6036 - val_loss: 0.1350 - val_acc: 0.4647\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.55400\n",
      "Epoch 99/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1068 - acc: 0.6099 - val_loss: 0.1358 - val_acc: 0.4633\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.55400\n",
      "Epoch 100/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1095 - acc: 0.5926 - val_loss: 0.1318 - val_acc: 0.4833\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.55400\n",
      "Train on 5996 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1101 - acc: 0.5947 - val_loss: 0.1112 - val_acc: 0.5893\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.55400 to 0.58933, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 2/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1132 - acc: 0.5759 - val_loss: 0.1145 - val_acc: 0.5720\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.58933\n",
      "Epoch 3/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1104 - acc: 0.5946 - val_loss: 0.1121 - val_acc: 0.5740\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.58933\n",
      "Epoch 4/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1091 - acc: 0.5966 - val_loss: 0.1140 - val_acc: 0.5673\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.58933\n",
      "Epoch 5/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1125 - acc: 0.5831 - val_loss: 0.1169 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.58933\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1105 - acc: 0.5897 - val_loss: 0.1150 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.58933\n",
      "Epoch 7/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1102 - acc: 0.5951 - val_loss: 0.1164 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.58933\n",
      "Epoch 8/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1107 - acc: 0.5862 - val_loss: 0.1170 - val_acc: 0.5533\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.58933\n",
      "Epoch 9/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1104 - acc: 0.5931 - val_loss: 0.1161 - val_acc: 0.5547\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.58933\n",
      "Epoch 10/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1114 - acc: 0.5859 - val_loss: 0.1172 - val_acc: 0.5520\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.58933\n",
      "Epoch 11/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1087 - acc: 0.5981 - val_loss: 0.1163 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.58933\n",
      "Epoch 12/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1084 - acc: 0.6006 - val_loss: 0.1160 - val_acc: 0.5707\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.58933\n",
      "Epoch 13/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1115 - acc: 0.5799 - val_loss: 0.1173 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.58933\n",
      "Epoch 14/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1096 - acc: 0.5987 - val_loss: 0.1192 - val_acc: 0.5467\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.58933\n",
      "Epoch 15/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1093 - acc: 0.5976 - val_loss: 0.1196 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.58933\n",
      "Epoch 16/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1084 - acc: 0.5999 - val_loss: 0.1185 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.58933\n",
      "Epoch 17/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1089 - acc: 0.5984 - val_loss: 0.1170 - val_acc: 0.5533\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.58933\n",
      "Epoch 18/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1103 - acc: 0.5957 - val_loss: 0.1181 - val_acc: 0.5553\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.58933\n",
      "Epoch 19/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1077 - acc: 0.6017 - val_loss: 0.1189 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.58933\n",
      "Epoch 20/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1105 - acc: 0.5907 - val_loss: 0.1191 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.58933\n",
      "Epoch 21/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1075 - acc: 0.6079 - val_loss: 0.1180 - val_acc: 0.5473\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.58933\n",
      "Epoch 22/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1107 - acc: 0.5914 - val_loss: 0.1206 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.58933\n",
      "Epoch 23/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1087 - acc: 0.5989 - val_loss: 0.1197 - val_acc: 0.5433\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.58933\n",
      "Epoch 24/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1073 - acc: 0.6087 - val_loss: 0.1199 - val_acc: 0.5433\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.58933\n",
      "Epoch 25/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1088 - acc: 0.5972 - val_loss: 0.1239 - val_acc: 0.5227\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.58933\n",
      "Epoch 26/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1097 - acc: 0.5952 - val_loss: 0.1217 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.58933\n",
      "Epoch 27/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1090 - acc: 0.5982 - val_loss: 0.1212 - val_acc: 0.5273\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.58933\n",
      "Epoch 28/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1083 - acc: 0.6041 - val_loss: 0.1209 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.58933\n",
      "Epoch 29/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1078 - acc: 0.6059 - val_loss: 0.1218 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.58933\n",
      "Epoch 30/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1088 - acc: 0.6012 - val_loss: 0.1245 - val_acc: 0.5160\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.58933\n",
      "Epoch 31/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1088 - acc: 0.5964 - val_loss: 0.1228 - val_acc: 0.5247\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.58933\n",
      "Epoch 32/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1088 - acc: 0.6009 - val_loss: 0.1202 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.58933\n",
      "Epoch 33/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1082 - acc: 0.5994 - val_loss: 0.1247 - val_acc: 0.5133\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.58933\n",
      "Epoch 34/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1086 - acc: 0.5947 - val_loss: 0.1214 - val_acc: 0.5347\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.58933\n",
      "Epoch 35/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1073 - acc: 0.6071 - val_loss: 0.1209 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.58933\n",
      "Epoch 36/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1073 - acc: 0.6044 - val_loss: 0.1260 - val_acc: 0.5013\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.58933\n",
      "Epoch 37/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1076 - acc: 0.6112 - val_loss: 0.1220 - val_acc: 0.5227\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.58933\n",
      "Epoch 38/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1061 - acc: 0.6159 - val_loss: 0.1227 - val_acc: 0.5213\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.58933\n",
      "Epoch 39/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1099 - acc: 0.5907 - val_loss: 0.1224 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.58933\n",
      "Epoch 40/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1062 - acc: 0.6112 - val_loss: 0.1221 - val_acc: 0.5260\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.58933\n",
      "Epoch 41/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1072 - acc: 0.6091 - val_loss: 0.1239 - val_acc: 0.5080\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.58933\n",
      "Epoch 42/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1099 - acc: 0.5934 - val_loss: 0.1237 - val_acc: 0.5133\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.58933\n",
      "Epoch 43/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1064 - acc: 0.6131 - val_loss: 0.1223 - val_acc: 0.5227\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.58933\n",
      "Epoch 44/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1080 - acc: 0.6019 - val_loss: 0.1247 - val_acc: 0.5147\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.58933\n",
      "Epoch 45/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1076 - acc: 0.6087 - val_loss: 0.1225 - val_acc: 0.5187\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.58933\n",
      "Epoch 46/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1055 - acc: 0.6142 - val_loss: 0.1237 - val_acc: 0.5220\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.58933\n",
      "Epoch 47/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1082 - acc: 0.6024 - val_loss: 0.1239 - val_acc: 0.5207\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.58933\n",
      "Epoch 48/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1078 - acc: 0.6047 - val_loss: 0.1249 - val_acc: 0.5120\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.58933\n",
      "Epoch 49/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1073 - acc: 0.6081 - val_loss: 0.1259 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.58933\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1066 - acc: 0.6114 - val_loss: 0.1231 - val_acc: 0.5267\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.58933\n",
      "Epoch 51/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1077 - acc: 0.6036 - val_loss: 0.1240 - val_acc: 0.5273\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.58933\n",
      "Epoch 52/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1049 - acc: 0.6197 - val_loss: 0.1237 - val_acc: 0.5260\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.58933\n",
      "Epoch 53/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1089 - acc: 0.5997 - val_loss: 0.1259 - val_acc: 0.5093\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.58933\n",
      "Epoch 54/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1073 - acc: 0.6057 - val_loss: 0.1239 - val_acc: 0.5187\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.58933\n",
      "Epoch 55/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1065 - acc: 0.6107 - val_loss: 0.1248 - val_acc: 0.5160\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.58933\n",
      "Epoch 56/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1062 - acc: 0.6097 - val_loss: 0.1248 - val_acc: 0.5173\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.58933\n",
      "Epoch 57/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1079 - acc: 0.6054 - val_loss: 0.1257 - val_acc: 0.5120\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.58933\n",
      "Epoch 58/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1067 - acc: 0.6126 - val_loss: 0.1260 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.58933\n",
      "Epoch 59/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1071 - acc: 0.6089 - val_loss: 0.1263 - val_acc: 0.5047\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.58933\n",
      "Epoch 60/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1056 - acc: 0.6189 - val_loss: 0.1251 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.58933\n",
      "Epoch 61/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1055 - acc: 0.6159 - val_loss: 0.1289 - val_acc: 0.4887\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.58933\n",
      "Epoch 62/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1084 - acc: 0.5934 - val_loss: 0.1260 - val_acc: 0.5013\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.58933\n",
      "Epoch 63/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1060 - acc: 0.6119 - val_loss: 0.1253 - val_acc: 0.5120\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.58933\n",
      "Epoch 64/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1049 - acc: 0.6206 - val_loss: 0.1246 - val_acc: 0.5147\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.58933\n",
      "Epoch 65/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1080 - acc: 0.6046 - val_loss: 0.1270 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.58933\n",
      "Epoch 66/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1050 - acc: 0.6186 - val_loss: 0.1244 - val_acc: 0.5153\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.58933\n",
      "Epoch 67/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1084 - acc: 0.5962 - val_loss: 0.1270 - val_acc: 0.4987\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.58933\n",
      "Epoch 68/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1055 - acc: 0.6184 - val_loss: 0.1256 - val_acc: 0.5073\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.58933\n",
      "Epoch 69/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1043 - acc: 0.6206 - val_loss: 0.1251 - val_acc: 0.5093\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.58933\n",
      "Epoch 70/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1072 - acc: 0.6051 - val_loss: 0.1278 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.58933\n",
      "Epoch 71/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1057 - acc: 0.6122 - val_loss: 0.1277 - val_acc: 0.4967\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.58933\n",
      "Epoch 72/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1067 - acc: 0.6082 - val_loss: 0.1273 - val_acc: 0.4940\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.58933\n",
      "Epoch 73/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1060 - acc: 0.6146 - val_loss: 0.1291 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.58933\n",
      "Epoch 74/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1062 - acc: 0.6112 - val_loss: 0.1265 - val_acc: 0.5073\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.58933\n",
      "Epoch 75/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1046 - acc: 0.6179 - val_loss: 0.1287 - val_acc: 0.4980\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.58933\n",
      "Epoch 76/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1076 - acc: 0.6044 - val_loss: 0.1265 - val_acc: 0.5027\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.58933\n",
      "Epoch 77/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1064 - acc: 0.6129 - val_loss: 0.1265 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.58933\n",
      "Epoch 78/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1049 - acc: 0.6152 - val_loss: 0.1302 - val_acc: 0.4867\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.58933\n",
      "Epoch 79/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1066 - acc: 0.6076 - val_loss: 0.1271 - val_acc: 0.5020\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.58933\n",
      "Epoch 80/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1060 - acc: 0.6099 - val_loss: 0.1267 - val_acc: 0.4987\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.58933\n",
      "Epoch 81/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1052 - acc: 0.6167 - val_loss: 0.1277 - val_acc: 0.4987\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.58933\n",
      "Epoch 82/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1069 - acc: 0.6034 - val_loss: 0.1284 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.58933\n",
      "Epoch 83/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1047 - acc: 0.6187 - val_loss: 0.1273 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.58933\n",
      "Epoch 84/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1036 - acc: 0.6254 - val_loss: 0.1286 - val_acc: 0.4927\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.58933\n",
      "Epoch 85/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1059 - acc: 0.6136 - val_loss: 0.1293 - val_acc: 0.4860\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.58933\n",
      "Epoch 86/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1053 - acc: 0.6169 - val_loss: 0.1292 - val_acc: 0.4860\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.58933\n",
      "Epoch 87/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1068 - acc: 0.6109 - val_loss: 0.1286 - val_acc: 0.4980\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.58933\n",
      "Epoch 88/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1054 - acc: 0.6147 - val_loss: 0.1266 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.58933\n",
      "Epoch 89/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1050 - acc: 0.6232 - val_loss: 0.1274 - val_acc: 0.5047\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.58933\n",
      "Epoch 90/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1035 - acc: 0.6266 - val_loss: 0.1277 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.58933\n",
      "Epoch 91/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1060 - acc: 0.6126 - val_loss: 0.1298 - val_acc: 0.4893\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.58933\n",
      "Epoch 92/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1059 - acc: 0.6091 - val_loss: 0.1280 - val_acc: 0.5033\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.58933\n",
      "Epoch 93/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1062 - acc: 0.6106 - val_loss: 0.1298 - val_acc: 0.4927\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.58933\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1040 - acc: 0.6258 - val_loss: 0.1274 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.58933\n",
      "Epoch 95/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1039 - acc: 0.6246 - val_loss: 0.1298 - val_acc: 0.4847\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.58933\n",
      "Epoch 96/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1078 - acc: 0.5994 - val_loss: 0.1282 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.58933\n",
      "Epoch 97/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1036 - acc: 0.6298 - val_loss: 0.1282 - val_acc: 0.4940\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.58933\n",
      "Epoch 98/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1044 - acc: 0.6199 - val_loss: 0.1301 - val_acc: 0.4847\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.58933\n",
      "Epoch 99/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1050 - acc: 0.6224 - val_loss: 0.1285 - val_acc: 0.4960\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.58933\n",
      "Epoch 100/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1051 - acc: 0.6176 - val_loss: 0.1289 - val_acc: 0.4833\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.58933\n",
      "Train on 5996 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1079 - acc: 0.6046 - val_loss: 0.1076 - val_acc: 0.5953\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.58933 to 0.59533, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 2/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1082 - acc: 0.6037 - val_loss: 0.1091 - val_acc: 0.5933\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.59533\n",
      "Epoch 3/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1109 - acc: 0.5876 - val_loss: 0.1141 - val_acc: 0.5680\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.59533\n",
      "Epoch 4/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1090 - acc: 0.5992 - val_loss: 0.1099 - val_acc: 0.5947\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.59533\n",
      "Epoch 5/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1074 - acc: 0.6037 - val_loss: 0.1106 - val_acc: 0.5893\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.59533\n",
      "Epoch 6/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1099 - acc: 0.5939 - val_loss: 0.1107 - val_acc: 0.5920\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.59533\n",
      "Epoch 7/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1066 - acc: 0.6067 - val_loss: 0.1127 - val_acc: 0.5780\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.59533\n",
      "Epoch 8/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1093 - acc: 0.5916 - val_loss: 0.1108 - val_acc: 0.5827\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.59533\n",
      "Epoch 9/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1072 - acc: 0.6066 - val_loss: 0.1144 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.59533\n",
      "Epoch 10/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1091 - acc: 0.5934 - val_loss: 0.1129 - val_acc: 0.5707\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.59533\n",
      "Epoch 11/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1073 - acc: 0.6049 - val_loss: 0.1131 - val_acc: 0.5693\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.59533\n",
      "Epoch 12/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1086 - acc: 0.6017 - val_loss: 0.1159 - val_acc: 0.5593\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.59533\n",
      "Epoch 13/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1062 - acc: 0.6117 - val_loss: 0.1124 - val_acc: 0.5713\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.59533\n",
      "Epoch 14/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1076 - acc: 0.6042 - val_loss: 0.1179 - val_acc: 0.5593\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.59533\n",
      "Epoch 15/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1084 - acc: 0.6012 - val_loss: 0.1124 - val_acc: 0.5767\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.59533\n",
      "Epoch 16/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1065 - acc: 0.6082 - val_loss: 0.1154 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.59533\n",
      "Epoch 17/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1067 - acc: 0.6097 - val_loss: 0.1156 - val_acc: 0.5560\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.59533\n",
      "Epoch 18/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1080 - acc: 0.6042 - val_loss: 0.1150 - val_acc: 0.5647\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.59533\n",
      "Epoch 19/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1061 - acc: 0.6107 - val_loss: 0.1146 - val_acc: 0.5547\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.59533\n",
      "Epoch 20/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1087 - acc: 0.6001 - val_loss: 0.1173 - val_acc: 0.5560\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.59533\n",
      "Epoch 21/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1062 - acc: 0.6127 - val_loss: 0.1167 - val_acc: 0.5620\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.59533\n",
      "Epoch 22/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1058 - acc: 0.6104 - val_loss: 0.1158 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.59533\n",
      "Epoch 23/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1073 - acc: 0.6062 - val_loss: 0.1161 - val_acc: 0.5533\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.59533\n",
      "Epoch 24/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1059 - acc: 0.6139 - val_loss: 0.1173 - val_acc: 0.5560\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.59533\n",
      "Epoch 25/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1069 - acc: 0.6116 - val_loss: 0.1158 - val_acc: 0.5680\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.59533\n",
      "Epoch 26/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1051 - acc: 0.6151 - val_loss: 0.1171 - val_acc: 0.5547\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.59533\n",
      "Epoch 27/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1074 - acc: 0.6034 - val_loss: 0.1178 - val_acc: 0.5540\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.59533\n",
      "Epoch 28/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1057 - acc: 0.6141 - val_loss: 0.1172 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.59533\n",
      "Epoch 29/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1063 - acc: 0.6122 - val_loss: 0.1199 - val_acc: 0.5420\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.59533\n",
      "Epoch 30/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1060 - acc: 0.6159 - val_loss: 0.1210 - val_acc: 0.5273\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.59533\n",
      "Epoch 31/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1080 - acc: 0.6049 - val_loss: 0.1170 - val_acc: 0.5513\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.59533\n",
      "Epoch 32/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1051 - acc: 0.6146 - val_loss: 0.1183 - val_acc: 0.5447\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.59533\n",
      "Epoch 33/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1056 - acc: 0.6116 - val_loss: 0.1235 - val_acc: 0.5193\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.59533\n",
      "Epoch 34/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1072 - acc: 0.6062 - val_loss: 0.1174 - val_acc: 0.5520\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.59533\n",
      "Epoch 35/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1040 - acc: 0.6209 - val_loss: 0.1179 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.59533\n",
      "Epoch 36/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1058 - acc: 0.6121 - val_loss: 0.1232 - val_acc: 0.5313\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.59533\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1081 - acc: 0.5977 - val_loss: 0.1193 - val_acc: 0.5467\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.59533\n",
      "Epoch 38/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1052 - acc: 0.6149 - val_loss: 0.1194 - val_acc: 0.5420\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.59533\n",
      "Epoch 39/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1053 - acc: 0.6186 - val_loss: 0.1182 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.59533\n",
      "Epoch 40/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1070 - acc: 0.6054 - val_loss: 0.1215 - val_acc: 0.5367\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.59533\n",
      "Epoch 41/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1055 - acc: 0.6124 - val_loss: 0.1188 - val_acc: 0.5467\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.59533\n",
      "Epoch 42/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1054 - acc: 0.6121 - val_loss: 0.1195 - val_acc: 0.5467\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.59533\n",
      "Epoch 43/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1060 - acc: 0.6166 - val_loss: 0.1198 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.59533\n",
      "Epoch 44/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1047 - acc: 0.6227 - val_loss: 0.1214 - val_acc: 0.5353\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.59533\n",
      "Epoch 45/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1067 - acc: 0.6112 - val_loss: 0.1193 - val_acc: 0.5513\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.59533\n",
      "Epoch 46/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1033 - acc: 0.6263 - val_loss: 0.1189 - val_acc: 0.5447\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.59533\n",
      "Epoch 47/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1035 - acc: 0.6229 - val_loss: 0.1253 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.59533\n",
      "Epoch 48/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1079 - acc: 0.6017 - val_loss: 0.1194 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.59533\n",
      "Epoch 49/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1035 - acc: 0.6229 - val_loss: 0.1198 - val_acc: 0.5413\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.59533\n",
      "Epoch 50/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1066 - acc: 0.6089 - val_loss: 0.1205 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.59533\n",
      "Epoch 51/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1043 - acc: 0.6206 - val_loss: 0.1204 - val_acc: 0.5433\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.59533\n",
      "Epoch 52/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1054 - acc: 0.6122 - val_loss: 0.1212 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.59533\n",
      "Epoch 53/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1048 - acc: 0.6209 - val_loss: 0.1221 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.59533\n",
      "Epoch 54/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1053 - acc: 0.6154 - val_loss: 0.1251 - val_acc: 0.5133\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.59533\n",
      "Epoch 55/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1054 - acc: 0.6174 - val_loss: 0.1204 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.59533\n",
      "Epoch 56/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1036 - acc: 0.6251 - val_loss: 0.1192 - val_acc: 0.5487\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.59533\n",
      "Epoch 57/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1046 - acc: 0.6191 - val_loss: 0.1256 - val_acc: 0.5080\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.59533\n",
      "Epoch 58/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1060 - acc: 0.6139 - val_loss: 0.1213 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.59533\n",
      "Epoch 59/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1043 - acc: 0.6222 - val_loss: 0.1214 - val_acc: 0.5393\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.59533\n",
      "Epoch 60/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1039 - acc: 0.6186 - val_loss: 0.1221 - val_acc: 0.5267\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.59533\n",
      "Epoch 61/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1057 - acc: 0.6146 - val_loss: 0.1230 - val_acc: 0.5233\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.59533\n",
      "Epoch 62/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1055 - acc: 0.6152 - val_loss: 0.1209 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.59533\n",
      "Epoch 63/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1024 - acc: 0.6279 - val_loss: 0.1206 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.59533\n",
      "Epoch 64/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1060 - acc: 0.6131 - val_loss: 0.1260 - val_acc: 0.5267\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.59533\n",
      "Epoch 65/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1028 - acc: 0.6286 - val_loss: 0.1214 - val_acc: 0.5373\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.59533\n",
      "Epoch 66/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1030 - acc: 0.6263 - val_loss: 0.1248 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.59533\n",
      "Epoch 67/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1063 - acc: 0.6112 - val_loss: 0.1219 - val_acc: 0.5427\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.59533\n",
      "Epoch 68/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1039 - acc: 0.6221 - val_loss: 0.1233 - val_acc: 0.5367\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.59533\n",
      "Epoch 69/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1043 - acc: 0.6189 - val_loss: 0.1213 - val_acc: 0.5407\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.59533\n",
      "Epoch 70/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1046 - acc: 0.6194 - val_loss: 0.1221 - val_acc: 0.5380\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.59533\n",
      "Epoch 71/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1027 - acc: 0.6264 - val_loss: 0.1228 - val_acc: 0.5380\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.59533\n",
      "Epoch 72/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1047 - acc: 0.6179 - val_loss: 0.1247 - val_acc: 0.5313\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.59533\n",
      "Epoch 73/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1036 - acc: 0.6214 - val_loss: 0.1222 - val_acc: 0.5393\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.59533\n",
      "Epoch 74/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1036 - acc: 0.6261 - val_loss: 0.1254 - val_acc: 0.5247\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.59533\n",
      "Epoch 75/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1049 - acc: 0.6141 - val_loss: 0.1233 - val_acc: 0.5353\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.59533\n",
      "Epoch 76/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1035 - acc: 0.6266 - val_loss: 0.1242 - val_acc: 0.5327\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.59533\n",
      "Epoch 77/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1041 - acc: 0.6231 - val_loss: 0.1221 - val_acc: 0.5407\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.59533\n",
      "Epoch 78/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1036 - acc: 0.6251 - val_loss: 0.1238 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.59533\n",
      "Epoch 79/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1046 - acc: 0.6186 - val_loss: 0.1237 - val_acc: 0.5367\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.59533\n",
      "Epoch 80/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1028 - acc: 0.6246 - val_loss: 0.1229 - val_acc: 0.5373\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.59533\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1037 - acc: 0.6236 - val_loss: 0.1264 - val_acc: 0.5293\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.59533\n",
      "Epoch 82/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1036 - acc: 0.6242 - val_loss: 0.1238 - val_acc: 0.5353\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.59533\n",
      "Epoch 83/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1049 - acc: 0.6199 - val_loss: 0.1252 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.59533\n",
      "Epoch 84/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1029 - acc: 0.6296 - val_loss: 0.1238 - val_acc: 0.5413\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.59533\n",
      "Epoch 85/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1023 - acc: 0.6296 - val_loss: 0.1265 - val_acc: 0.5180\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.59533\n",
      "Epoch 86/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1049 - acc: 0.6171 - val_loss: 0.1248 - val_acc: 0.5340\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.59533\n",
      "Epoch 87/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1031 - acc: 0.6258 - val_loss: 0.1234 - val_acc: 0.5347\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.59533\n",
      "Epoch 88/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1028 - acc: 0.6256 - val_loss: 0.1255 - val_acc: 0.5280\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.59533\n",
      "Epoch 89/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1036 - acc: 0.6237 - val_loss: 0.1249 - val_acc: 0.5313\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.59533\n",
      "Epoch 90/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1019 - acc: 0.6293 - val_loss: 0.1256 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.59533\n",
      "Epoch 91/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1046 - acc: 0.6222 - val_loss: 0.1242 - val_acc: 0.5293\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.59533\n",
      "Epoch 92/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1031 - acc: 0.6284 - val_loss: 0.1297 - val_acc: 0.5073\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.59533\n",
      "Epoch 93/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1025 - acc: 0.6289 - val_loss: 0.1255 - val_acc: 0.5160\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.59533\n",
      "Epoch 94/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1019 - acc: 0.6284 - val_loss: 0.1305 - val_acc: 0.4907\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.59533\n",
      "Epoch 95/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1060 - acc: 0.6147 - val_loss: 0.1256 - val_acc: 0.5167\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.59533\n",
      "Epoch 96/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1021 - acc: 0.6306 - val_loss: 0.1257 - val_acc: 0.5147\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.59533\n",
      "Epoch 97/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1032 - acc: 0.6268 - val_loss: 0.1258 - val_acc: 0.5180\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.59533\n",
      "Epoch 98/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1031 - acc: 0.6259 - val_loss: 0.1261 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.59533\n",
      "Epoch 99/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1017 - acc: 0.6348 - val_loss: 0.1245 - val_acc: 0.5153\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.59533\n",
      "Epoch 100/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1019 - acc: 0.6368 - val_loss: 0.1262 - val_acc: 0.5147\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.59533\n",
      "Train on 5996 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1083 - acc: 0.5982 - val_loss: 0.1080 - val_acc: 0.6080\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.59533 to 0.60800, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 2/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1081 - acc: 0.6014 - val_loss: 0.1090 - val_acc: 0.6007\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.60800\n",
      "Epoch 3/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1048 - acc: 0.6212 - val_loss: 0.1102 - val_acc: 0.5927\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.60800\n",
      "Epoch 4/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1079 - acc: 0.6047 - val_loss: 0.1090 - val_acc: 0.6013\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.60800\n",
      "Epoch 5/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1044 - acc: 0.6202 - val_loss: 0.1089 - val_acc: 0.6020\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.60800\n",
      "Epoch 6/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1070 - acc: 0.6051 - val_loss: 0.1100 - val_acc: 0.5893\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.60800\n",
      "Epoch 7/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1060 - acc: 0.6119 - val_loss: 0.1108 - val_acc: 0.5847\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.60800\n",
      "Epoch 8/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1064 - acc: 0.6117 - val_loss: 0.1140 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.60800\n",
      "Epoch 9/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1051 - acc: 0.6167 - val_loss: 0.1097 - val_acc: 0.5967\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.60800\n",
      "Epoch 10/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1034 - acc: 0.6256 - val_loss: 0.1131 - val_acc: 0.5767\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.60800\n",
      "Epoch 11/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1073 - acc: 0.6042 - val_loss: 0.1142 - val_acc: 0.5713\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.60800\n",
      "Epoch 12/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1056 - acc: 0.6121 - val_loss: 0.1129 - val_acc: 0.5747\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.60800\n",
      "Epoch 13/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1053 - acc: 0.6152 - val_loss: 0.1122 - val_acc: 0.5827\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.60800\n",
      "Epoch 14/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1035 - acc: 0.6246 - val_loss: 0.1113 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.60800\n",
      "Epoch 15/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1035 - acc: 0.6269 - val_loss: 0.1182 - val_acc: 0.5560\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.60800\n",
      "Epoch 16/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1074 - acc: 0.6071 - val_loss: 0.1125 - val_acc: 0.5853\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.60800\n",
      "Epoch 17/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1024 - acc: 0.6309 - val_loss: 0.1139 - val_acc: 0.5693\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.60800\n",
      "Epoch 18/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1062 - acc: 0.6116 - val_loss: 0.1135 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.60800\n",
      "Epoch 19/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1056 - acc: 0.6137 - val_loss: 0.1139 - val_acc: 0.5627\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.60800\n",
      "Epoch 20/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1051 - acc: 0.6191 - val_loss: 0.1148 - val_acc: 0.5660\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.60800\n",
      "Epoch 21/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1024 - acc: 0.6279 - val_loss: 0.1130 - val_acc: 0.5760\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.60800\n",
      "Epoch 22/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1027 - acc: 0.6333 - val_loss: 0.1185 - val_acc: 0.5480\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.60800\n",
      "Epoch 23/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1065 - acc: 0.6062 - val_loss: 0.1160 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.60800\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1036 - acc: 0.6249 - val_loss: 0.1132 - val_acc: 0.5747\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.60800\n",
      "Epoch 25/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1015 - acc: 0.6371 - val_loss: 0.1150 - val_acc: 0.5667\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.60800\n",
      "Epoch 26/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1063 - acc: 0.6122 - val_loss: 0.1141 - val_acc: 0.5667\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.60800\n",
      "Epoch 27/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1029 - acc: 0.6293 - val_loss: 0.1142 - val_acc: 0.5680\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.60800\n",
      "Epoch 28/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1042 - acc: 0.6231 - val_loss: 0.1203 - val_acc: 0.5380\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.60800\n",
      "Epoch 29/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1046 - acc: 0.6164 - val_loss: 0.1163 - val_acc: 0.5527\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.60800\n",
      "Epoch 30/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1033 - acc: 0.6209 - val_loss: 0.1168 - val_acc: 0.5473\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.60800\n",
      "Epoch 31/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1023 - acc: 0.6303 - val_loss: 0.1165 - val_acc: 0.5507\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.60800\n",
      "Epoch 32/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1060 - acc: 0.6114 - val_loss: 0.1166 - val_acc: 0.5507\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.60800\n",
      "Epoch 33/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1035 - acc: 0.6214 - val_loss: 0.1153 - val_acc: 0.5673\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.60800\n",
      "Epoch 34/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1023 - acc: 0.6288 - val_loss: 0.1173 - val_acc: 0.5460\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.60800\n",
      "Epoch 35/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1039 - acc: 0.6224 - val_loss: 0.1201 - val_acc: 0.5307\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.60800\n",
      "Epoch 36/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1030 - acc: 0.6241 - val_loss: 0.1160 - val_acc: 0.5533\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.60800\n",
      "Epoch 37/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1032 - acc: 0.6273 - val_loss: 0.1193 - val_acc: 0.5393\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.60800\n",
      "Epoch 38/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1042 - acc: 0.6197 - val_loss: 0.1163 - val_acc: 0.5527\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.60800\n",
      "Epoch 39/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1017 - acc: 0.6361 - val_loss: 0.1169 - val_acc: 0.5513\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.60800\n",
      "Epoch 40/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1020 - acc: 0.6296 - val_loss: 0.1177 - val_acc: 0.5473\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.60800\n",
      "Epoch 41/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1059 - acc: 0.6076 - val_loss: 0.1184 - val_acc: 0.5367\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.60800\n",
      "Epoch 42/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1023 - acc: 0.6268 - val_loss: 0.1157 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.60800\n",
      "Epoch 43/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1020 - acc: 0.6333 - val_loss: 0.1222 - val_acc: 0.5280\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.60800\n",
      "Epoch 44/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1041 - acc: 0.6179 - val_loss: 0.1173 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.60800\n",
      "Epoch 45/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1011 - acc: 0.6393 - val_loss: 0.1190 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.60800\n",
      "Epoch 46/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1030 - acc: 0.6259 - val_loss: 0.1180 - val_acc: 0.5567\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.60800\n",
      "Epoch 47/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1039 - acc: 0.6227 - val_loss: 0.1219 - val_acc: 0.5367\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.60800\n",
      "Epoch 48/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1026 - acc: 0.6281 - val_loss: 0.1175 - val_acc: 0.5440\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.60800\n",
      "Epoch 49/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1015 - acc: 0.6348 - val_loss: 0.1195 - val_acc: 0.5360\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.60800\n",
      "Epoch 50/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1034 - acc: 0.6202 - val_loss: 0.1182 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.60800\n",
      "Epoch 51/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1020 - acc: 0.6341 - val_loss: 0.1219 - val_acc: 0.5260\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.60800\n",
      "Epoch 52/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1029 - acc: 0.6222 - val_loss: 0.1175 - val_acc: 0.5513\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.60800\n",
      "Epoch 53/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1022 - acc: 0.6311 - val_loss: 0.1200 - val_acc: 0.5307\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.60800\n",
      "Epoch 54/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1033 - acc: 0.6209 - val_loss: 0.1210 - val_acc: 0.5260\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.60800\n",
      "Epoch 55/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1021 - acc: 0.6306 - val_loss: 0.1192 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.60800\n",
      "Epoch 56/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1007 - acc: 0.6379 - val_loss: 0.1204 - val_acc: 0.5467\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.60800\n",
      "Epoch 57/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1046 - acc: 0.6149 - val_loss: 0.1233 - val_acc: 0.5227\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.60800\n",
      "Epoch 58/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1006 - acc: 0.6366 - val_loss: 0.1190 - val_acc: 0.5507\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.60800\n",
      "Epoch 59/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1002 - acc: 0.6414 - val_loss: 0.1197 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.60800\n",
      "Epoch 60/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1037 - acc: 0.6276 - val_loss: 0.1251 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.60800\n",
      "Epoch 61/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1032 - acc: 0.6184 - val_loss: 0.1197 - val_acc: 0.5353\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.60800\n",
      "Epoch 62/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1010 - acc: 0.6334 - val_loss: 0.1232 - val_acc: 0.5233\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.60800\n",
      "Epoch 63/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1030 - acc: 0.6186 - val_loss: 0.1193 - val_acc: 0.5467\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.60800\n",
      "Epoch 64/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1018 - acc: 0.6316 - val_loss: 0.1218 - val_acc: 0.5287\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.60800\n",
      "Epoch 65/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1033 - acc: 0.6231 - val_loss: 0.1205 - val_acc: 0.5327\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.60800\n",
      "Epoch 66/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.0997 - acc: 0.6456 - val_loss: 0.1192 - val_acc: 0.5467\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.60800\n",
      "Epoch 67/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1035 - acc: 0.6209 - val_loss: 0.1204 - val_acc: 0.5347\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.60800\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1020 - acc: 0.6291 - val_loss: 0.1234 - val_acc: 0.5207\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.60800\n",
      "Epoch 69/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1029 - acc: 0.6253 - val_loss: 0.1195 - val_acc: 0.5380\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.60800\n",
      "Epoch 70/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1011 - acc: 0.6338 - val_loss: 0.1219 - val_acc: 0.5273\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.60800\n",
      "Epoch 71/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1019 - acc: 0.6311 - val_loss: 0.1193 - val_acc: 0.5427\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.60800\n",
      "Epoch 72/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0991 - acc: 0.6463 - val_loss: 0.1210 - val_acc: 0.5413\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.60800\n",
      "Epoch 73/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1032 - acc: 0.6258 - val_loss: 0.1228 - val_acc: 0.5287\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.60800\n",
      "Epoch 74/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1018 - acc: 0.6294 - val_loss: 0.1212 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.60800\n",
      "Epoch 75/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0994 - acc: 0.6421 - val_loss: 0.1224 - val_acc: 0.5340\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.60800\n",
      "Epoch 76/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1039 - acc: 0.6217 - val_loss: 0.1218 - val_acc: 0.5407\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.60800\n",
      "Epoch 77/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1006 - acc: 0.6398 - val_loss: 0.1210 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.60800\n",
      "Epoch 78/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1023 - acc: 0.6296 - val_loss: 0.1221 - val_acc: 0.5307\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.60800\n",
      "Epoch 79/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1004 - acc: 0.6376 - val_loss: 0.1209 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.60800\n",
      "Epoch 80/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0989 - acc: 0.6449 - val_loss: 0.1233 - val_acc: 0.5267\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.60800\n",
      "Epoch 81/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1031 - acc: 0.6229 - val_loss: 0.1244 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.60800\n",
      "Epoch 82/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1022 - acc: 0.6246 - val_loss: 0.1224 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.60800\n",
      "Epoch 83/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0991 - acc: 0.6428 - val_loss: 0.1216 - val_acc: 0.5293\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.60800\n",
      "Epoch 84/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1032 - acc: 0.6256 - val_loss: 0.1221 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.60800\n",
      "Epoch 85/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0996 - acc: 0.6428 - val_loss: 0.1209 - val_acc: 0.5313\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.60800\n",
      "Epoch 86/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0986 - acc: 0.6471 - val_loss: 0.1282 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.60800\n",
      "Epoch 87/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1042 - acc: 0.6159 - val_loss: 0.1251 - val_acc: 0.5153\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.60800\n",
      "Epoch 88/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1000 - acc: 0.6406 - val_loss: 0.1219 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.60800\n",
      "Epoch 89/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.0998 - acc: 0.6409 - val_loss: 0.1256 - val_acc: 0.5193\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.60800\n",
      "Epoch 90/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1043 - acc: 0.6187 - val_loss: 0.1245 - val_acc: 0.5173\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.60800\n",
      "Epoch 91/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1009 - acc: 0.6329 - val_loss: 0.1239 - val_acc: 0.5253\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.60800\n",
      "Epoch 92/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1007 - acc: 0.6381 - val_loss: 0.1224 - val_acc: 0.5353\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.60800\n",
      "Epoch 93/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0998 - acc: 0.6383 - val_loss: 0.1307 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.60800\n",
      "Epoch 94/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1022 - acc: 0.6273 - val_loss: 0.1229 - val_acc: 0.5313\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.60800\n",
      "Epoch 95/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.0990 - acc: 0.6481 - val_loss: 0.1250 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.60800\n",
      "Epoch 96/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1017 - acc: 0.6293 - val_loss: 0.1260 - val_acc: 0.5140\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.60800\n",
      "Epoch 97/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1013 - acc: 0.6288 - val_loss: 0.1260 - val_acc: 0.5173\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.60800\n",
      "Epoch 98/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1008 - acc: 0.6318 - val_loss: 0.1239 - val_acc: 0.5273\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.60800\n",
      "Epoch 99/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0983 - acc: 0.6471 - val_loss: 0.1223 - val_acc: 0.5347\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.60800\n",
      "Epoch 100/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0986 - acc: 0.6448 - val_loss: 0.1256 - val_acc: 0.5193\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.60800\n",
      "Train on 5996 samples, validate on 1500 samples\n",
      "Epoch 1/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1079 - acc: 0.5931 - val_loss: 0.1049 - val_acc: 0.6167\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.60800 to 0.61667, saving model to weights_image_categorcial.hdf6\n",
      "Epoch 2/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1039 - acc: 0.6209 - val_loss: 0.1062 - val_acc: 0.6020\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.61667\n",
      "Epoch 3/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1032 - acc: 0.6278 - val_loss: 0.1124 - val_acc: 0.5813\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.61667\n",
      "Epoch 4/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1064 - acc: 0.6056 - val_loss: 0.1077 - val_acc: 0.6013\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.61667\n",
      "Epoch 5/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1020 - acc: 0.6273 - val_loss: 0.1120 - val_acc: 0.5813\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.61667\n",
      "Epoch 6/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1054 - acc: 0.6111 - val_loss: 0.1127 - val_acc: 0.5727\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.61667\n",
      "Epoch 7/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1015 - acc: 0.6323 - val_loss: 0.1080 - val_acc: 0.6007\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.61667\n",
      "Epoch 8/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1044 - acc: 0.6176 - val_loss: 0.1148 - val_acc: 0.5633\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.61667\n",
      "Epoch 9/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1043 - acc: 0.6126 - val_loss: 0.1128 - val_acc: 0.5720\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.61667\n",
      "Epoch 10/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1025 - acc: 0.6256 - val_loss: 0.1122 - val_acc: 0.5747\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.61667\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1040 - acc: 0.6146 - val_loss: 0.1123 - val_acc: 0.5780\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.61667\n",
      "Epoch 12/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1023 - acc: 0.6291 - val_loss: 0.1166 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.61667\n",
      "Epoch 13/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1025 - acc: 0.6242 - val_loss: 0.1121 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.61667\n",
      "Epoch 14/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1031 - acc: 0.6259 - val_loss: 0.1124 - val_acc: 0.5733\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.61667\n",
      "Epoch 15/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1041 - acc: 0.6159 - val_loss: 0.1161 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.61667\n",
      "Epoch 16/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1009 - acc: 0.6351 - val_loss: 0.1109 - val_acc: 0.5893\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.61667\n",
      "Epoch 17/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1016 - acc: 0.6281 - val_loss: 0.1105 - val_acc: 0.5880\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.61667\n",
      "Epoch 18/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1019 - acc: 0.6288 - val_loss: 0.1147 - val_acc: 0.5727\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.61667\n",
      "Epoch 19/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1044 - acc: 0.6156 - val_loss: 0.1131 - val_acc: 0.5833\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.61667\n",
      "Epoch 20/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1006 - acc: 0.6348 - val_loss: 0.1124 - val_acc: 0.5787\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.61667\n",
      "Epoch 21/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1017 - acc: 0.6316 - val_loss: 0.1137 - val_acc: 0.5767\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.61667\n",
      "Epoch 22/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1024 - acc: 0.6234 - val_loss: 0.1150 - val_acc: 0.5747\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.61667\n",
      "Epoch 23/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1041 - acc: 0.6142 - val_loss: 0.1123 - val_acc: 0.5807\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.61667\n",
      "Epoch 24/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0992 - acc: 0.6436 - val_loss: 0.1123 - val_acc: 0.5793\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.61667\n",
      "Epoch 25/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1029 - acc: 0.6246 - val_loss: 0.1149 - val_acc: 0.5707\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.61667\n",
      "Epoch 26/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1023 - acc: 0.6271 - val_loss: 0.1131 - val_acc: 0.5753\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.61667\n",
      "Epoch 27/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0999 - acc: 0.6383 - val_loss: 0.1137 - val_acc: 0.5793\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.61667\n",
      "Epoch 28/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1011 - acc: 0.6328 - val_loss: 0.1182 - val_acc: 0.5647\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.61667\n",
      "Epoch 29/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1032 - acc: 0.6199 - val_loss: 0.1136 - val_acc: 0.5773\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.61667\n",
      "Epoch 30/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1021 - acc: 0.6268 - val_loss: 0.1143 - val_acc: 0.5767\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.61667\n",
      "Epoch 31/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1017 - acc: 0.6318 - val_loss: 0.1141 - val_acc: 0.5767\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.61667\n",
      "Epoch 32/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1010 - acc: 0.6346 - val_loss: 0.1145 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.61667\n",
      "Epoch 33/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1026 - acc: 0.6268 - val_loss: 0.1145 - val_acc: 0.5780\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.61667\n",
      "Epoch 34/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0998 - acc: 0.6384 - val_loss: 0.1146 - val_acc: 0.5733\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.61667\n",
      "Epoch 35/100\n",
      "5996/5996 [==============================] - 0s 5us/step - loss: 0.1018 - acc: 0.6271 - val_loss: 0.1153 - val_acc: 0.5720\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.61667\n",
      "Epoch 36/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1020 - acc: 0.6276 - val_loss: 0.1152 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.61667\n",
      "Epoch 37/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0989 - acc: 0.6456 - val_loss: 0.1156 - val_acc: 0.5720\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.61667\n",
      "Epoch 38/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1027 - acc: 0.6264 - val_loss: 0.1257 - val_acc: 0.5193\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.61667\n",
      "Epoch 39/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0999 - acc: 0.6413 - val_loss: 0.1150 - val_acc: 0.5747\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.61667\n",
      "Epoch 40/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1020 - acc: 0.6261 - val_loss: 0.1162 - val_acc: 0.5673\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.61667\n",
      "Epoch 41/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1013 - acc: 0.6334 - val_loss: 0.1160 - val_acc: 0.5667\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.61667\n",
      "Epoch 42/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0995 - acc: 0.6418 - val_loss: 0.1163 - val_acc: 0.5620\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.61667\n",
      "Epoch 43/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1022 - acc: 0.6289 - val_loss: 0.1153 - val_acc: 0.5653\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.61667\n",
      "Epoch 44/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0982 - acc: 0.6456 - val_loss: 0.1239 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.61667\n",
      "Epoch 45/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1040 - acc: 0.6166 - val_loss: 0.1186 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.61667\n",
      "Epoch 46/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1000 - acc: 0.6433 - val_loss: 0.1207 - val_acc: 0.5367\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.61667\n",
      "Epoch 47/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1007 - acc: 0.6316 - val_loss: 0.1212 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.61667\n",
      "Epoch 48/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1010 - acc: 0.6336 - val_loss: 0.1231 - val_acc: 0.5327\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.61667\n",
      "Epoch 49/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1002 - acc: 0.6393 - val_loss: 0.1187 - val_acc: 0.5480\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.61667\n",
      "Epoch 50/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.0997 - acc: 0.6411 - val_loss: 0.1174 - val_acc: 0.5567\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.61667\n",
      "Epoch 51/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1015 - acc: 0.6263 - val_loss: 0.1216 - val_acc: 0.5313\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.61667\n",
      "Epoch 52/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1005 - acc: 0.6386 - val_loss: 0.1195 - val_acc: 0.5413\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.61667\n",
      "Epoch 53/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0985 - acc: 0.6486 - val_loss: 0.1180 - val_acc: 0.5540\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.61667\n",
      "Epoch 54/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.0988 - acc: 0.6478 - val_loss: 0.1223 - val_acc: 0.5407\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.61667\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1033 - acc: 0.6172 - val_loss: 0.1182 - val_acc: 0.5540\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.61667\n",
      "Epoch 56/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.0999 - acc: 0.6383 - val_loss: 0.1176 - val_acc: 0.5633\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.61667\n",
      "Epoch 57/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1001 - acc: 0.6378 - val_loss: 0.1181 - val_acc: 0.5567\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.61667\n",
      "Epoch 58/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0988 - acc: 0.6458 - val_loss: 0.1201 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.61667\n",
      "Epoch 59/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1025 - acc: 0.6246 - val_loss: 0.1179 - val_acc: 0.5573\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.61667\n",
      "Epoch 60/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0977 - acc: 0.6548 - val_loss: 0.1191 - val_acc: 0.5533\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.61667\n",
      "Epoch 61/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1005 - acc: 0.6384 - val_loss: 0.1194 - val_acc: 0.5480\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.61667\n",
      "Epoch 62/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1024 - acc: 0.6288 - val_loss: 0.1186 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.61667\n",
      "Epoch 63/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0983 - acc: 0.6468 - val_loss: 0.1187 - val_acc: 0.5553\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.61667\n",
      "Epoch 64/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.0994 - acc: 0.6448 - val_loss: 0.1223 - val_acc: 0.5473\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.61667\n",
      "Epoch 65/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1017 - acc: 0.6333 - val_loss: 0.1191 - val_acc: 0.5607\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.61667\n",
      "Epoch 66/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0985 - acc: 0.6493 - val_loss: 0.1193 - val_acc: 0.5473\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.61667\n",
      "Epoch 67/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1014 - acc: 0.6353 - val_loss: 0.1191 - val_acc: 0.5560\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.61667\n",
      "Epoch 68/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0984 - acc: 0.6494 - val_loss: 0.1201 - val_acc: 0.5527\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.61667\n",
      "Epoch 69/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1009 - acc: 0.6336 - val_loss: 0.1202 - val_acc: 0.5573\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.61667\n",
      "Epoch 70/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0995 - acc: 0.6431 - val_loss: 0.1201 - val_acc: 0.5573\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.61667\n",
      "Epoch 71/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0971 - acc: 0.6549 - val_loss: 0.1194 - val_acc: 0.5520\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.61667\n",
      "Epoch 72/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1021 - acc: 0.6259 - val_loss: 0.1193 - val_acc: 0.5573\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.61667\n",
      "Epoch 73/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0970 - acc: 0.6511 - val_loss: 0.1211 - val_acc: 0.5507\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.61667\n",
      "Epoch 74/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1006 - acc: 0.6343 - val_loss: 0.1222 - val_acc: 0.5293\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.61667\n",
      "Epoch 75/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0989 - acc: 0.6443 - val_loss: 0.1226 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.61667\n",
      "Epoch 76/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0999 - acc: 0.6394 - val_loss: 0.1249 - val_acc: 0.5267\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.61667\n",
      "Epoch 77/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0990 - acc: 0.6453 - val_loss: 0.1247 - val_acc: 0.5247\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.61667\n",
      "Epoch 78/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0995 - acc: 0.6354 - val_loss: 0.1290 - val_acc: 0.5087\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.61667\n",
      "Epoch 79/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0991 - acc: 0.6414 - val_loss: 0.1243 - val_acc: 0.5220\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.61667\n",
      "Epoch 80/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1016 - acc: 0.6334 - val_loss: 0.1241 - val_acc: 0.5247\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.61667\n",
      "Epoch 81/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.0976 - acc: 0.6511 - val_loss: 0.1205 - val_acc: 0.5487\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.61667\n",
      "Epoch 82/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0974 - acc: 0.6529 - val_loss: 0.1257 - val_acc: 0.5293\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.61667\n",
      "Epoch 83/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1029 - acc: 0.6251 - val_loss: 0.1198 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.61667\n",
      "Epoch 84/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.0983 - acc: 0.6471 - val_loss: 0.1205 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.61667\n",
      "Epoch 85/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0969 - acc: 0.6561 - val_loss: 0.1225 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.61667\n",
      "Epoch 86/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.1021 - acc: 0.6278 - val_loss: 0.1222 - val_acc: 0.5340\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.61667\n",
      "Epoch 87/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0984 - acc: 0.6474 - val_loss: 0.1214 - val_acc: 0.5527\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.61667\n",
      "Epoch 88/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0973 - acc: 0.6538 - val_loss: 0.1219 - val_acc: 0.5493\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.61667\n",
      "Epoch 89/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1013 - acc: 0.6338 - val_loss: 0.1205 - val_acc: 0.5433\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.61667\n",
      "Epoch 90/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0968 - acc: 0.6574 - val_loss: 0.1225 - val_acc: 0.5367\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.61667\n",
      "Epoch 91/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0994 - acc: 0.6433 - val_loss: 0.1232 - val_acc: 0.5407\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.61667\n",
      "Epoch 92/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0978 - acc: 0.6531 - val_loss: 0.1211 - val_acc: 0.5500\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.61667\n",
      "Epoch 93/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0994 - acc: 0.6416 - val_loss: 0.1237 - val_acc: 0.5380\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.61667\n",
      "Epoch 94/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0990 - acc: 0.6443 - val_loss: 0.1223 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.61667\n",
      "Epoch 95/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0964 - acc: 0.6591 - val_loss: 0.1216 - val_acc: 0.5473\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.61667\n",
      "Epoch 96/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1001 - acc: 0.6391 - val_loss: 0.1233 - val_acc: 0.5447\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.61667\n",
      "Epoch 97/100\n",
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.1001 - acc: 0.6393 - val_loss: 0.1225 - val_acc: 0.5460\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.61667\n",
      "Epoch 98/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.0976 - acc: 0.6484 - val_loss: 0.1230 - val_acc: 0.5393\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.61667\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5996/5996 [==============================] - 0s 4us/step - loss: 0.0994 - acc: 0.6433 - val_loss: 0.1224 - val_acc: 0.5447\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.61667\n",
      "Epoch 100/100\n",
      "5996/5996 [==============================] - 0s 3us/step - loss: 0.0988 - acc: 0.6454 - val_loss: 0.1221 - val_acc: 0.5480\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.61667\n"
     ]
=======
      "Train on 10045 samples, validate on 4948 samples\n",
      "Epoch 1/260\n",
      "10045/10045 [==============================] - 3s 327us/step - loss: 0.2154 - acc: 0.2274 - val_loss: 0.1640 - val_acc: 0.2122\n",
      "Epoch 2/260\n",
      "10045/10045 [==============================] - 2s 189us/step - loss: 0.1555 - acc: 0.2764 - val_loss: 0.1536 - val_acc: 0.2823\n",
      "Epoch 3/260\n",
      "10045/10045 [==============================] - 2s 181us/step - loss: 0.1536 - acc: 0.2996 - val_loss: 0.1519 - val_acc: 0.3068\n",
      "Epoch 4/260\n",
      "10045/10045 [==============================] - 2s 180us/step - loss: 0.1521 - acc: 0.3021 - val_loss: 0.1512 - val_acc: 0.2941\n",
      "Epoch 5/260\n",
      "10045/10045 [==============================] - 2s 181us/step - loss: 0.1509 - acc: 0.3194 - val_loss: 0.1493 - val_acc: 0.3159\n",
      "Epoch 6/260\n",
      "10045/10045 [==============================] - 2s 184us/step - loss: 0.1496 - acc: 0.3301 - val_loss: 0.1509 - val_acc: 0.3161\n",
      "Epoch 7/260\n",
      "10045/10045 [==============================] - 2s 182us/step - loss: 0.1489 - acc: 0.3406 - val_loss: 0.1472 - val_acc: 0.3397\n",
      "Epoch 8/260\n",
      "10045/10045 [==============================] - 2s 184us/step - loss: 0.1488 - acc: 0.3336 - val_loss: 0.1483 - val_acc: 0.3254\n",
      "Epoch 9/260\n",
      "10045/10045 [==============================] - 2s 182us/step - loss: 0.1487 - acc: 0.3383 - val_loss: 0.1482 - val_acc: 0.3343\n",
      "Epoch 10/260\n",
      "10045/10045 [==============================] - 2s 183us/step - loss: 0.1478 - acc: 0.3548 - val_loss: 0.1461 - val_acc: 0.3622\n",
      "Epoch 11/260\n",
      "10045/10045 [==============================] - 2s 204us/step - loss: 0.1475 - acc: 0.3520 - val_loss: 0.1461 - val_acc: 0.3636\n",
      "Epoch 12/260\n",
      "10045/10045 [==============================] - 2s 188us/step - loss: 0.1475 - acc: 0.3522 - val_loss: 0.1472 - val_acc: 0.3506\n",
      "Epoch 13/260\n",
      "10045/10045 [==============================] - 2s 185us/step - loss: 0.1472 - acc: 0.3536 - val_loss: 0.1492 - val_acc: 0.3385\n",
      "Epoch 14/260\n",
      "10045/10045 [==============================] - 2s 185us/step - loss: 0.1470 - acc: 0.3607 - val_loss: 0.1462 - val_acc: 0.3618\n",
      "Epoch 15/260\n",
      "10045/10045 [==============================] - 2s 184us/step - loss: 0.1470 - acc: 0.3533 - val_loss: 0.1456 - val_acc: 0.3648\n",
      "Epoch 16/260\n",
      "10045/10045 [==============================] - 2s 186us/step - loss: 0.1469 - acc: 0.3538 - val_loss: 0.1455 - val_acc: 0.3688\n",
      "Epoch 17/260\n",
      "10045/10045 [==============================] - 2s 185us/step - loss: 0.1467 - acc: 0.3564 - val_loss: 0.1454 - val_acc: 0.3664\n",
      "Epoch 18/260\n",
      "10045/10045 [==============================] - 2s 186us/step - loss: 0.1467 - acc: 0.3573 - val_loss: 0.1453 - val_acc: 0.3705\n",
      "Epoch 19/260\n",
      "10045/10045 [==============================] - 2s 189us/step - loss: 0.1467 - acc: 0.3564 - val_loss: 0.1460 - val_acc: 0.3591\n",
      "Epoch 20/260\n",
      "10045/10045 [==============================] - 2s 201us/step - loss: 0.1466 - acc: 0.3579 - val_loss: 0.1453 - val_acc: 0.3688\n",
      "Epoch 21/260\n",
      "10045/10045 [==============================] - 2s 190us/step - loss: 0.1467 - acc: 0.3584 - val_loss: 0.1550 - val_acc: 0.3379\n",
      "Epoch 22/260\n",
      "10045/10045 [==============================] - 2s 189us/step - loss: 0.1469 - acc: 0.3548 - val_loss: 0.1462 - val_acc: 0.3551\n",
      "Epoch 23/260\n",
      "10045/10045 [==============================] - 2s 192us/step - loss: 0.1471 - acc: 0.3561 - val_loss: 0.1456 - val_acc: 0.3581\n",
      "Epoch 24/260\n",
      "10045/10045 [==============================] - 2s 189us/step - loss: 0.1466 - acc: 0.3587 - val_loss: 0.1508 - val_acc: 0.3405\n",
      "Epoch 25/260\n",
      "10045/10045 [==============================] - 2s 197us/step - loss: 0.1466 - acc: 0.3611 - val_loss: 0.1450 - val_acc: 0.3684\n",
      "Epoch 26/260\n",
      "10045/10045 [==============================] - 2s 195us/step - loss: 0.1466 - acc: 0.3561 - val_loss: 0.1462 - val_acc: 0.3656\n",
      "Epoch 27/260\n",
      "10045/10045 [==============================] - 2s 188us/step - loss: 0.1465 - acc: 0.3590 - val_loss: 0.1472 - val_acc: 0.3676\n",
      "Epoch 28/260\n",
      "10045/10045 [==============================] - 2s 190us/step - loss: 0.1466 - acc: 0.3586 - val_loss: 0.1460 - val_acc: 0.3571\n",
      "Epoch 29/260\n",
      "10045/10045 [==============================] - 2s 185us/step - loss: 0.1463 - acc: 0.3624 - val_loss: 0.1456 - val_acc: 0.3605\n",
      "Epoch 30/260\n",
      "10045/10045 [==============================] - 2s 181us/step - loss: 0.1464 - acc: 0.3606 - val_loss: 0.1474 - val_acc: 0.3486\n",
      "Epoch 31/260\n",
      "10045/10045 [==============================] - 2s 183us/step - loss: 0.1466 - acc: 0.3573 - val_loss: 0.1458 - val_acc: 0.3660\n",
      "Epoch 32/260\n",
      "10045/10045 [==============================] - 2s 202us/step - loss: 0.1465 - acc: 0.3586 - val_loss: 0.1461 - val_acc: 0.3672\n",
      "Epoch 33/260\n",
      "10045/10045 [==============================] - 2s 188us/step - loss: 0.1466 - acc: 0.3598 - val_loss: 0.1455 - val_acc: 0.3650\n",
      "Epoch 34/260\n",
      "10045/10045 [==============================] - 2s 186us/step - loss: 0.1465 - acc: 0.3571 - val_loss: 0.1451 - val_acc: 0.3751\n",
      "Epoch 35/260\n",
      "10045/10045 [==============================] - 2s 186us/step - loss: 0.1463 - acc: 0.3599 - val_loss: 0.1455 - val_acc: 0.3626\n",
      "Epoch 36/260\n",
      "10045/10045 [==============================] - 2s 185us/step - loss: 0.1462 - acc: 0.3610 - val_loss: 0.1492 - val_acc: 0.3399\n",
      "Epoch 37/260\n",
      "10045/10045 [==============================] - 2s 184us/step - loss: 0.1462 - acc: 0.3608 - val_loss: 0.1446 - val_acc: 0.3666\n",
      "Epoch 38/260\n",
      "10045/10045 [==============================] - 2s 198us/step - loss: 0.1462 - acc: 0.3617 - val_loss: 0.1476 - val_acc: 0.3478\n",
      "Epoch 39/260\n",
      "10045/10045 [==============================] - 2s 183us/step - loss: 0.1463 - acc: 0.3596 - val_loss: 0.1457 - val_acc: 0.3664\n",
      "Epoch 40/260\n",
      "10045/10045 [==============================] - 2s 192us/step - loss: 0.1463 - acc: 0.3594 - val_loss: 0.1459 - val_acc: 0.3634\n",
      "Epoch 41/260\n",
      " 2140/10045 [=====>........................] - ETA: 1s - loss: 0.1464 - acc: 0.3533"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-2975f2341d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m260\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mglobal_variables\u001b[0;34m(scope)\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m   \"\"\"\n\u001b[0;32m-> 2692\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_VARIABLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_collection\u001b[0;34m(key, scope)\u001b[0m\n\u001b[1;32m   5925\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5926\u001b[0m   \"\"\"\n\u001b[0;32m-> 5927\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5559\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5560\u001b[0m   \"\"\"\n\u001b[0;32m-> 5561\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5563\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhas_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5202\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5203\u001b[0m     \u001b[0;34m\"\"\"Override that returns a global default if the stack is empty.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5204\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DefaultGraphStack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5206\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_GetGlobalDefaultGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
>>>>>>> zekun
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(tr_df['AdoptionSpeed'], num_classes=5)\n",
    "y_valid = np_utils.to_categorical(val_df['AdoptionSpeed'], num_classes=5)\n",
    "continuous = ['Type','Age','Breed1','Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', \n",
    "          'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized','Health', 'Quantity','State','VideoAmt','PhotoAmt']\n",
    "cs = StandardScaler()\n",
    "trainContinuous = cs.fit_transform(tr_df[continuous])\n",
    "trainContinuous2 = cs.fit_transform(val_df[continuous])\n",
    "trainContinuous3 = cs.fit_transform(test_df[continuous])\n",
    "x_train = np.hstack([trainContinuous])\n",
    "x_valid = np.hstack([trainContinuous2])\n",
    "x_test = np.hstack([trainContinuous3])\n",
    "x_train = tr_df[continuous]\n",
    "x_valid = val_df[continuous]\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=18),\n",
    "    Activation('relu'),\n",
    "    Dense(96),\n",
    "    Activation('relu'),\n",
    "    Dense(64),\n",
    "    Activation('relu'),\n",
    "    Dense(32),\n",
    "    Activation('relu'),\n",
    "    Dense(32),\n",
    "    Activation('relu'),\n",
    "    Dense(5),\n",
    "    Activation('sigmoid'),\n",
    "])\n",
    "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# We add metrics to get more results you want to see\n",
    "#categorical_crossentropy--mse\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "filepath=\"weights_image_categorcial.hdf6\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "earlystopped = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=10, verbose=0, mode='max')\n",
    "# callbacks_list = [checkpoint, earlystopped]\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "for i in range(10):\n",
    "    x_train1, x_train2, y_train1,y_train2 = train_test_split(x_train,y_train, test_size = 0.2, random_state = i*15);\n",
    "    history = model.fit(x_train1, y_train1,validation_data = (x_train2,y_train2),epochs=100, batch_size=1000,shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('bestForNow.hdf6')"
   ]
=======
   "execution_count": null,
   "metadata": {
    "_uuid": "af4f6d90a3808b86ed1a4fc0b5bd23bfb7f60196"
   },
   "outputs": [],
   "source": []
>>>>>>> zekun
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "  \n",
    "def extractMax(input): \n",
    "  \n",
    "     # get a list of all numbers separated by  \n",
    "     # lower case characters  \n",
    "     # \\d+ is a regular expression which means \n",
    "     # one or more digit \n",
    "     # output will be like ['100','564','365'] \n",
    "     numbers = re.findall('\\d+',input) \n",
    "  \n",
    "     # now we need to convert each number into integer \n",
    "     # int(string) converts string into integer \n",
    "     # we will map int() function onto all elements  \n",
    "     # of numbers list \n",
    "     numbers = map(int,numbers) \n",
    "  \n",
    "     return max(numbers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f508f56d4cab23c936752a1033028117e5a4b08c"
   },
   "outputs": [],
   "source": [
    "tr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "079cf918082ebbeec3902493f0055a9a3633912c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n"
     ]
    }
   ],
   "source": [
    "from numpy  import array\n",
    "print('\\nTesting ------------')\n",
    "# Evaluate the model with the metrics we defined earlier\n",
    "loss = model.predict(x_train, batch_size=1000)\n",
    "ans = [0 for x in range(len(x_train))]\n",
    "for i in range(len(x_train)):\n",
    "    index_of_maximum = np.where(loss[i] == loss[i].max());\n",
    "    ans[i] = extractMax(str(index_of_maximum))\n",
    "ans = array(ans)\n",
    "\n",
    "y_train = tr_df['AdoptionSpeed'].values;\n",
    "\n",
    "loss1 = model.predict(x_valid, batch_size=1000)\n",
    "ans1 = [0 for x in range(len(x_valid))]\n",
    "for i in range(len(x_valid)):\n",
    "    index_of_maximum = np.where(loss1[i] == loss1[i].max());\n",
    "    ans1[i] = extractMax(str(index_of_maximum))\n",
    "ans1 = array(ans1)\n",
    "\n",
    "y_valid = val_df['AdoptionSpeed'].values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "253e65605d45da4db28f84363edeb98fb54431fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "avg train kappa: 0.5717094404116411\n",
      "\n",
      "avg valid kappa: 0.2141534975425673\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = ans;\n",
    "y_valid_pred = ans1;\n",
    "avg_train_kappa = 0;\n",
    "avg_valid_kappa =0;\n",
    "avg_train_kappa += kappa(y_train_pred, y_train)\n",
    "avg_valid_kappa += kappa(y_valid_pred, y_valid)\n",
    "print(\"\\navg train kappa:\", avg_train_kappa,)\n",
    "print(\"\\navg valid kappa:\", avg_valid_kappa,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = plt.figure(figsize=(10,3))\n",
    "ax = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "\n",
    "ax.plot(history.history['loss'])\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.set_title('Model loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.legend(['train', 'valid'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['acc'])\n",
    "ax2.plot(history.history['val_acc'])\n",
    "ax2.legend(['acc', 'val_acc'])\n",
    "ax2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "def kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
