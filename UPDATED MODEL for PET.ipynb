{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import cohen_kappa_score as kappa_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "kappa_scorer = make_scorer(kappa_score)\n",
    "from keras.constraints import maxnorm\n",
    "import os\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import concatenate\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout, Dense, np\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/all/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/all/test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "ef5d56c772b4442e32b2637e94141cb09ac70751"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>RescuerID</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PetID</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>41326</td>\n",
       "      <td>8480853f516546f6cf33aa88cd76c379</td>\n",
       "      <td>0</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>86e1089a3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>6296e909a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>3422e4906</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>41401</td>\n",
       "      <td>9238e4f44c71a75282e62f7136c6b240</td>\n",
       "      <td>0</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>5842f1ff5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>850a43f90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2       Nibble    3     299       0       1       1       7       0   \n",
       "1     2  No Name Yet    1     265       0       1       1       2       0   \n",
       "2     1       Brisco    1     307       0       1       2       7       0   \n",
       "3     1         Miko    4     307       0       2       1       2       0   \n",
       "4     1       Hunter    1     307       0       1       1       0       0   \n",
       "\n",
       "   MaturitySize  ...  Health  Quantity  Fee  State  \\\n",
       "0             1  ...       1         1  100  41326   \n",
       "1             2  ...       1         1    0  41401   \n",
       "2             2  ...       1         1    0  41326   \n",
       "3             2  ...       1         1  150  41401   \n",
       "4             2  ...       1         1    0  41326   \n",
       "\n",
       "                          RescuerID  VideoAmt  \\\n",
       "0  8480853f516546f6cf33aa88cd76c379         0   \n",
       "1  3082c7125d8fb66f7dd4bff4192c8b14         0   \n",
       "2  fa90fa5b1ee11c86938398b60abc32cb         0   \n",
       "3  9238e4f44c71a75282e62f7136c6b240         0   \n",
       "4  95481e953f8aed9ec3d16fc4509537e8         0   \n",
       "\n",
       "                                         Description      PetID PhotoAmt  \\\n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3      1.0   \n",
       "1  I just found it alone yesterday near my apartm...  6296e909a      2.0   \n",
       "2  Their pregnant mother was dumped by her irresp...  3422e4906      7.0   \n",
       "3  Good guard dog, very alert, active, obedience ...  5842f1ff5      8.0   \n",
       "4  This handsome yet cute boy is up for adoption....  850a43f90      3.0   \n",
       "\n",
       "   AdoptionSpeed  \n",
       "0              2  \n",
       "1              0  \n",
       "2              3  \n",
       "3              2  \n",
       "4              2  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "1f3134cdea8d875a07091109a7dd346cb6a4fa75"
   },
   "outputs": [],
   "source": [
    "cat_cols = ['Type','Age','Breed1','Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', \n",
    "          'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized','Health', 'Quantity','State','VideoAmt','PhotoAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "17ae5c7fc86c5fe1cae9fae501bfb55197ec73ca"
   },
   "outputs": [],
   "source": [
    "num_cols = ['Fee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "9a97f8dc0cf912e766d0d5e9d81c2676fc2549dd"
   },
   "outputs": [],
   "source": [
    "text_cols = ['Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a2628badb9b1f04cffca6d30b81f45c59227f94"
   },
   "source": [
    "## Handling categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "0afaf139a012943cb6d03deb4cfa2fcc9b9a16ed"
   },
   "outputs": [],
   "source": [
    "embed_sizes = [len(train_df[col].unique()) + 1 for col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 107, 177, 136, 4, 8, 8, 7, 5, 4, 4, 4, 4, 4, 20, 15, 10, 32]\n"
     ]
    }
   ],
   "source": [
    "print(embed_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7cca9a5c04d10a9c37ba1e9ae8b9a638484c2e55"
   },
   "source": [
    "## Handling numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "b05f8395653cc9e4592327fb66ed58f7035349c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling num_cols\n",
      "scaling Fee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "print('scaling num_cols')\n",
    "for col in num_cols:\n",
    "    print('scaling {}'.format(col))\n",
    "    col_mean = train_df[col].mean()\n",
    "    train_df[col].fillna(col_mean, inplace=True)\n",
    "    test_df[col].fillna(col_mean, inplace=True)\n",
    "    scaler = StandardScaler()\n",
    "    train_df[col] = scaler.fit_transform(train_df[col].values.reshape(-1, 1))\n",
    "    test_df[col] = scaler.transform(test_df[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2392bdaea329920f259f98b3cce6f3da4d59f0b2"
   },
   "source": [
    "## Handling text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "a561a4e861fcafd2760ecd2c23c4489ac5fecf85"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "f613316747775cf123e090079e8fb87472e94285"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1175it [00:00, 11746.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000000it [01:22, 12146.32it/s]\n"
     ]
    }
   ],
   "source": [
    "print('getting embeddings')\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in tqdm(open('//Users/zekunzhao/Downloads/wiki-news-300d-1M-subword.vec')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "a9265461a9d4fb775ccee06dd08b0f4f10b7057e"
   },
   "outputs": [],
   "source": [
    "num_words = 20000\n",
    "maxlen = 80\n",
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "abf3715d1ac826cd72c9656580b40617c8ba5fc6"
   },
   "outputs": [],
   "source": [
    "train_df['Description'] = train_df['Description'].astype(str).fillna('no text')\n",
    "test_df['Description'] = test_df['Description'].astype(str).fillna('no text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "8de1d2c7b25c3f94b8816b2d839b9ca5a7723e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Fitting tokenizer...\n"
     ]
    }
   ],
   "source": [
    "print(\"   Fitting tokenizer...\")\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(train_df['Description'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "09501dbc242aa63863ae78989f5fbf613a60c148"
   },
   "outputs": [],
   "source": [
    "train_df['Description'] = tokenizer.texts_to_sequences(train_df['Description'])\n",
    "test_df['Description'] = tokenizer.texts_to_sequences(test_df['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "6d5bfc3b6dfa04e5723ed9c1ee5a027849aab513"
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(num_words, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= num_words: continue\n",
    "    try:\n",
    "        embedding_vector = embeddings_index[word]\n",
    "    except KeyError:\n",
    "        embedding_vector = None\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "d9c4764bb94b0d5a65b28b02040c47e562471d8f"
   },
   "outputs": [],
   "source": [
    "def get_input_features(df):\n",
    "    X = {'description':pad_sequences(df['Description'], maxlen=maxlen)}\n",
    "    X['numerical'] = np.array(df[num_cols])\n",
    "    for cat in cat_cols:\n",
    "        X[cat] = np.array(df[cat])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68c7d6bd517854b1adf9fdb5ee15bc493e95d295"
   },
   "source": [
    "## Define NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "5b6b71a4869aef86857014827789eed549c0c022"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Concatenate, Flatten, Dense, Dropout, BatchNormalization,LSTM, CuDNNLSTM, SpatialDropout1D\n",
    "from keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import  Adam\n",
    "\n",
    "def prepare_data(data):\n",
    "    pet_id = data.PetID\n",
    "\n",
    "    # Remove unused features\n",
    "    data.drop(['RescuerID', 'Description', 'PetID', 'State'], axis=1, inplace=True)\n",
    "\n",
    "    # Apply binning to ages\n",
    "    data['Age'] = pd.cut(data['Age'], [-1, 2, 3, 6, 255], labels=[0, 1, 2, 3])\n",
    "\n",
    "    # Apply binning to fee\n",
    "    data['Fee'] = pd.cut(data['Fee'], [-1, 50, 100, 200, 3000], labels=[0, 1, 2, 3])\n",
    "\n",
    "    # Apply binning to photo amount\n",
    "    data['PhotoAmt'] = pd.cut(data['PhotoAmt'], [-1, 1, 5, 10, 100], labels=[0, 1, 2, 3])\n",
    "\n",
    "    # Apply binning to video amount\n",
    "    data['VideoAmt'] = pd.cut(data['VideoAmt'], [-1, 1, 100], labels=[0, 1])\n",
    "\n",
    "    # Replace names with 1 is present, 0 if not present\n",
    "    data.loc[data['Name'].notnull(), 'Name'] = 1\n",
    "    data.loc[data['Name'].isnull(), 'Name'] = 0\n",
    "\n",
    "    # Fill missing continuous data\n",
    "    data_continuous = data.select_dtypes(exclude=['object'])\n",
    "    data_continuous.fillna(0, inplace=True)\n",
    "\n",
    "    # Fill missing string data\n",
    "    data_categorical = data.select_dtypes(include=['object'])\n",
    "    data_categorical.fillna('NONE', inplace=True)\n",
    "\n",
    "    final_data = data_continuous.merge(data_categorical, left_index=True, right_index=True)\n",
    "\n",
    "    return final_data, data_categorical, data_continuous, pet_id, data.shape[1]\n",
    "\n",
    "\n",
    "categorical_inputs = []\n",
    "for cat in cat_cols:\n",
    "    categorical_inputs.append(Input(shape=[1], name=cat))\n",
    "\n",
    "categorical_embeddings = []\n",
    "for i, cat in enumerate(cat_cols):\n",
    "    categorical_embeddings.append(\n",
    "        Embedding(embed_sizes[i], 10)(categorical_inputs[i]))\n",
    "\n",
    "categorical_logits = Concatenate()([Flatten()(cat_emb) for cat_emb in categorical_embeddings])\n",
    "categorical_logits = Dense(256, activation = 'relu')(categorical_logits)\n",
    "\n",
    "\n",
    "numerical_inputs = Input(shape=[len(num_cols)], name='numerical')\n",
    "numerical_logits = numerical_inputs\n",
    "numerical_logits = BatchNormalization()(numerical_logits)\n",
    "numerical_logits = Dense(128, activation = 'relu')(numerical_logits)\n",
    "\n",
    "text_inp = Input(shape=[maxlen], name='description')\n",
    "text_embed = Embedding(nb_words, embed_size, weights=[embedding_matrix], trainable=False)(text_inp)\n",
    "text_logits = SpatialDropout1D(0.2)(text_embed)\n",
    "text_logits = Bidirectional(LSTM(64, return_sequences=True))(text_logits)\n",
    "avg_pool = GlobalAveragePooling1D()(text_logits)\n",
    "max_pool = GlobalMaxPool1D()(text_logits)\n",
    "text_logits = Concatenate()([avg_pool, max_pool])\n",
    "\n",
    "x = Concatenate()([categorical_logits, text_logits, numerical_logits])\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "out = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[text_inp] + categorical_inputs + [numerical_inputs],outputs=out)\n",
    "model.compile(optimizer=Adam(lr = 0.0001), loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "7bf00ec907fa08fe47ef7a36d297736a8eb98aa3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for i, l in enumerate(tr_df['AdoptionSpeed'].values):\n",
    "#    y_train[i,l] = 1\n",
    "#for i, l in enumerate(val_df['AdoptionSpeed'].values):\n",
    "#    y_valid[i,l] = 1\n",
    "tr_df, val_df = train_test_split(train_df, test_size = 0.6, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "beb7737cd9a56e2616e0fcf7c415d52433f1f0da"
   },
   "outputs": [],
   "source": [
    "# from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "ccc902b5c62afceca9159762813d525cc5d2482e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5997,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df['AdoptionSpeed'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "c8ba9c6ea62da5a0d94acbb22d88c5c89e2f3c1a"
   },
   "outputs": [],
   "source": [
    "y_train = tr_df['AdoptionSpeed'].values / 4\n",
    "y_valid = val_df['AdoptionSpeed'].values / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "28870d4162b0556201bc5016c7b817532c615324"
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(tr_df['AdoptionSpeed'], num_classes=5)\n",
    "y_valid = np_utils.to_categorical(val_df['AdoptionSpeed'], num_classes=5)\n",
    "# y_test = np_utils.to_categorical(test_df['AdoptionSpeed'], num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "d11852ccd09ff14509a1e8aadc09ec8e0c510c90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>RescuerID</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PetID</th>\n",
       "      <th>PhotoAmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Puppy</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.641842</td>\n",
       "      <td>41326</td>\n",
       "      <td>4475f31553f0170229455e3c5645644f</td>\n",
       "      <td>0</td>\n",
       "      <td>[72, 5, 590, 6, 3, 269, 32, 38, 13, 3234, 16, ...</td>\n",
       "      <td>378fcc4fc</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>London</td>\n",
       "      <td>24</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.271132</td>\n",
       "      <td>41326</td>\n",
       "      <td>4475f31553f0170229455e3c5645644f</td>\n",
       "      <td>0</td>\n",
       "      <td>[427, 736, 39, 20, 54, 6, 619, 667]</td>\n",
       "      <td>73c10e136</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Snowball</td>\n",
       "      <td>20</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.641842</td>\n",
       "      <td>41326</td>\n",
       "      <td>4475f31553f0170229455e3c5645644f</td>\n",
       "      <td>0</td>\n",
       "      <td>[7860, 357, 219, 47, 43, 9, 5, 74, 3, 369, 108...</td>\n",
       "      <td>72000c4c5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Malibu</td>\n",
       "      <td>5</td>\n",
       "      <td>266</td>\n",
       "      <td>252</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.004184</td>\n",
       "      <td>41326</td>\n",
       "      <td>4475f31553f0170229455e3c5645644f</td>\n",
       "      <td>0</td>\n",
       "      <td>[13607, 101, 753, 259, 105, 124, 88, 165, 1, 1...</td>\n",
       "      <td>e147a4b9f</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Lala Girl</td>\n",
       "      <td>6</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.641842</td>\n",
       "      <td>41326</td>\n",
       "      <td>4475f31553f0170229455e3c5645644f</td>\n",
       "      <td>0</td>\n",
       "      <td>[3696, 894, 21, 191, 148, 3, 141, 158, 52, 179...</td>\n",
       "      <td>43fbba852</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type       Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     1      Puppy    2     307       0       1       1       0       0   \n",
       "1     2     London   24     266       0       1       2       7       0   \n",
       "2     2   Snowball   20     266       0       2       7       0       0   \n",
       "3     2     Malibu    5     266     252       2       1       6       7   \n",
       "4     1  Lala Girl    6     307       0       2       1       2       7   \n",
       "\n",
       "   MaturitySize  ...  Sterilized  Health  Quantity       Fee  State  \\\n",
       "0             2  ...           2       1         1  1.641842  41326   \n",
       "1             2  ...           1       1         1 -0.271132  41326   \n",
       "2             2  ...           1       1         1  1.641842  41326   \n",
       "3             2  ...           1       1         1  1.004184  41326   \n",
       "4             2  ...           1       1         1  1.641842  41326   \n",
       "\n",
       "                          RescuerID  VideoAmt  \\\n",
       "0  4475f31553f0170229455e3c5645644f         0   \n",
       "1  4475f31553f0170229455e3c5645644f         0   \n",
       "2  4475f31553f0170229455e3c5645644f         0   \n",
       "3  4475f31553f0170229455e3c5645644f         0   \n",
       "4  4475f31553f0170229455e3c5645644f         0   \n",
       "\n",
       "                                         Description      PetID  PhotoAmt  \n",
       "0  [72, 5, 590, 6, 3, 269, 32, 38, 13, 3234, 16, ...  378fcc4fc       3.0  \n",
       "1                [427, 736, 39, 20, 54, 6, 619, 667]  73c10e136       1.0  \n",
       "2  [7860, 357, 219, 47, 43, 9, 5, 74, 3, 369, 108...  72000c4c5       1.0  \n",
       "3  [13607, 101, 753, 259, 105, 124, 88, 165, 1, 1...  e147a4b9f       1.0  \n",
       "4  [3696, 894, 21, 191, 148, 3, 141, 158, 52, 179...  43fbba852       1.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train = get_input_features(tr_df)\n",
    "# X_valid = get_input_features(val_df)\n",
    "# X_test = get_input_features(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/zekunzhao/venv/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "continuous = ['Type','Age','Breed1','Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', \n",
    "          'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized','Health', 'Quantity','State','VideoAmt','PhotoAmt']\n",
    "# zipcodes = tr_df[uncontinuous].value_counts().keys().tolist()\n",
    "# counts = tr_df[uncontinuous].value_counts().tolist()\n",
    "\n",
    "# \t# loop over each of the unique zip codes and their corresponding\n",
    "# \t# count\n",
    "# for (zipcode, count) in zip(zipcodes, counts):\n",
    "# \t\t# the zip code counts for our housing dataset is *extremely*\n",
    "# \t\t# unbalanced (some only having 1 or 2 houses per zip code)\n",
    "# \t\t# so let's sanitize our data by removing any houses with less\n",
    "# \t\t# than 25 houses per zip code\n",
    "# \tif count < 25:\n",
    "# \t\tidxs = tr_df[tr_df[uncontinuous] == zipcode].index\n",
    "# \t\ttr_df.drop(idxs, inplace=True)\n",
    "        \n",
    "# zipBinarizer = LabelBinarizer().fit(tr_df[uncontinuous])\n",
    "# trainCategorical = zipBinarizer.transform(tr_df[uncontinuous])\n",
    "\n",
    "cs = MinMaxScaler()\n",
    "trainContinuous = cs.fit_transform(tr_df[continuous])\n",
    "trainContinuous2 = cs.fit_transform(val_df[continuous])\n",
    "trainContinuous3 = cs.fit_transform(test_df[continuous])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 8996 samples\n",
      "Epoch 1/260\n",
      "5997/5997 [==============================] - 2s 268us/step - loss: 0.1569 - acc: 0.2738 - val_loss: 0.1520 - val_acc: 0.2807\n",
      "Epoch 2/260\n",
      "5997/5997 [==============================] - 1s 186us/step - loss: 0.1497 - acc: 0.3167 - val_loss: 0.1493 - val_acc: 0.3226\n",
      "Epoch 3/260\n",
      "5997/5997 [==============================] - 1s 184us/step - loss: 0.1484 - acc: 0.3308 - val_loss: 0.1477 - val_acc: 0.3420\n",
      "Epoch 4/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1472 - acc: 0.3408 - val_loss: 0.1474 - val_acc: 0.3430\n",
      "Epoch 5/260\n",
      "5997/5997 [==============================] - 1s 184us/step - loss: 0.1464 - acc: 0.3535 - val_loss: 0.1470 - val_acc: 0.3505\n",
      "Epoch 6/260\n",
      "5997/5997 [==============================] - 1s 177us/step - loss: 0.1455 - acc: 0.3632 - val_loss: 0.1464 - val_acc: 0.3606\n",
      "Epoch 7/260\n",
      "5997/5997 [==============================] - 1s 177us/step - loss: 0.1448 - acc: 0.3642 - val_loss: 0.1471 - val_acc: 0.3569\n",
      "Epoch 8/260\n",
      "5997/5997 [==============================] - 1s 185us/step - loss: 0.1444 - acc: 0.3724 - val_loss: 0.1458 - val_acc: 0.3610\n",
      "Epoch 9/260\n",
      "5997/5997 [==============================] - 1s 175us/step - loss: 0.1437 - acc: 0.3794 - val_loss: 0.1495 - val_acc: 0.3450\n",
      "Epoch 10/260\n",
      "5997/5997 [==============================] - 1s 194us/step - loss: 0.1433 - acc: 0.3774 - val_loss: 0.1477 - val_acc: 0.3376\n",
      "Epoch 11/260\n",
      "5997/5997 [==============================] - 1s 177us/step - loss: 0.1433 - acc: 0.3820 - val_loss: 0.1463 - val_acc: 0.3547\n",
      "Epoch 12/260\n",
      "5997/5997 [==============================] - 1s 178us/step - loss: 0.1425 - acc: 0.3907 - val_loss: 0.1460 - val_acc: 0.3547\n",
      "Epoch 13/260\n",
      "5997/5997 [==============================] - 1s 176us/step - loss: 0.1422 - acc: 0.3840 - val_loss: 0.1460 - val_acc: 0.3552\n",
      "Epoch 14/260\n",
      "5997/5997 [==============================] - 1s 180us/step - loss: 0.1418 - acc: 0.3860 - val_loss: 0.1450 - val_acc: 0.3679\n",
      "Epoch 15/260\n",
      "5997/5997 [==============================] - 1s 178us/step - loss: 0.1416 - acc: 0.3850 - val_loss: 0.1451 - val_acc: 0.3675\n",
      "Epoch 16/260\n",
      "5997/5997 [==============================] - 1s 179us/step - loss: 0.1413 - acc: 0.3979 - val_loss: 0.1456 - val_acc: 0.3639\n",
      "Epoch 17/260\n",
      "5997/5997 [==============================] - 1s 178us/step - loss: 0.1410 - acc: 0.3960 - val_loss: 0.1455 - val_acc: 0.3639\n",
      "Epoch 18/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1403 - acc: 0.4019 - val_loss: 0.1459 - val_acc: 0.3674\n",
      "Epoch 19/260\n",
      "5997/5997 [==============================] - 1s 202us/step - loss: 0.1404 - acc: 0.3944 - val_loss: 0.1460 - val_acc: 0.3661\n",
      "Epoch 20/260\n",
      "5997/5997 [==============================] - 1s 185us/step - loss: 0.1399 - acc: 0.4109 - val_loss: 0.1454 - val_acc: 0.3679\n",
      "Epoch 21/260\n",
      "5997/5997 [==============================] - 1s 177us/step - loss: 0.1393 - acc: 0.4125 - val_loss: 0.1497 - val_acc: 0.3221\n",
      "Epoch 22/260\n",
      "5997/5997 [==============================] - 1s 190us/step - loss: 0.1391 - acc: 0.4107 - val_loss: 0.1477 - val_acc: 0.3714\n",
      "Epoch 23/260\n",
      "5997/5997 [==============================] - 1s 202us/step - loss: 0.1391 - acc: 0.4124 - val_loss: 0.1468 - val_acc: 0.3636\n",
      "Epoch 24/260\n",
      "5997/5997 [==============================] - 1s 198us/step - loss: 0.1385 - acc: 0.4142 - val_loss: 0.1481 - val_acc: 0.3490\n",
      "Epoch 25/260\n",
      "5997/5997 [==============================] - 1s 175us/step - loss: 0.1384 - acc: 0.4124 - val_loss: 0.1464 - val_acc: 0.3562\n",
      "Epoch 26/260\n",
      "5997/5997 [==============================] - 1s 180us/step - loss: 0.1381 - acc: 0.4224 - val_loss: 0.1475 - val_acc: 0.3588\n",
      "Epoch 27/260\n",
      "5997/5997 [==============================] - 1s 177us/step - loss: 0.1379 - acc: 0.4204 - val_loss: 0.1472 - val_acc: 0.3673\n",
      "Epoch 28/260\n",
      "5997/5997 [==============================] - 1s 205us/step - loss: 0.1373 - acc: 0.4254 - val_loss: 0.1495 - val_acc: 0.3580\n",
      "Epoch 29/260\n",
      "5997/5997 [==============================] - 1s 202us/step - loss: 0.1372 - acc: 0.4225 - val_loss: 0.1519 - val_acc: 0.3642\n",
      "Epoch 30/260\n",
      "5997/5997 [==============================] - 1s 180us/step - loss: 0.1368 - acc: 0.4212 - val_loss: 0.1490 - val_acc: 0.3456\n",
      "Epoch 31/260\n",
      "5997/5997 [==============================] - 1s 217us/step - loss: 0.1367 - acc: 0.4280 - val_loss: 0.1487 - val_acc: 0.3588\n",
      "Epoch 32/260\n",
      "5997/5997 [==============================] - 1s 201us/step - loss: 0.1361 - acc: 0.4249 - val_loss: 0.1475 - val_acc: 0.3608\n",
      "Epoch 33/260\n",
      "5997/5997 [==============================] - 1s 192us/step - loss: 0.1363 - acc: 0.4374 - val_loss: 0.1485 - val_acc: 0.3615\n",
      "Epoch 34/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1359 - acc: 0.4346 - val_loss: 0.1495 - val_acc: 0.3574\n",
      "Epoch 35/260\n",
      "5997/5997 [==============================] - 1s 179us/step - loss: 0.1353 - acc: 0.4362 - val_loss: 0.1481 - val_acc: 0.3612\n",
      "Epoch 36/260\n",
      "5997/5997 [==============================] - 1s 201us/step - loss: 0.1353 - acc: 0.4421 - val_loss: 0.1498 - val_acc: 0.3505\n",
      "Epoch 37/260\n",
      "5997/5997 [==============================] - 1s 199us/step - loss: 0.1354 - acc: 0.4382 - val_loss: 0.1499 - val_acc: 0.3575\n",
      "Epoch 38/260\n",
      "5997/5997 [==============================] - 1s 194us/step - loss: 0.1349 - acc: 0.4394 - val_loss: 0.1487 - val_acc: 0.3623\n",
      "Epoch 39/260\n",
      "5997/5997 [==============================] - 1s 191us/step - loss: 0.1345 - acc: 0.4399 - val_loss: 0.1504 - val_acc: 0.3522\n",
      "Epoch 40/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1343 - acc: 0.4424 - val_loss: 0.1520 - val_acc: 0.3409\n",
      "Epoch 41/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1341 - acc: 0.4446 - val_loss: 0.1514 - val_acc: 0.3494\n",
      "Epoch 42/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1336 - acc: 0.4437 - val_loss: 0.1522 - val_acc: 0.3453\n",
      "Epoch 43/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1332 - acc: 0.4557 - val_loss: 0.1514 - val_acc: 0.3573\n",
      "Epoch 44/260\n",
      "5997/5997 [==============================] - 1s 186us/step - loss: 0.1332 - acc: 0.4531 - val_loss: 0.1530 - val_acc: 0.3443\n",
      "Epoch 45/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1332 - acc: 0.4502 - val_loss: 0.1510 - val_acc: 0.3555\n",
      "Epoch 46/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1326 - acc: 0.4566 - val_loss: 0.1576 - val_acc: 0.3479\n",
      "Epoch 47/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1324 - acc: 0.4559 - val_loss: 0.1514 - val_acc: 0.3509\n",
      "Epoch 48/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1322 - acc: 0.4592 - val_loss: 0.1562 - val_acc: 0.3349\n",
      "Epoch 49/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1318 - acc: 0.4554 - val_loss: 0.1523 - val_acc: 0.3609\n",
      "Epoch 50/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1317 - acc: 0.4639 - val_loss: 0.1545 - val_acc: 0.3583\n",
      "Epoch 51/260\n",
      "5997/5997 [==============================] - 1s 180us/step - loss: 0.1308 - acc: 0.4657 - val_loss: 0.1525 - val_acc: 0.3438\n",
      "Epoch 52/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1312 - acc: 0.4624 - val_loss: 0.1563 - val_acc: 0.3277\n",
      "Epoch 53/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1307 - acc: 0.4666 - val_loss: 0.1536 - val_acc: 0.3417\n",
      "Epoch 54/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1308 - acc: 0.4669 - val_loss: 0.1544 - val_acc: 0.3668\n",
      "Epoch 55/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1304 - acc: 0.4709 - val_loss: 0.1535 - val_acc: 0.3500\n",
      "Epoch 56/260\n",
      "5997/5997 [==============================] - 1s 187us/step - loss: 0.1303 - acc: 0.4686 - val_loss: 0.1537 - val_acc: 0.3527\n",
      "Epoch 57/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1296 - acc: 0.4737 - val_loss: 0.1564 - val_acc: 0.3540\n",
      "Epoch 58/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1296 - acc: 0.4744 - val_loss: 0.1564 - val_acc: 0.3520\n",
      "Epoch 59/260\n",
      "5997/5997 [==============================] - 1s 184us/step - loss: 0.1290 - acc: 0.4797 - val_loss: 0.1544 - val_acc: 0.3489\n",
      "Epoch 60/260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 1s 180us/step - loss: 0.1290 - acc: 0.4814 - val_loss: 0.1577 - val_acc: 0.3536\n",
      "Epoch 61/260\n",
      "5997/5997 [==============================] - 1s 179us/step - loss: 0.1291 - acc: 0.4812 - val_loss: 0.1556 - val_acc: 0.3470\n",
      "Epoch 62/260\n",
      "5997/5997 [==============================] - 1s 177us/step - loss: 0.1290 - acc: 0.4766 - val_loss: 0.1575 - val_acc: 0.3474\n",
      "Epoch 63/260\n",
      "5997/5997 [==============================] - 1s 177us/step - loss: 0.1289 - acc: 0.4842 - val_loss: 0.1571 - val_acc: 0.3448\n",
      "Epoch 64/260\n",
      "5997/5997 [==============================] - 1s 179us/step - loss: 0.1284 - acc: 0.4791 - val_loss: 0.1555 - val_acc: 0.3552\n",
      "Epoch 65/260\n",
      "5997/5997 [==============================] - 1s 178us/step - loss: 0.1282 - acc: 0.4816 - val_loss: 0.1582 - val_acc: 0.3402\n",
      "Epoch 66/260\n",
      "5997/5997 [==============================] - 1s 178us/step - loss: 0.1280 - acc: 0.4826 - val_loss: 0.1602 - val_acc: 0.3445\n",
      "Epoch 67/260\n",
      "5997/5997 [==============================] - 1s 173us/step - loss: 0.1282 - acc: 0.4897 - val_loss: 0.1548 - val_acc: 0.3524\n",
      "Epoch 68/260\n",
      "5997/5997 [==============================] - 1s 179us/step - loss: 0.1278 - acc: 0.4936 - val_loss: 0.1597 - val_acc: 0.3508\n",
      "Epoch 69/260\n",
      "5997/5997 [==============================] - 1s 177us/step - loss: 0.1280 - acc: 0.4872 - val_loss: 0.1566 - val_acc: 0.3500\n",
      "Epoch 70/260\n",
      "5997/5997 [==============================] - 1s 177us/step - loss: 0.1276 - acc: 0.4881 - val_loss: 0.1592 - val_acc: 0.3247\n",
      "Epoch 71/260\n",
      "5997/5997 [==============================] - 1s 179us/step - loss: 0.1274 - acc: 0.4916 - val_loss: 0.1581 - val_acc: 0.3339\n",
      "Epoch 72/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1269 - acc: 0.4889 - val_loss: 0.1586 - val_acc: 0.3498\n",
      "Epoch 73/260\n",
      "5997/5997 [==============================] - 1s 179us/step - loss: 0.1265 - acc: 0.4986 - val_loss: 0.1583 - val_acc: 0.3397\n",
      "Epoch 74/260\n",
      "5997/5997 [==============================] - 1s 178us/step - loss: 0.1265 - acc: 0.4959 - val_loss: 0.1604 - val_acc: 0.3527\n",
      "Epoch 75/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1260 - acc: 0.5041 - val_loss: 0.1588 - val_acc: 0.3527\n",
      "Epoch 76/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1261 - acc: 0.4977 - val_loss: 0.1612 - val_acc: 0.3380\n",
      "Epoch 77/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1258 - acc: 0.5028 - val_loss: 0.1610 - val_acc: 0.3515\n",
      "Epoch 78/260\n",
      "5997/5997 [==============================] - 1s 179us/step - loss: 0.1261 - acc: 0.4967 - val_loss: 0.1576 - val_acc: 0.3468\n",
      "Epoch 79/260\n",
      "5997/5997 [==============================] - 1s 196us/step - loss: 0.1255 - acc: 0.5078 - val_loss: 0.1579 - val_acc: 0.3500\n",
      "Epoch 80/260\n",
      "5997/5997 [==============================] - 1s 187us/step - loss: 0.1255 - acc: 0.5049 - val_loss: 0.1596 - val_acc: 0.3484\n",
      "Epoch 81/260\n",
      "5997/5997 [==============================] - 1s 215us/step - loss: 0.1253 - acc: 0.5043 - val_loss: 0.1598 - val_acc: 0.3522\n",
      "Epoch 82/260\n",
      "5997/5997 [==============================] - 1s 210us/step - loss: 0.1246 - acc: 0.5111 - val_loss: 0.1588 - val_acc: 0.3465\n",
      "Epoch 83/260\n",
      "5997/5997 [==============================] - 1s 205us/step - loss: 0.1247 - acc: 0.5071 - val_loss: 0.1609 - val_acc: 0.3419\n",
      "Epoch 84/260\n",
      "5997/5997 [==============================] - 1s 207us/step - loss: 0.1242 - acc: 0.5066 - val_loss: 0.1593 - val_acc: 0.3489\n",
      "Epoch 85/260\n",
      "5997/5997 [==============================] - 1s 186us/step - loss: 0.1244 - acc: 0.5076 - val_loss: 0.1646 - val_acc: 0.3494\n",
      "Epoch 86/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1239 - acc: 0.5113 - val_loss: 0.1609 - val_acc: 0.3440\n",
      "Epoch 87/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1239 - acc: 0.5043 - val_loss: 0.1657 - val_acc: 0.3412\n",
      "Epoch 88/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1235 - acc: 0.5126 - val_loss: 0.1615 - val_acc: 0.3271\n",
      "Epoch 89/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1238 - acc: 0.5093 - val_loss: 0.1608 - val_acc: 0.3463\n",
      "Epoch 90/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1232 - acc: 0.5128 - val_loss: 0.1602 - val_acc: 0.3576\n",
      "Epoch 91/260\n",
      "5997/5997 [==============================] - 1s 184us/step - loss: 0.1235 - acc: 0.5113 - val_loss: 0.1618 - val_acc: 0.3334\n",
      "Epoch 92/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1233 - acc: 0.5141 - val_loss: 0.1616 - val_acc: 0.3430\n",
      "Epoch 93/260\n",
      "5997/5997 [==============================] - 1s 215us/step - loss: 0.1226 - acc: 0.5203 - val_loss: 0.1637 - val_acc: 0.3399\n",
      "Epoch 94/260\n",
      "5997/5997 [==============================] - 1s 210us/step - loss: 0.1223 - acc: 0.5173 - val_loss: 0.1613 - val_acc: 0.3473\n",
      "Epoch 95/260\n",
      "5997/5997 [==============================] - 1s 207us/step - loss: 0.1232 - acc: 0.5164 - val_loss: 0.1604 - val_acc: 0.3543\n",
      "Epoch 96/260\n",
      "5997/5997 [==============================] - 1s 191us/step - loss: 0.1223 - acc: 0.5161 - val_loss: 0.1611 - val_acc: 0.3546\n",
      "Epoch 97/260\n",
      "5997/5997 [==============================] - 1s 195us/step - loss: 0.1225 - acc: 0.5181 - val_loss: 0.1635 - val_acc: 0.3369\n",
      "Epoch 98/260\n",
      "5997/5997 [==============================] - 1s 184us/step - loss: 0.1223 - acc: 0.5226 - val_loss: 0.1625 - val_acc: 0.3483\n",
      "Epoch 99/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1217 - acc: 0.5199 - val_loss: 0.1680 - val_acc: 0.3476\n",
      "Epoch 100/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1224 - acc: 0.5249 - val_loss: 0.1650 - val_acc: 0.3437\n",
      "Epoch 101/260\n",
      "5997/5997 [==============================] - 1s 184us/step - loss: 0.1213 - acc: 0.5278 - val_loss: 0.1670 - val_acc: 0.3329\n",
      "Epoch 102/260\n",
      "5997/5997 [==============================] - 1s 180us/step - loss: 0.1212 - acc: 0.5306 - val_loss: 0.1668 - val_acc: 0.3348\n",
      "Epoch 103/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1216 - acc: 0.5266 - val_loss: 0.1616 - val_acc: 0.3396\n",
      "Epoch 104/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1212 - acc: 0.5261 - val_loss: 0.1645 - val_acc: 0.3361\n",
      "Epoch 105/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1215 - acc: 0.5321 - val_loss: 0.1643 - val_acc: 0.3434\n",
      "Epoch 106/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1208 - acc: 0.5251 - val_loss: 0.1665 - val_acc: 0.3458\n",
      "Epoch 107/260\n",
      "5997/5997 [==============================] - 1s 180us/step - loss: 0.1201 - acc: 0.5296 - val_loss: 0.1633 - val_acc: 0.3320\n",
      "Epoch 108/260\n",
      "5997/5997 [==============================] - 1s 185us/step - loss: 0.1209 - acc: 0.5299 - val_loss: 0.1687 - val_acc: 0.3436\n",
      "Epoch 109/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1202 - acc: 0.5319 - val_loss: 0.1667 - val_acc: 0.3489\n",
      "Epoch 110/260\n",
      "5997/5997 [==============================] - 1s 185us/step - loss: 0.1201 - acc: 0.5354 - val_loss: 0.1663 - val_acc: 0.3439\n",
      "Epoch 111/260\n",
      "5997/5997 [==============================] - 1s 182us/step - loss: 0.1200 - acc: 0.5304 - val_loss: 0.1664 - val_acc: 0.3318\n",
      "Epoch 112/260\n",
      "5997/5997 [==============================] - 1s 187us/step - loss: 0.1203 - acc: 0.5338 - val_loss: 0.1661 - val_acc: 0.3442\n",
      "Epoch 113/260\n",
      "5997/5997 [==============================] - 1s 185us/step - loss: 0.1198 - acc: 0.5341 - val_loss: 0.1661 - val_acc: 0.3436\n",
      "Epoch 114/260\n",
      "5997/5997 [==============================] - 1s 218us/step - loss: 0.1202 - acc: 0.5354 - val_loss: 0.1678 - val_acc: 0.3395\n",
      "Epoch 115/260\n",
      "5997/5997 [==============================] - 1s 203us/step - loss: 0.1201 - acc: 0.5348 - val_loss: 0.1682 - val_acc: 0.3433\n",
      "Epoch 116/260\n",
      "5997/5997 [==============================] - 1s 197us/step - loss: 0.1201 - acc: 0.5321 - val_loss: 0.1664 - val_acc: 0.3356\n",
      "Epoch 117/260\n",
      "5997/5997 [==============================] - 1s 193us/step - loss: 0.1187 - acc: 0.5381 - val_loss: 0.1685 - val_acc: 0.3433\n",
      "Epoch 118/260\n",
      "5997/5997 [==============================] - 1s 184us/step - loss: 0.1190 - acc: 0.5406 - val_loss: 0.1659 - val_acc: 0.3265\n",
      "Epoch 119/260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 1s 202us/step - loss: 0.1195 - acc: 0.5426 - val_loss: 0.1680 - val_acc: 0.3465\n",
      "Epoch 120/260\n",
      "5997/5997 [==============================] - 1s 204us/step - loss: 0.1190 - acc: 0.5438 - val_loss: 0.1696 - val_acc: 0.3415\n",
      "Epoch 121/260\n",
      "5997/5997 [==============================] - 1s 191us/step - loss: 0.1193 - acc: 0.5396 - val_loss: 0.1668 - val_acc: 0.3483\n",
      "Epoch 122/260\n",
      "5997/5997 [==============================] - 1s 189us/step - loss: 0.1188 - acc: 0.5426 - val_loss: 0.1671 - val_acc: 0.3486\n",
      "Epoch 123/260\n",
      "5997/5997 [==============================] - 1s 180us/step - loss: 0.1188 - acc: 0.5423 - val_loss: 0.1657 - val_acc: 0.3455\n",
      "Epoch 124/260\n",
      "5997/5997 [==============================] - 1s 179us/step - loss: 0.1184 - acc: 0.5466 - val_loss: 0.1685 - val_acc: 0.3514\n",
      "Epoch 125/260\n",
      "5997/5997 [==============================] - 1s 201us/step - loss: 0.1181 - acc: 0.5399 - val_loss: 0.1705 - val_acc: 0.3306\n",
      "Epoch 126/260\n",
      "5997/5997 [==============================] - 1s 199us/step - loss: 0.1186 - acc: 0.5424 - val_loss: 0.1670 - val_acc: 0.3493\n",
      "Epoch 127/260\n",
      "5997/5997 [==============================] - 1s 200us/step - loss: 0.1186 - acc: 0.5456 - val_loss: 0.1681 - val_acc: 0.3508\n",
      "Epoch 128/260\n",
      "5997/5997 [==============================] - 1s 203us/step - loss: 0.1170 - acc: 0.5538 - val_loss: 0.1739 - val_acc: 0.3345\n",
      "Epoch 129/260\n",
      "5997/5997 [==============================] - 1s 185us/step - loss: 0.1177 - acc: 0.5499 - val_loss: 0.1671 - val_acc: 0.3446\n",
      "Epoch 130/260\n",
      "5997/5997 [==============================] - 1s 184us/step - loss: 0.1180 - acc: 0.5454 - val_loss: 0.1680 - val_acc: 0.3407\n",
      "Epoch 131/260\n",
      "5997/5997 [==============================] - 1s 198us/step - loss: 0.1183 - acc: 0.5434 - val_loss: 0.1675 - val_acc: 0.3377\n",
      "Epoch 132/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1174 - acc: 0.5456 - val_loss: 0.1685 - val_acc: 0.3412\n",
      "Epoch 133/260\n",
      "5997/5997 [==============================] - 1s 197us/step - loss: 0.1175 - acc: 0.5478 - val_loss: 0.1704 - val_acc: 0.3513\n",
      "Epoch 134/260\n",
      "5997/5997 [==============================] - 1s 192us/step - loss: 0.1176 - acc: 0.5523 - val_loss: 0.1706 - val_acc: 0.3467\n",
      "Epoch 135/260\n",
      "5997/5997 [==============================] - 1s 198us/step - loss: 0.1177 - acc: 0.5398 - val_loss: 0.1714 - val_acc: 0.3502\n",
      "Epoch 136/260\n",
      "5997/5997 [==============================] - 1s 203us/step - loss: 0.1173 - acc: 0.5509 - val_loss: 0.1659 - val_acc: 0.3423\n",
      "Epoch 137/260\n",
      "5997/5997 [==============================] - 1s 194us/step - loss: 0.1172 - acc: 0.5451 - val_loss: 0.1689 - val_acc: 0.3478\n",
      "Epoch 138/260\n",
      "5997/5997 [==============================] - 1s 190us/step - loss: 0.1172 - acc: 0.5488 - val_loss: 0.1661 - val_acc: 0.3385\n",
      "Epoch 139/260\n",
      "5997/5997 [==============================] - 1s 186us/step - loss: 0.1174 - acc: 0.5506 - val_loss: 0.1705 - val_acc: 0.3405\n",
      "Epoch 140/260\n",
      "5997/5997 [==============================] - 1s 186us/step - loss: 0.1172 - acc: 0.5533 - val_loss: 0.1701 - val_acc: 0.3449\n",
      "Epoch 141/260\n",
      "5997/5997 [==============================] - 1s 196us/step - loss: 0.1168 - acc: 0.5569 - val_loss: 0.1745 - val_acc: 0.3429\n",
      "Epoch 142/260\n",
      "5997/5997 [==============================] - 1s 190us/step - loss: 0.1165 - acc: 0.5533 - val_loss: 0.1731 - val_acc: 0.3440\n",
      "Epoch 143/260\n",
      "5997/5997 [==============================] - 1s 193us/step - loss: 0.1166 - acc: 0.5534 - val_loss: 0.1734 - val_acc: 0.3315\n",
      "Epoch 144/260\n",
      "5997/5997 [==============================] - 1s 206us/step - loss: 0.1163 - acc: 0.5554 - val_loss: 0.1709 - val_acc: 0.3442\n",
      "Epoch 145/260\n",
      "5997/5997 [==============================] - 1s 186us/step - loss: 0.1163 - acc: 0.5573 - val_loss: 0.1751 - val_acc: 0.3315\n",
      "Epoch 146/260\n",
      "5997/5997 [==============================] - 1s 198us/step - loss: 0.1169 - acc: 0.5549 - val_loss: 0.1756 - val_acc: 0.3375\n",
      "Epoch 147/260\n",
      "5997/5997 [==============================] - 1s 205us/step - loss: 0.1164 - acc: 0.5514 - val_loss: 0.1727 - val_acc: 0.3366\n",
      "Epoch 148/260\n",
      "5997/5997 [==============================] - 1s 204us/step - loss: 0.1163 - acc: 0.5526 - val_loss: 0.1684 - val_acc: 0.3487\n",
      "Epoch 149/260\n",
      "5997/5997 [==============================] - 1s 233us/step - loss: 0.1157 - acc: 0.5566 - val_loss: 0.1763 - val_acc: 0.3483\n",
      "Epoch 150/260\n",
      "5997/5997 [==============================] - 1s 195us/step - loss: 0.1158 - acc: 0.5558 - val_loss: 0.1731 - val_acc: 0.3337\n",
      "Epoch 151/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1167 - acc: 0.5484 - val_loss: 0.1741 - val_acc: 0.3358\n",
      "Epoch 152/260\n",
      "5997/5997 [==============================] - 1s 185us/step - loss: 0.1161 - acc: 0.5566 - val_loss: 0.1774 - val_acc: 0.3384\n",
      "Epoch 153/260\n",
      "5997/5997 [==============================] - 1s 197us/step - loss: 0.1163 - acc: 0.5566 - val_loss: 0.1761 - val_acc: 0.3414\n",
      "Epoch 154/260\n",
      "5997/5997 [==============================] - 1s 232us/step - loss: 0.1161 - acc: 0.5621 - val_loss: 0.1706 - val_acc: 0.3449\n",
      "Epoch 155/260\n",
      "5997/5997 [==============================] - 1s 187us/step - loss: 0.1157 - acc: 0.5618 - val_loss: 0.1757 - val_acc: 0.3306\n",
      "Epoch 156/260\n",
      "5997/5997 [==============================] - 1s 190us/step - loss: 0.1152 - acc: 0.5514 - val_loss: 0.1711 - val_acc: 0.3488\n",
      "Epoch 157/260\n",
      "5997/5997 [==============================] - 1s 195us/step - loss: 0.1157 - acc: 0.5598 - val_loss: 0.1707 - val_acc: 0.3463\n",
      "Epoch 158/260\n",
      "5997/5997 [==============================] - 1s 194us/step - loss: 0.1151 - acc: 0.5614 - val_loss: 0.1716 - val_acc: 0.3398\n",
      "Epoch 159/260\n",
      "5997/5997 [==============================] - 1s 174us/step - loss: 0.1149 - acc: 0.5581 - val_loss: 0.1776 - val_acc: 0.3219\n",
      "Epoch 160/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1141 - acc: 0.5654 - val_loss: 0.1712 - val_acc: 0.3442\n",
      "Epoch 161/260\n",
      "5997/5997 [==============================] - 1s 168us/step - loss: 0.1151 - acc: 0.5656 - val_loss: 0.1726 - val_acc: 0.3448\n",
      "Epoch 162/260\n",
      "5997/5997 [==============================] - 1s 168us/step - loss: 0.1148 - acc: 0.5624 - val_loss: 0.1714 - val_acc: 0.3504\n",
      "Epoch 163/260\n",
      "5997/5997 [==============================] - 1s 175us/step - loss: 0.1146 - acc: 0.5614 - val_loss: 0.1750 - val_acc: 0.3442\n",
      "Epoch 164/260\n",
      "5997/5997 [==============================] - 1s 161us/step - loss: 0.1145 - acc: 0.5638 - val_loss: 0.1719 - val_acc: 0.3410\n",
      "Epoch 165/260\n",
      "5997/5997 [==============================] - 1s 170us/step - loss: 0.1148 - acc: 0.5653 - val_loss: 0.1752 - val_acc: 0.3497\n",
      "Epoch 166/260\n",
      "5997/5997 [==============================] - 1s 163us/step - loss: 0.1141 - acc: 0.5664 - val_loss: 0.1832 - val_acc: 0.3299\n",
      "Epoch 167/260\n",
      "5997/5997 [==============================] - 1s 163us/step - loss: 0.1142 - acc: 0.5705 - val_loss: 0.1745 - val_acc: 0.3476\n",
      "Epoch 168/260\n",
      "5997/5997 [==============================] - 1s 174us/step - loss: 0.1147 - acc: 0.5593 - val_loss: 0.1749 - val_acc: 0.3419\n",
      "Epoch 169/260\n",
      "5997/5997 [==============================] - 1s 168us/step - loss: 0.1150 - acc: 0.5568 - val_loss: 0.1733 - val_acc: 0.3357\n",
      "Epoch 170/260\n",
      "5997/5997 [==============================] - 1s 199us/step - loss: 0.1146 - acc: 0.5601 - val_loss: 0.1729 - val_acc: 0.3449\n",
      "Epoch 171/260\n",
      "5997/5997 [==============================] - 1s 195us/step - loss: 0.1139 - acc: 0.5654 - val_loss: 0.1717 - val_acc: 0.3463\n",
      "Epoch 172/260\n",
      "5997/5997 [==============================] - 1s 174us/step - loss: 0.1138 - acc: 0.5651 - val_loss: 0.1743 - val_acc: 0.3457\n",
      "Epoch 173/260\n",
      "5997/5997 [==============================] - 1s 168us/step - loss: 0.1139 - acc: 0.5676 - val_loss: 0.1764 - val_acc: 0.3415\n",
      "Epoch 174/260\n",
      "5997/5997 [==============================] - 1s 164us/step - loss: 0.1149 - acc: 0.5711 - val_loss: 0.1747 - val_acc: 0.3428\n",
      "Epoch 175/260\n",
      "5997/5997 [==============================] - 1s 162us/step - loss: 0.1142 - acc: 0.5721 - val_loss: 0.1749 - val_acc: 0.3502\n",
      "Epoch 176/260\n",
      "5997/5997 [==============================] - 1s 170us/step - loss: 0.1138 - acc: 0.5683 - val_loss: 0.1788 - val_acc: 0.3409\n",
      "Epoch 177/260\n",
      "5997/5997 [==============================] - 1s 187us/step - loss: 0.1134 - acc: 0.5743 - val_loss: 0.1787 - val_acc: 0.3428\n",
      "Epoch 178/260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 1s 172us/step - loss: 0.1148 - acc: 0.5686 - val_loss: 0.1840 - val_acc: 0.3266\n",
      "Epoch 179/260\n",
      "5997/5997 [==============================] - 1s 181us/step - loss: 0.1142 - acc: 0.5629 - val_loss: 0.1755 - val_acc: 0.3351\n",
      "Epoch 180/260\n",
      "5997/5997 [==============================] - 1s 190us/step - loss: 0.1132 - acc: 0.5708 - val_loss: 0.1806 - val_acc: 0.3409\n",
      "Epoch 181/260\n",
      "5997/5997 [==============================] - 1s 192us/step - loss: 0.1133 - acc: 0.5738 - val_loss: 0.1785 - val_acc: 0.3434\n",
      "Epoch 182/260\n",
      "5997/5997 [==============================] - 1s 197us/step - loss: 0.1129 - acc: 0.5705 - val_loss: 0.1801 - val_acc: 0.3430\n",
      "Epoch 183/260\n",
      "5997/5997 [==============================] - 1s 200us/step - loss: 0.1137 - acc: 0.5691 - val_loss: 0.1758 - val_acc: 0.3540\n",
      "Epoch 184/260\n",
      "5997/5997 [==============================] - 1s 204us/step - loss: 0.1142 - acc: 0.5634 - val_loss: 0.1799 - val_acc: 0.3457\n",
      "Epoch 185/260\n",
      "5997/5997 [==============================] - 1s 185us/step - loss: 0.1134 - acc: 0.5690 - val_loss: 0.1735 - val_acc: 0.3442\n",
      "Epoch 186/260\n",
      "5997/5997 [==============================] - 1s 201us/step - loss: 0.1132 - acc: 0.5701 - val_loss: 0.1796 - val_acc: 0.3420\n",
      "Epoch 187/260\n",
      "5997/5997 [==============================] - 1s 188us/step - loss: 0.1135 - acc: 0.5705 - val_loss: 0.1805 - val_acc: 0.3299\n",
      "Epoch 188/260\n",
      "5997/5997 [==============================] - 1s 187us/step - loss: 0.1133 - acc: 0.5725 - val_loss: 0.1768 - val_acc: 0.3344\n",
      "Epoch 189/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1125 - acc: 0.5783 - val_loss: 0.1790 - val_acc: 0.3462\n",
      "Epoch 190/260\n",
      "5997/5997 [==============================] - 1s 188us/step - loss: 0.1126 - acc: 0.5730 - val_loss: 0.1719 - val_acc: 0.3480\n",
      "Epoch 191/260\n",
      "5997/5997 [==============================] - 1s 189us/step - loss: 0.1128 - acc: 0.5690 - val_loss: 0.1785 - val_acc: 0.3395\n",
      "Epoch 192/260\n",
      "5997/5997 [==============================] - 1s 187us/step - loss: 0.1124 - acc: 0.5740 - val_loss: 0.1772 - val_acc: 0.3489\n",
      "Epoch 193/260\n",
      "5997/5997 [==============================] - 1s 210us/step - loss: 0.1128 - acc: 0.5761 - val_loss: 0.1768 - val_acc: 0.3346\n",
      "Epoch 194/260\n",
      "5997/5997 [==============================] - 1s 204us/step - loss: 0.1130 - acc: 0.5781 - val_loss: 0.1797 - val_acc: 0.3366\n",
      "Epoch 195/260\n",
      "5997/5997 [==============================] - 1s 218us/step - loss: 0.1132 - acc: 0.5745 - val_loss: 0.1805 - val_acc: 0.3285\n",
      "Epoch 196/260\n",
      "5997/5997 [==============================] - 1s 208us/step - loss: 0.1126 - acc: 0.5733 - val_loss: 0.1888 - val_acc: 0.3319\n",
      "Epoch 197/260\n",
      "5997/5997 [==============================] - 1s 213us/step - loss: 0.1129 - acc: 0.5753 - val_loss: 0.1819 - val_acc: 0.3281\n",
      "Epoch 198/260\n",
      "5997/5997 [==============================] - 1s 207us/step - loss: 0.1135 - acc: 0.5766 - val_loss: 0.1800 - val_acc: 0.3361\n",
      "Epoch 199/260\n",
      "5997/5997 [==============================] - 1s 184us/step - loss: 0.1125 - acc: 0.5786 - val_loss: 0.1783 - val_acc: 0.3510\n",
      "Epoch 200/260\n",
      "5997/5997 [==============================] - 1s 199us/step - loss: 0.1122 - acc: 0.5816 - val_loss: 0.1810 - val_acc: 0.3354\n",
      "Epoch 201/260\n",
      "5997/5997 [==============================] - 1s 192us/step - loss: 0.1130 - acc: 0.5755 - val_loss: 0.1741 - val_acc: 0.3458\n",
      "Epoch 202/260\n",
      "5997/5997 [==============================] - 1s 198us/step - loss: 0.1126 - acc: 0.5753 - val_loss: 0.1750 - val_acc: 0.3444\n",
      "Epoch 203/260\n",
      "5997/5997 [==============================] - 1s 200us/step - loss: 0.1122 - acc: 0.5771 - val_loss: 0.1752 - val_acc: 0.3386\n",
      "Epoch 204/260\n",
      "5997/5997 [==============================] - 1s 194us/step - loss: 0.1122 - acc: 0.5758 - val_loss: 0.1763 - val_acc: 0.3425\n",
      "Epoch 205/260\n",
      "5997/5997 [==============================] - 1s 209us/step - loss: 0.1128 - acc: 0.5815 - val_loss: 0.1748 - val_acc: 0.3436\n",
      "Epoch 206/260\n",
      "5997/5997 [==============================] - 1s 197us/step - loss: 0.1115 - acc: 0.5848 - val_loss: 0.1812 - val_acc: 0.3402\n",
      "Epoch 207/260\n",
      "5997/5997 [==============================] - 1s 192us/step - loss: 0.1128 - acc: 0.5733 - val_loss: 0.1798 - val_acc: 0.3425\n",
      "Epoch 208/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1120 - acc: 0.5751 - val_loss: 0.1809 - val_acc: 0.3361\n",
      "Epoch 209/260\n",
      "5997/5997 [==============================] - 1s 194us/step - loss: 0.1128 - acc: 0.5771 - val_loss: 0.1764 - val_acc: 0.3399\n",
      "Epoch 210/260\n",
      "5997/5997 [==============================] - 1s 221us/step - loss: 0.1119 - acc: 0.5786 - val_loss: 0.1853 - val_acc: 0.3336\n",
      "Epoch 211/260\n",
      "5997/5997 [==============================] - 1s 199us/step - loss: 0.1122 - acc: 0.5730 - val_loss: 0.1746 - val_acc: 0.3435\n",
      "Epoch 212/260\n",
      "5997/5997 [==============================] - 1s 189us/step - loss: 0.1127 - acc: 0.5730 - val_loss: 0.1802 - val_acc: 0.3402\n",
      "Epoch 213/260\n",
      "5997/5997 [==============================] - 1s 192us/step - loss: 0.1121 - acc: 0.5788 - val_loss: 0.1798 - val_acc: 0.3358\n",
      "Epoch 214/260\n",
      "5997/5997 [==============================] - 1s 195us/step - loss: 0.1127 - acc: 0.5795 - val_loss: 0.1743 - val_acc: 0.3477\n",
      "Epoch 215/260\n",
      "5997/5997 [==============================] - 1s 217us/step - loss: 0.1126 - acc: 0.5743 - val_loss: 0.1776 - val_acc: 0.3434\n",
      "Epoch 216/260\n",
      "5997/5997 [==============================] - 1s 205us/step - loss: 0.1131 - acc: 0.5720 - val_loss: 0.1748 - val_acc: 0.3489\n",
      "Epoch 217/260\n",
      "5997/5997 [==============================] - 1s 205us/step - loss: 0.1122 - acc: 0.5805 - val_loss: 0.1771 - val_acc: 0.3377\n",
      "Epoch 218/260\n",
      "5997/5997 [==============================] - 1s 217us/step - loss: 0.1125 - acc: 0.5771 - val_loss: 0.1722 - val_acc: 0.3438\n",
      "Epoch 219/260\n",
      "5997/5997 [==============================] - 1s 175us/step - loss: 0.1122 - acc: 0.5815 - val_loss: 0.1776 - val_acc: 0.3503\n",
      "Epoch 220/260\n",
      "5997/5997 [==============================] - 1s 176us/step - loss: 0.1124 - acc: 0.5750 - val_loss: 0.1830 - val_acc: 0.3408\n",
      "Epoch 221/260\n",
      "5997/5997 [==============================] - 1s 189us/step - loss: 0.1119 - acc: 0.5831 - val_loss: 0.1815 - val_acc: 0.3412\n",
      "Epoch 222/260\n",
      "5997/5997 [==============================] - 1s 215us/step - loss: 0.1125 - acc: 0.5781 - val_loss: 0.1803 - val_acc: 0.3465\n",
      "Epoch 223/260\n",
      "5997/5997 [==============================] - 1s 199us/step - loss: 0.1116 - acc: 0.5791 - val_loss: 0.1819 - val_acc: 0.3490\n",
      "Epoch 224/260\n",
      "5997/5997 [==============================] - 1s 188us/step - loss: 0.1108 - acc: 0.5846 - val_loss: 0.1777 - val_acc: 0.3475\n",
      "Epoch 225/260\n",
      "5997/5997 [==============================] - 1s 198us/step - loss: 0.1116 - acc: 0.5765 - val_loss: 0.1822 - val_acc: 0.3286\n",
      "Epoch 226/260\n",
      "5997/5997 [==============================] - 1s 187us/step - loss: 0.1119 - acc: 0.5778 - val_loss: 0.1806 - val_acc: 0.3371\n",
      "Epoch 227/260\n",
      "5997/5997 [==============================] - 1s 180us/step - loss: 0.1109 - acc: 0.5865 - val_loss: 0.1776 - val_acc: 0.3542\n",
      "Epoch 228/260\n",
      "5997/5997 [==============================] - 1s 195us/step - loss: 0.1110 - acc: 0.5800 - val_loss: 0.1771 - val_acc: 0.3509\n",
      "Epoch 229/260\n",
      "5997/5997 [==============================] - 1s 190us/step - loss: 0.1105 - acc: 0.5836 - val_loss: 0.1780 - val_acc: 0.3402\n",
      "Epoch 230/260\n",
      "5997/5997 [==============================] - 1s 198us/step - loss: 0.1121 - acc: 0.5786 - val_loss: 0.1823 - val_acc: 0.3437\n",
      "Epoch 231/260\n",
      "5997/5997 [==============================] - 1s 194us/step - loss: 0.1110 - acc: 0.5836 - val_loss: 0.1779 - val_acc: 0.3518\n",
      "Epoch 232/260\n",
      "5997/5997 [==============================] - 1s 203us/step - loss: 0.1114 - acc: 0.5793 - val_loss: 0.1772 - val_acc: 0.3435\n",
      "Epoch 233/260\n",
      "5997/5997 [==============================] - 1s 191us/step - loss: 0.1104 - acc: 0.5820 - val_loss: 0.1796 - val_acc: 0.3369\n",
      "Epoch 234/260\n",
      "5997/5997 [==============================] - 1s 232us/step - loss: 0.1118 - acc: 0.5803 - val_loss: 0.1782 - val_acc: 0.3415\n",
      "Epoch 235/260\n",
      "5997/5997 [==============================] - 1s 224us/step - loss: 0.1106 - acc: 0.5880 - val_loss: 0.1820 - val_acc: 0.3365\n",
      "Epoch 236/260\n",
      "5997/5997 [==============================] - 1s 220us/step - loss: 0.1109 - acc: 0.5876 - val_loss: 0.1838 - val_acc: 0.3420\n",
      "Epoch 237/260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 1s 210us/step - loss: 0.1106 - acc: 0.5816 - val_loss: 0.1844 - val_acc: 0.3507\n",
      "Epoch 238/260\n",
      "5997/5997 [==============================] - 1s 193us/step - loss: 0.1112 - acc: 0.5786 - val_loss: 0.1777 - val_acc: 0.3428\n",
      "Epoch 239/260\n",
      "5997/5997 [==============================] - 1s 185us/step - loss: 0.1123 - acc: 0.5805 - val_loss: 0.1752 - val_acc: 0.3566\n",
      "Epoch 240/260\n",
      "5997/5997 [==============================] - 1s 189us/step - loss: 0.1120 - acc: 0.5743 - val_loss: 0.1771 - val_acc: 0.3470\n",
      "Epoch 241/260\n",
      "5997/5997 [==============================] - 1s 189us/step - loss: 0.1111 - acc: 0.5883 - val_loss: 0.1815 - val_acc: 0.3415\n",
      "Epoch 242/260\n",
      "5997/5997 [==============================] - 1s 194us/step - loss: 0.1104 - acc: 0.5835 - val_loss: 0.1733 - val_acc: 0.3427\n",
      "Epoch 243/260\n",
      "5997/5997 [==============================] - 1s 199us/step - loss: 0.1115 - acc: 0.5820 - val_loss: 0.1795 - val_acc: 0.3487\n",
      "Epoch 244/260\n",
      "5997/5997 [==============================] - 1s 187us/step - loss: 0.1099 - acc: 0.5913 - val_loss: 0.1758 - val_acc: 0.3475\n",
      "Epoch 245/260\n",
      "5997/5997 [==============================] - 1s 194us/step - loss: 0.1106 - acc: 0.5868 - val_loss: 0.1835 - val_acc: 0.3246\n",
      "Epoch 246/260\n",
      "5997/5997 [==============================] - 1s 192us/step - loss: 0.1119 - acc: 0.5873 - val_loss: 0.1821 - val_acc: 0.3350\n",
      "Epoch 247/260\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 0.1103 - acc: 0.5905 - val_loss: 0.1788 - val_acc: 0.3465\n",
      "Epoch 248/260\n",
      "5997/5997 [==============================] - 1s 197us/step - loss: 0.1101 - acc: 0.5851 - val_loss: 0.1822 - val_acc: 0.3452\n",
      "Epoch 249/260\n",
      "5997/5997 [==============================] - 1s 187us/step - loss: 0.1115 - acc: 0.5878 - val_loss: 0.1776 - val_acc: 0.3468\n",
      "Epoch 250/260\n",
      "5997/5997 [==============================] - 1s 194us/step - loss: 0.1116 - acc: 0.5856 - val_loss: 0.1794 - val_acc: 0.3367\n",
      "Epoch 251/260\n",
      "5997/5997 [==============================] - 1s 189us/step - loss: 0.1123 - acc: 0.5831 - val_loss: 0.1797 - val_acc: 0.3482\n",
      "Epoch 252/260\n",
      "5997/5997 [==============================] - 1s 197us/step - loss: 0.1113 - acc: 0.5775 - val_loss: 0.1825 - val_acc: 0.3432\n",
      "Epoch 253/260\n",
      "5997/5997 [==============================] - 1s 188us/step - loss: 0.1106 - acc: 0.5833 - val_loss: 0.1794 - val_acc: 0.3460\n",
      "Epoch 254/260\n",
      "5997/5997 [==============================] - 1s 191us/step - loss: 0.1107 - acc: 0.5865 - val_loss: 0.1779 - val_acc: 0.3455\n",
      "Epoch 255/260\n",
      "5997/5997 [==============================] - 1s 198us/step - loss: 0.1110 - acc: 0.5881 - val_loss: 0.1759 - val_acc: 0.3455\n",
      "Epoch 256/260\n",
      "5997/5997 [==============================] - 1s 189us/step - loss: 0.1107 - acc: 0.5881 - val_loss: 0.1833 - val_acc: 0.3436\n",
      "Epoch 257/260\n",
      "5997/5997 [==============================] - 1s 187us/step - loss: 0.1109 - acc: 0.5871 - val_loss: 0.1828 - val_acc: 0.3321\n",
      "Epoch 258/260\n",
      "5997/5997 [==============================] - 1s 176us/step - loss: 0.1107 - acc: 0.5911 - val_loss: 0.1796 - val_acc: 0.3456\n",
      "Epoch 259/260\n",
      "5997/5997 [==============================] - 1s 191us/step - loss: 0.1112 - acc: 0.5868 - val_loss: 0.1817 - val_acc: 0.3483\n",
      "Epoch 260/260\n",
      "5997/5997 [==============================] - 1s 186us/step - loss: 0.1105 - acc: 0.5875 - val_loss: 0.1784 - val_acc: 0.3465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152835dd8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.hstack([trainContinuous])\n",
    "x_valid = np.hstack([trainContinuous2])\n",
    "x_test = np.hstack([trainContinuous3])\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=18),\n",
    "    Activation('relu'),\n",
    "    Dense(32),\n",
    "    Activation('relu'),\n",
    "    Dense(32),\n",
    "    Activation('relu'),\n",
    "    Dense(16),\n",
    "    Activation('relu'),\n",
    "    Dense(5),\n",
    "    Activation('sigmoid'),\n",
    "])\n",
    "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "# We add metrics to get more results you want to see\n",
    "#categorical_crossentropy--mse\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,validation_data = (x_valid,y_valid),epochs=260, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "067149907a4df1bb157b07fbcd4d9d69fb65f3fa"
   },
   "outputs": [],
   "source": [
    "# print('\\nTesting ------------')\n",
    "# # Evaluate the model with the metrics we defined earlier\n",
    "# loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "# print('test loss: ', loss)\n",
    "# print('test accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "af4f6d90a3808b86ed1a4fc0b5bd23bfb7f60196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.00784314 1.         ... 0.84615385 0.         0.06666667]\n",
      " [1.         0.         0.86644951 ... 0.13186813 0.         0.06666667]\n",
      " [1.         0.02352941 0.86319218 ... 0.84615385 0.         0.16666667]\n",
      " ...\n",
      " [1.         0.02352941 0.86644951 ... 0.84615385 0.         0.13333333]\n",
      " [1.         0.00784314 0.96742671 ... 0.02197802 0.         0.16666667]\n",
      " [1.         0.00784314 0.85993485 ... 0.84615385 0.125      0.16666667]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1019193b82f8cc31c77a8630e40013297cc68b10"
   },
   "outputs": [],
   "source": [
    "#y_pred2 = np.argmax(y_pred,axis = 1)\n",
    "#y_pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f508f56d4cab23c936752a1033028117e5a4b08c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "079cf918082ebbeec3902493f0055a9a3633912c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "253e65605d45da4db28f84363edeb98fb54431fb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3bf89d25aa58d21dc41ec03abdb05150d05e9ab"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
