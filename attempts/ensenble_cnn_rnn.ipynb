{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Reshape\n",
    "from keras.layers import Embedding, Dropout, LSTM, Bidirectional, Concatenate, Input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "batch_size = 16\n",
    "VALIDATION_SPLIT = 0.5\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "#Sett=1\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "#Measure of success\n",
    "def kappa(y_true, y_pred):\n",
    "    y_true = np.argmax(y_true, axis = 1)\n",
    "    y_pred = np.argmax(y_pred, axis = 1)\n",
    "    \n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    # Apply binning to ages\n",
    "    data['Age'] = pd.cut(data['Age'], [-1, 2, 3, 6, 255], labels=[0, 1, 2, 3])\n",
    "\n",
    "    # Apply binning to fee\n",
    "    data['Fee'] = pd.cut(data['Fee'], [-1, 50, 100, 200, 3000], labels=[0, 1, 2, 3])\n",
    "\n",
    "    # Apply binning to photo amount\n",
    "    data['PhotoAmt'] = pd.cut(data['PhotoAmt'], [-1, 1, 5, 10, 100], labels=[0, 1, 2, 3])\n",
    "\n",
    "    # Apply binning to video amount\n",
    "    data['VideoAmt'] = pd.cut(data['VideoAmt'], [-1, 1, 100], labels=[0, 1])\n",
    "\n",
    "    # Replace names with 1 is present, 0 if not present\n",
    "    data.loc[data['Name'].notnull(), 'Name'] = 1\n",
    "    data.loc[data['Name'].isnull(), 'Name'] = 0\n",
    "\n",
    "    # Fill missing continuous data\n",
    "    data_continuous = data.select_dtypes(exclude=['object'])\n",
    "    data_continuous.fillna(0, inplace=True)\n",
    "\n",
    "    # Fill missing string data\n",
    "    data_categorical = data.select_dtypes(include=['object'])\n",
    "    data_categorical.fillna('NONE', inplace=True)\n",
    "\n",
    "    return data_continuous.merge(data_categorical, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/viteka/final_project/venv/lib/python3.6/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "breeds = pd.read_csv('../all/breed_labels.csv')\n",
    "colors = pd.read_csv('../all/color_labels.csv')\n",
    "states = pd.read_csv('../all/state_labels.csv')\n",
    "train = prepare_data(pd.read_csv('../all/train.csv'))\n",
    "test = prepare_data(pd.read_csv('../all/test/test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_ids = train['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Extract text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(df):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = df['Description']\n",
    "    string = re.sub(r\"\\\\\", \"\", string)    \n",
    "    string = re.sub(r\"\\\"\", \"\", string)\n",
    "    string = re.sub(\"<a.*?</a>\", \"\", string) #remobe <a> href tag\n",
    "    return string.strip().lower()\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Preparing text and labels\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    \n",
    "    for idx in range(text.shape[0]):\n",
    "        text = df.Text[idx]\n",
    "        texts.append(clean_str(text))\n",
    "    \n",
    "    return texts\n",
    "\n",
    "def tokenization(texts,dataset= \"full_data\", maxlen=MAX_SEQUENCE_LENGTH,num_words=MAX_NB_WORDS):\n",
    "    ### tokenizing and creating word_index dictionary - Map each word to and index in vocabulary dictionary\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts) #only keep top 20000\n",
    "\n",
    "    word_index = tokenizer.word_index # all unique word index!\n",
    "    print('Found {} unique tokens in {}.'.format(len(word_index),dataset))\n",
    "\n",
    "    data2 = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH) #pad all sequences to be size 1000\n",
    "    \n",
    "    return sequences, word_index, data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Description'] = train.apply(clean_str, axis = 1)\n",
    "test['Description'] = test.apply(clean_str, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21810 unique tokens in full_data.\n",
      "Found 11547 unique tokens in full_data.\n"
     ]
    }
   ],
   "source": [
    "seq , word_index , full_data = tokenization(train.Description)\n",
    "test_seq , test_word_index , test_full_data = tokenization(test.Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(dic, word_embed):\n",
    "    embedin_matrix = np.random.random((len(dic) + 1 , EMBEDDING_DIM))\n",
    "    for word, ind in dic.items():\n",
    "        embedding_vector = word_embed.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedin_matrix[ind] = embedding_vector ### word not found in glove will be initialized randomly\n",
    "    \n",
    "    return embedin_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "GLOVE_DIR = \"../all/data/glove\"\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "em_mat = create_embedding(word_index, embeddings_index)\n",
    "#test_em_mat = create_embedding(test_word_index, embeddings_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the keras embedding layer which we will use for all our experiments\n",
    "embedding_layer = Embedding(len(em_mat),\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[em_mat],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 256 image features for each pet\n",
    "\n",
    "Don't need to run the model now. Directly load the csv features. Later, we could use a different pre-trained model or even re-train few layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resize_to_square(im):\n",
    "#     old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "#     ratio = float(img_size)/max(old_size)\n",
    "#     new_size = tuple([int(x*ratio) for x in old_size])\n",
    "#     # new_size should be in (width, height) format\n",
    "#     im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "#     delta_w = img_size - new_size[1]\n",
    "#     delta_h = img_size - new_size[0]\n",
    "#     top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "#     left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "#     color = [0, 0, 0]\n",
    "#     new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "#     return new_im\n",
    "\n",
    "# def load_image(path, pet_id):\n",
    "#     image = cv2.imread(f'{path}{pet_id}-1.jpg')\n",
    "#     new_image = resize_to_square(image)\n",
    "#     new_image = preprocess_input(new_image)\n",
    "#     return new_image\n",
    "\n",
    "# inp = Input((256,256,3))\n",
    "# backbone = DenseNet121(input_tensor = inp, include_top = False)\n",
    "# x = backbone.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
    "# x = AveragePooling1D(4)(x)\n",
    "# out = Lambda(lambda x: x[:,:,0])(x)\n",
    "\n",
    "# m = Model(inp,out)\n",
    "\n",
    "# features = {}\n",
    "# for b in (range(n_batches)):\n",
    "#     start = b*batch_size\n",
    "#     end = (b+1)*batch_size\n",
    "#     batch_pets = pet_ids[start:end]\n",
    "#     batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "#     for i,pet_id in enumerate(batch_pets):\n",
    "#         try:\n",
    "#             batch_images[i] = load_image(\"all/train_images/\", pet_id)\n",
    "#         except:\n",
    "#             pass\n",
    "#     batch_preds = m.predict(batch_images)\n",
    "#     for i,pet_id in enumerate(batch_pets):\n",
    "#         features[pet_id] = batch_preds[i]\n",
    "\n",
    "# train_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "\n",
    "# train_feats.to_csv('test_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "# test_feats.to_csv('all/test/test_img_features.csv').csv')\n",
    "\n",
    "# test_df = pd.read_csv('all/test/test.csv')\n",
    "# pet_ids = test_df['PetID'].values\n",
    "# n_batches = len(pet_ids) // batch_size + 1\n",
    "\n",
    "# features = {}\n",
    "# for b in tqdm_notebook(range(n_batches)):\n",
    "#     start = b*batch_size\n",
    "#     end = (b+1)*batch_size\n",
    "#     batch_pets = pet_ids[start:end]\n",
    "#     batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "#     for i,pet_id in enumerate(batch_pets):\n",
    "#         try:\n",
    "#             batch_images[i] = load_image(\"all/test_images/\", pet_id)\n",
    "#         except:\n",
    "#             pass\n",
    "#     batch_preds = m.predict(batch_images)\n",
    "#     for i,pet_id in enumerate(batch_pets):\n",
    "#         features[pet_id] = batch_preds[i]\n",
    "\n",
    "# test_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "# test_feats.to_csv('all/test/test_img_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = pd.read_csv('../all/train_img_features.csv')\n",
    "test_feats = pd.read_csv('../all/test/test_img_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 257)\n",
      "(3948, 257)\n"
     ]
    }
   ],
   "source": [
    "print(train_feats.shape)\n",
    "print(test_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = train_feats.iloc[:, 1:]\n",
    "#train_feats = train_feats.drop(train_feats.columns[1:], axis = 1)\n",
    "#train_feats['Img_data'] = df.apply(lambda x: np.array(x), axis=1)\n",
    "#train_feats['Img_data'] = df.apply(lambda x: x.tolist(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the image features with the categorical and numerical embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787699</td>\n",
       "      <td>0.176625</td>\n",
       "      <td>0.575706</td>\n",
       "      <td>1.088627</td>\n",
       "      <td>0.439557</td>\n",
       "      <td>0.520460</td>\n",
       "      <td>1.547071</td>\n",
       "      <td>0.832572</td>\n",
       "      <td>0.599095</td>\n",
       "      <td>0.763349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628260</td>\n",
       "      <td>0.686865</td>\n",
       "      <td>0.563999</td>\n",
       "      <td>0.968190</td>\n",
       "      <td>1.070276</td>\n",
       "      <td>1.545739</td>\n",
       "      <td>0.894411</td>\n",
       "      <td>0.838595</td>\n",
       "      <td>0.468236</td>\n",
       "      <td>0.916672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579116</td>\n",
       "      <td>0.557624</td>\n",
       "      <td>1.131405</td>\n",
       "      <td>0.720514</td>\n",
       "      <td>1.496672</td>\n",
       "      <td>0.870955</td>\n",
       "      <td>1.289682</td>\n",
       "      <td>1.184461</td>\n",
       "      <td>0.465113</td>\n",
       "      <td>0.892826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295853</td>\n",
       "      <td>0.326143</td>\n",
       "      <td>0.291668</td>\n",
       "      <td>1.608086</td>\n",
       "      <td>1.119176</td>\n",
       "      <td>1.470888</td>\n",
       "      <td>0.591445</td>\n",
       "      <td>0.832753</td>\n",
       "      <td>0.483021</td>\n",
       "      <td>1.134128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.092663</td>\n",
       "      <td>0.669893</td>\n",
       "      <td>0.395784</td>\n",
       "      <td>0.886075</td>\n",
       "      <td>1.219730</td>\n",
       "      <td>1.033964</td>\n",
       "      <td>1.065685</td>\n",
       "      <td>0.304053</td>\n",
       "      <td>0.438069</td>\n",
       "      <td>0.676818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Name Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2     1   1     299       0       1       1       7       0   \n",
       "1     2     1   0     265       0       1       1       2       0   \n",
       "2     1     1   0     307       0       1       2       7       0   \n",
       "3     1     1   2     307       0       2       1       2       0   \n",
       "4     1     1   0     307       0       1       1       0       0   \n",
       "\n",
       "   MaturitySize    ...          246       247       248       249       250  \\\n",
       "0             1    ...     0.787699  0.176625  0.575706  1.088627  0.439557   \n",
       "1             2    ...     0.628260  0.686865  0.563999  0.968190  1.070276   \n",
       "2             2    ...     0.579116  0.557624  1.131405  0.720514  1.496672   \n",
       "3             2    ...     1.295853  0.326143  0.291668  1.608086  1.119176   \n",
       "4             2    ...     1.092663  0.669893  0.395784  0.886075  1.219730   \n",
       "\n",
       "        251       252       253       254       255  \n",
       "0  0.520460  1.547071  0.832572  0.599095  0.763349  \n",
       "1  1.545739  0.894411  0.838595  0.468236  0.916672  \n",
       "2  0.870955  1.289682  1.184461  0.465113  0.892826  \n",
       "3  1.470888  0.591445  0.832753  0.483021  1.134128  \n",
       "4  1.033964  1.065685  0.304053  0.438069  0.676818  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(train_feats, left_on='PetID', right_on='Unnamed: 0', how='outer')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, pd.DataFrame(full_data)], axis=1, sort=False)\n",
    "test = pd.concat([test, pd.DataFrame(test_full_data)], axis=1, sort=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode tabular features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train.AdoptionSpeed\n",
    "#We drop name because it creates a huge embedding vector and we know that name is not very useful anyway\n",
    "train = train.drop(['AdoptionSpeed', 'Name', 'Description', 'PetID', 'Unnamed: 0', 'RescuerID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 1275)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, train_label, test_size=TEST_SPLIT, random_state=9)\n",
    "\n",
    "#Turn labels into n dimensional vectors for loss calculation\n",
    "y_train = to_categorical(y_train, num_classes=None)\n",
    "y_test = to_categorical(y_test, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
    "        'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
    "        'Sterilized', 'Health', 'State']\n",
    "numerical_vars = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(X_train, X_test, embed_cols, num_cols):\n",
    "\n",
    "    input_list_train = []\n",
    "    input_list_test = []\n",
    "    m= MinMaxScaler()\n",
    "        \n",
    "    #the cols to be embedded: rescaling to range [0, # values)\n",
    "    for c in embed_cols:\n",
    "        raw_vals = np.unique(X_train[c])\n",
    "        val_map = {}\n",
    "        for i in range(len(raw_vals)):\n",
    "            val_map[raw_vals[i]] = i       \n",
    "        m.fit(X_train[c].map(val_map).values.reshape(-1, 1))\n",
    "        input_list_train.append(m.transform(X_train[c].map(val_map).values.reshape(-1, 1)))\n",
    "        \n",
    "        m.fit(X_test[c].map(val_map).fillna(0).values.reshape(-1, 1))\n",
    "        input_list_test.append(m.transform(X_test[c].map(val_map).fillna(0).values.reshape(-1, 1)))\n",
    "        \n",
    "    #the numerical columns\n",
    "    m.fit(X_train[num_cols].values)\n",
    "    input_list_train.append(m.transform(X_train[num_cols].values))\n",
    "    \n",
    "    m.fit(X_test[num_cols].values)\n",
    "    input_list_test.append(m.transform(X_test[num_cols].values))\n",
    "    \n",
    "    #img data\n",
    "    input_list_train.append(X_train.iloc[:, 19:275].as_matrix())\n",
    "    input_list_test.append(X_test.iloc[:, 19:275].as_matrix())\n",
    "    \n",
    "    #text data\n",
    "    input_list_train.append(X_train.iloc[:, 275:].as_matrix())\n",
    "    input_list_test.append(X_test.iloc[:, 275:].as_matrix())\n",
    "    \n",
    "    return input_list_train, input_list_test\n",
    "\n",
    "\n",
    "#Creating a Embedding model for categorical variables using the fast.ai approach\n",
    "def createModel(data, categorical_vars, numerical_vars):\n",
    "    embeddings = []\n",
    "    inputs = []\n",
    "    for categorical_var in categorical_vars :\n",
    "        i = Input(shape=(1,))\n",
    "        no_of_unique_cat  = data[categorical_var].nunique()\n",
    "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "        embedding_size = int(embedding_size)\n",
    "        vocab  = no_of_unique_cat+1\n",
    "        embedding = Embedding(vocab ,embedding_size, input_length = 1 )(i)\n",
    "        embedding = Reshape(target_shape=(embedding_size,))(embedding)\n",
    "        embeddings.append( embedding )\n",
    "        inputs.append(i)\n",
    "        \n",
    "    input_numeric = Input(shape=(len(numerical_vars),))\n",
    "    embedding_numeric = Dense(16)(input_numeric) \n",
    "    \n",
    "    \n",
    "    inputs.append(input_numeric)\n",
    "    embeddings.append(embedding_numeric)\n",
    "    \n",
    "    x = Concatenate()(embeddings)\n",
    "    x = Dense(40, activation='relu')(x)\n",
    "    x = Dropout(.25)(x)\n",
    "    \n",
    "    #hardcoded for now\n",
    "    image_input = Input(shape=(256,))\n",
    "    inputs.append(image_input)\n",
    "    \n",
    "    y = Dense(80, activation='relu')(image_input)    \n",
    "    y = Dense(40, activation='relu')(y)\n",
    "    y = Dropout(.25)(y)\n",
    "    \n",
    "    #Words\n",
    "    w = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    inputs.append(w)\n",
    "    w = embedding_layer(w)\n",
    "    w = Bidirectional(LSTM(40, recurrent_dropout=0.3))(w)\n",
    "    \n",
    "    z = Concatenate()([x, y, w])\n",
    "    \n",
    "    z = Dense(20, activation='relu')(z)\n",
    "    z = Dense(30, activation='relu')(z)\n",
    "    \n",
    "    output = Dense(5, activation='softmax')(z)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    model.compile(metrics=['categorical_accuracy'], loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "X_train, X_test = preproc(X_train, X_test, categorical_vars, numerical_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 1)         3           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 50)        8850        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 50)        6800        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 2)         8           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 4)         32          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 4)         32          input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 3)         21          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 2)         10          input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 2)         8           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 2)         8           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1, 2)         8           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1, 2)         8           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 2)         8           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 7)         105         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 50)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 50)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 2)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 4)            0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 4)            0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 3)            0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 2)            0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 2)            0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 2)            0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 2)            0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 2)            0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 2)            0           embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 7)            0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           96          input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 149)          0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "                                                                 reshape_12[0][0]                 \n",
      "                                                                 reshape_13[0][0]                 \n",
      "                                                                 reshape_14[0][0]                 \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           20560       input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 40)           6000        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 40)           3240        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 100)    2181100     input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 40)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 40)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 80)           45120       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 160)          0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 20)           3220        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           630         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 5)            155         dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,276,022\n",
      "Trainable params: 94,922\n",
      "Non-trainable params: 2,181,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = createModel(train, categorical_vars, numerical_vars)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"../checkpoints/weights_image_text_categorical.hdf6\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "earlystopped = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.0001, patience=10, verbose=0, mode='max')\n",
    "#callbacks_list = [checkpoint, earlystopped]\n",
    "callbacks_list = [checkpoint, earlystopped]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 5997 samples\n",
      "Epoch 1/1\n",
      "5997/5997 [==============================] - 119s 20ms/step - loss: 1.4513 - categorical_accuracy: 0.3233 - val_loss: 1.4193 - val_categorical_accuracy: 0.3395\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.33950, saving model to ../checkpoints/weights_image_text_categorical.hdf6\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=64 ,epochs=40, validation_split=VALIDATION_SPLIT, \n",
    "                 shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFvdJREFUeJzt3XuQnXWd5/H3h6RJmIUsl4QEEiRhvYAQxaLDSO0Ekd1VhkIERTOIQFiFkljBKxVGtGAUS4OjsK5KlnEgYHHLgqIrKuiIRmqRpckEElQuImAHxnQAb8NGTPLdP/rBPWQ66U6f0+k0vl9VT+Wc3/N9nvP9pav6c57L6ZOqQpKknUa7AUnSjsFAkCQBBoIkqWEgSJIAA0GS1DAQJEmAgSBJahgIkiTAQJAkNcaPdgPbYvLkyTVz5szRbkOSxpR77rlnXVVNGaxuTAXCzJkz6enpGe02JGlMSfLYUOo8ZSRJAgwESVLDQJAkAWPsGoKkPz9//OMf6e3tZf369aPdyg5v4sSJzJgxg66urmFtbyBI2qH19vay2267MXPmTJKMdjs7rKriqaeeore3l1mzZg1rH54ykrRDW79+PXvttZdhMIgk7LXXXm0dSRkIknZ4hsHQtPv/ZCBIkgADQZIGteuuu452C9uFgSBJAgwESRqyquLcc8/lkEMOYfbs2dxwww0APPnkkxx55JEceuihHHLIIfzoRz9i48aNzJ8//0+1l1xyySh3PzhvO5U0Zvzd/7qfnzzx247u85X7TuKCNx08pNqvfvWrrFy5knvvvZd169YxZ84cjjzySK699lre+MY3cv7557Nx40aeffZZVq5cyZo1a1i9ejUAv/71rzva90jwCEGShuiOO+7g5JNPZty4cUydOpXXve513H333cyZM4crr7ySCy+8kFWrVrHbbrtxwAEH8Mgjj7Bw4UK+853vMGnSpNFuf1CDHiEkuQI4DlhbVYdspW4OcCfwN1V1YzO2EVjVlDxeVcc347OA64G9gHuAU6vquXYmIunFb6jv5Le3I488kuXLl3PLLbcwf/58PvjBD3Laaadx7733cuutt7JkyRKWLVvGFVdcMdqtbtVQjhCWAsdsrSDJOGAxcNtmq/5vVR3aLMe3jC8GLqmqlwLPAO8aesuSNDrmzp3LDTfcwMaNG+nr62P58uUcfvjhPPbYY0ydOpUzzzyTd7/73axYsYJ169axadMm3vrWt3LRRRexYsWK0W5/UIMeIVTV8iQzBylbCNwEzBlsf+n/5MTRwDuaoauAC4HLBttWkkbTiSeeyJ133smrX/1qknDxxRczbdo0rrrqKj7zmc/Q1dXFrrvuytVXX82aNWs444wz2LRpEwCf+tSnRrn7waWqBi/qD4RvDnTKKMl04Frg9cAVTd3zp4w2ACuBDcCnq+rmJJOBHzdHByTZD/j2lk5HJTkLOAvgJS95yWGPPTak73mQ9CLx05/+lIMOOmi02xgzBvr/SnJPVXUPtm0n7jK6FFhUVZsG+Nj0/lW1JskBwPeTrAJ+sy07r6rLgcsBuru7B08vSdKwdCIQuoHrmzCYDBybZENV3VxVawCq6pEkPwBeQ/+ppd2TjK+qDcAMYE0H+pAktaHt206ralZVzayqmcCNwILm1NAeSSYANKeJ/iPwk+o/R3U7cFKzi9OBr7fbhySpPUO57fQ64ChgcpJe4AKgC6Cqlmxl04OA/5FkE/3B8+mq+kmzbhH9RxUXAf8M/OOwZyBJ6oih3GV08lB3VlXzWx7/b2D2FuoeAQ4f6n4lSSPPTypLkgADQZLUMBAkqcO29v0Jjz76KIccssW/AjSqDARJEuCfv5Y0lnz7PPiXVYPXbYtps+GvP73VkvPOO4/99tuP9773vQBceOGFjB8/nttvv51nnnmGP/7xj1x00UW8+c1v3qaXXr9+PWeffTY9PT2MHz+ez33uc7z+9a/n/vvv54wzzuC5555j06ZN3HTTTey77768/e1vp7e3l40bN/Kxj32MefPmDXvaAzEQJGkQ8+bN4/3vf/+fAmHZsmXceuutnHPOOUyaNIl169bx2te+luOPP36bvuj+i1/8IklYtWoVP/vZz3jDG97Agw8+yJIlS3jf+97HKaecwnPPPcfGjRv51re+xb777sstt9wCwG9+s01/9GFIDARJY8cg7+RHymte8xrWrl3LE088QV9fH3vssQfTpk3jAx/4AMuXL2ennXZizZo1/OpXv2LatGlD3u8dd9zBwoULATjwwAPZf//9efDBBzniiCP45Cc/SW9vL295y1t42ctexuzZs/nQhz7EokWLOO6445g7d27H5+k1BEkagre97W3ceOON3HDDDcybN49rrrmGvr4+7rnnHlauXMnUqVNZv359R17rHe94B9/4xjfYZZddOPbYY/n+97/Py1/+clasWMHs2bP56Ec/ysc//vGOvFYrjxAkaQjmzZvHmWeeybp16/jhD3/IsmXL2Hvvvenq6uL2229nOH+Jee7cuVxzzTUcffTRPPjggzz++OO84hWv4JFHHuGAAw7gnHPO4fHHH+e+++7jwAMPZM899+Sd73wnu+++O1/+8pc7PkcDQZKG4OCDD+Z3v/sd06dPZ5999uGUU07hTW96E7Nnz6a7u5sDDzxwm/e5YMECzj77bGbPns348eNZunQpEyZMYNmyZXzlK1+hq6uLadOm8ZGPfIS7776bc889l5122omuri4uu6zzXyEzpO9D2FF0d3dXT0/PaLchaTvy+xC2TTvfh+A1BEkS4CkjSRoRq1at4tRTT33B2IQJE7jrrrtGqaPBGQiSdnhVtU339+8IZs+ezcqVK7fra7Z7CcBTRpJ2aBMnTuSpp55q+5fdi11V8dRTTzFx4sRh78MjBEk7tBkzZtDb20tfX99ot7LDmzhxIjNmzBj29gaCpB1aV1cXs2bNGu02/ix4ykiSBBgIkqSGgSBJAgwESVLDQJAkAUMIhCRXJFmbZPUgdXOSbEhy0mbjk5L0JvlCy9gPkjyQZGWz7D38KUiSOmEoRwhLgWO2VpBkHLAYuG2A1Z8Alg8wfkpVHdosa4fQhyRpBA0aCFW1HHh6kLKFwE3AC36xJzkMmMrAQSFJ2oG0fQ0hyXTgROCyzcZ3Aj4LfHgLm17ZnC76WLbyR0qSnJWkJ0mPn1SUpJHTiYvKlwKLqmrTZuMLgG9VVe8A25xSVbOBuc1y6gA1AFTV5VXVXVXdU6ZM6UC7kqSBdOJPV3QD1zdv8icDxybZABwBzE2yANgV2DnJ76vqvKpaA1BVv0tyLXA4cHUHepEkDVPbgVBVf/ojI0mWAt+sqpuBm1vG5wPdVXVekvHA7lW1LkkXcBzwvXb7kCS1Z9BASHIdcBQwOUkvcAHQBVBVS4bxmhOAW5swGEd/GPzDMPYjSeogv1NZkl7k/E5lSdI2MRAkSYCBIElqGAiSJMBAkCQ1DARJEmAgSJIaBoIkCTAQJEkNA0GSBBgIkqSGgSBJAgwESVLDQJAkAQaCJKlhIEiSAANBktQwECRJgIEgSWoYCJIkwECQJDUMBEkSMMRASHJFkrVJVg9SNyfJhiQnbTY+KUlvki+0jB2WZFWSh5N8PkmGNwVJUicM9QhhKXDM1gqSjAMWA7cNsPoTwPLNxi4DzgRe1ixb3b8kaWQNKRCqajnw9CBlC4GbgLWtg0kOA6bSEhRJ9gEmVdWPq6qAq4ETtqFvSVKHdeQaQpLpwIn0v+tvHd8J+Czw4c02mQ70tjzvbcYG2vdZSXqS9PT19XWiXUnSADp1UflSYFFVbdpsfAHwrarqHWCbIamqy6uqu6q6p0yZ0laTkqQtG9+h/XQD1zfXhScDxybZABwBzE2yANgV2DnJ74H/Bsxo2X4GsKZDvUiShqEjgVBVs55/nGQp8M2quhm4uWV8PtBdVec1z3+b5LXAXcBpwH/vRC+SpOEZUiAkuQ44CpicpBe4AOgCqKolw3ztBfTfvbQL8O1mkSSNkvTf5DM2dHd3V09Pz2i3IUljSpJ7qqp7sDo/qSxJAgwESVLDQJAkAQaCJKlhIEiSAANBktQwECRJgIEgSWoYCJIkwECQJDUMBEkSYCBIkhoGgiQJMBAkSQ0DQZIEGAiSpIaBIEkCDARJUsNAkCQBBoIkqWEgSJKAIQRCkiuSrE2yepC6OUk2JDmpeb5/khVJVia5P8l7Wmp/kOSBZt3KJHu3PxVJUjvGD6FmKfAF4OotFSQZBywGbmsZfhI4oqr+kGRXYHWSb1TVE836U6qqZ3htS5I6bdAjhKpaDjw9SNlC4CZgbct2z1XVH5qnE4byWpKk0dP2L+kk04ETgcsGWLdfkvuAXwKLW44OAK5sThd9LEna7UOS1J5OvGu/FFhUVZs2X1FVv6yqVwEvBU5PMrVZdUpVzQbmNsupW9p5krOS9CTp6evr60C7kqSBdCIQuoHrkzwKnAR8KckJrQXNkcFq+n/5U1Vrmn9/B1wLHL6lnVfV5VXVXVXdU6ZM6UC7kqSBtB0IVTWrqmZW1UzgRmBBVd2cZEaSXQCS7AH8FfBAkvFJJjfjXcBx9IeFJGkUDXqXUZLrgKOAyUl6gQuALoCqWrKVTQ8CPpukgAB/X1Wrkvw74NYmDMYB3wP+oa1ZSJLaNmggVNXJQ91ZVc1vefxd4FUD1PwrcNhQ9ylJ2j68FVSSBBgIkqSGgSBJAgwESVLDQJAkAQaCJKlhIEiSAANBktQwECRJgIEgSWoYCJIkwECQJDUMBEkSYCBIkhoGgiQJMBAkSQ0DQZIEGAiSpIaBIEkCDARJUsNAkCQBBoIkqTGkQEhyRZK1SVYPUjcnyYYkJzXP90+yIsnKJPcneU9L7WFJViV5OMnnk6S9qUiS2jHUI4SlwDFbK0gyDlgM3NYy/CRwRFUdCvwlcF6SfZt1lwFnAi9rlq3uX5I0soYUCFW1HHh6kLKFwE3A2pbtnquqPzRPJzz/ekn2ASZV1Y+rqoCrgRO2sXdJUgd15BpCkunAifS/69983X5J7gN+CSyuqieA6UBvS1lvMyZJGiWduqh8KbCoqjZtvqKqfllVrwJeCpyeZOq27DjJWUl6kvT09fV1qF1J0uY6FQjdwPVJHgVOAr6U5AWngJojg9XAXGANMKNl9Yxm7N+oqsurqruquqdMmdKhdiVJm+tIIFTVrKqaWVUzgRuBBVV1c5IZSXYBSLIH8FfAA1X1JPDbJK9t7i46Dfh6J3qRJA3P+KEUJbkOOAqYnKQXuADoAqiqJVvZ9CDgs0kKCPD3VbWqWbeA/ruXdgG+3SySpFEypECoqpOHusOqmt/y+LvAq7ZQ1wMcMtT9SpJGlp9UliQBBoIkqWEgSJIAA0GS1DAQJEmAgSBJahgIkiTAQJAkNQwESRJgIEiSGgaCJAkwECRJDQNBkgQYCJKkhoEgSQIMBElSw0CQJAEGgiSpYSBIkgADQZLUMBAkSYCBIElqDBoISa5IsjbJ6kHq5iTZkOSk5vmhSe5Mcn+S+5LMa6ldmuQXSVY2y6HtT0WS1I6hHCEsBY7ZWkGSccBi4LaW4WeB06rq4Gb7S5Ps3rL+3Ko6tFlWblvbkqROGzQQqmo58PQgZQuBm4C1Lds9WFUPNY+faNZNGX6rkqSR1PY1hCTTgROBy7ZScziwM/DzluFPNqeSLkkyod0+JEnt6cRF5UuBRVW1aaCVSfYBvgKc0VLzt8CBwBxgT2DRlnae5KwkPUl6+vr6OtCuJGkgnQiEbuD6JI8CJwFfSnICQJJJwC3A+VX14+c3qKonq98fgCuBw7e086q6vKq6q6p7yhTPOEnSSBnf7g6qatbzj5MsBb5ZVTcn2Rn4GnB1Vd3Yuk2SfarqySQBTgC2egeTJGnkDRoISa4DjgImJ+kFLgC6AKpqyVY2fTtwJLBXkvnN2PzmjqJrkkwBAqwE3jPcCUiSOiNVNdo9DFl3d3f19PSMdhuSNKYkuaequger85PKkiTAQJAkNQwESRJgIEiSGgaCJAkwECRJDQNBkgQYCJKkhoEgSQIMBElSw0CQJAEGgiSpYSBIkgADQZLUMBAkSYCBIElqGAiSJMBAkCQ1DARJEmAgSJIaBoIkCTAQJEmNQQMhyRVJ1iZZPUjdnCQbkpzUPD80yZ1J7k9yX5J5LbWzktyV5OEkNyTZuf2pSJLaMZQjhKXAMVsrSDIOWAzc1jL8LHBaVR3cbH9pkt2bdYuBS6rqpcAzwLu2sW9JUocNGghVtRx4epCyhcBNwNqW7R6sqoeax08066YkCXA0cGNTehVwwra3LknqpLavISSZDpwIXLaVmsOBnYGfA3sBv66qDc3qXmB6u31IktrTiYvKlwKLqmrTQCuT7AN8BThjSzVbk+SsJD1Jevr6+tpsVZK0JeM7sI9u4Pr+M0FMBo5NsqGqbk4yCbgFOL+qftzUPwXsnmR8c5QwA1izpZ1X1eXA5QDd3d3VgX4lSQNo+wihqmZV1cyqmkn/dYEFTRjsDHwNuLqqbmypL+B24KRm6HTg6+32IUlqz1BuO70OuBN4RZLeJO9K8p4k7xlk07cDRwLzk6xslkObdYuADyZ5mP5rCv/YxhwkSR2Q/jfsY0N3d3f19PSMdhuSNKYkuaequger85PKkiTAQJAkNQwESRJgIEiSGgaCJAkwECRJDQNBkgQYCJKkhoEgSQLG2CeVk/QBj412H9toMrButJvYzpzznwfnPHbsX1VTBisaU4EwFiXpGcpHxl9MnPOfB+f84uMpI0kSYCBIkhoGwsi7fLQbGAXO+c+Dc36R8RqCJAnwCEGS1DAQOiDJnkm+m+Sh5t89tlB3elPzUJLTB1j/jSSrR77j9rUz5yR/keSWJD9Lcn+ST2/f7rdNkmOSPJDk4STnDbB+QpIbmvV3JZnZsu5vm/EHkrxxe/bdjuHOOcl/SXJPklXNv0dv796Hq52fc7P+JUl+n+TD26vnjqsqlzYX4GLgvObxecDiAWr2BB5p/t2jebxHy/q3ANcCq0d7PiM9Z+AvgNc3NTsDPwL+erTntIV5jgN+DhzQ9Hov8MrNahYAS5rHfwPc0Dx+ZVM/AZjV7GfcaM9phOf8GmDf5vEhwJrRns9Iz7ll/Y3A/wQ+PNrzGe7iEUJnvBm4qnl8FXDCADVvBL5bVU9X1TPAd4FjAJLsCnwQuGg79Nopw55zVT1bVbcDVNVzwApgxnboeTgOBx6uqkeaXq+nf+6tWv8vbgT+U5I049dX1R+q6hfAw83+dnTDnnNV/XNVPdGM3w/skmTCdum6Pe38nElyAvAL+uc8ZhkInTG1qp5sHv8LMHWAmunAL1ue9zZjAJ8APgs8O2Iddl67cwYgye7Am4B/GokmO2DQObTWVNUG4DfAXkPcdkfUzpxbvRVYUVV/GKE+O2nYc27e0C0C/m479Dmixo92A2NFku8B0wZYdX7rk6qqJEO+dSvJocB/qKoPbH5OcrSN1Jxb9j8euA74fFU9MrwutSNKcjCwGHjDaPeyHVwIXFJVv28OGMYsA2GIquo/b2ldkl8l2aeqnkyyD7B2gLI1wFEtz2cAPwCOALqTPEr/z2PvJD+oqqMYZSM45+ddDjxUVZd2oN2RsgbYr+X5jGZsoJreJuT+PfDUELfdEbUzZ5LMAL4GnFZVPx/5djuinTn/JXBSkouB3YFNSdZX1RdGvu0OG+2LGC+GBfgML7zAevEANXvSf45xj2b5BbDnZjUzGTsXlduaM/3XS24CdhrtuQwyz/H0Xwyfxf+/2HjwZjXv5YUXG5c1jw/mhReVH2FsXFRuZ867N/VvGe15bK85b1ZzIWP4ovKoN/BiWOg/d/pPwEPA91p+6XUDX26p+6/0X1h8GDhjgP2MpUAY9pzpf/dVwE+Blc3y7tGe01bmeizwIP13oZzfjH0cOL55PJH+u0seBv4PcEDLtuc32z3ADnonVSfnDHwU+NeWn+tKYO/Rns9I/5xb9jGmA8FPKkuSAO8ykiQ1DARJEmAgSJIaBoIkCTAQJEkNA0GSBBgIkqSGgSBJAuD/AX6RRp/UV24bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b8c3a6f2681d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plt.plot(hist.history['categorical_accuracy'])\n",
    "plt.plot(hist.history['val_categorical_accuracy'])\n",
    "plt.legend(['categorical_accuracy', 'val_categorical_accuracy'])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate our test set and find out Cohen's  quadratic weighte kappa for both Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)\n",
    "kappa(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(X_train)\n",
    "kappa(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load out best model and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('checkpoints/weights_image_text_categorical.hdf6')\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "kappa(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(X_train)\n",
    "kappa(y_train, train_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
